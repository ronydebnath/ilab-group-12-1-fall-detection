{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2ea3f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb9ea3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/raw/MobiAct_combined.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75e2198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_map = {\n",
    "    \"subject_id\": \"int16\",\n",
    "    \"trial\": \"int16\",\n",
    "    \"acc_x\": \"float32\", \"acc_y\": \"float32\", \"acc_z\": \"float32\",\n",
    "    \"gyro_x\": \"float32\",\"gyro_y\": \"float32\",\"gyro_z\": \"float32\",\n",
    "    \"azimuth\": \"float32\",\t\"pitch\": \"float32\",\t\"roll\": \"float32\",\n",
    "    \"label\": \"category\"\n",
    "}\n",
    "\n",
    "df = pd.read_csv(\n",
    "    file_path,\n",
    "    dtype=dtype_map,        # reduces memory footprint \n",
    "    engine='c')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83f459fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rel_time</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>pitch</th>\n",
       "      <th>roll</th>\n",
       "      <th>label</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>trial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1295405261000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.407311</td>\n",
       "      <td>9.614395</td>\n",
       "      <td>-2.086666</td>\n",
       "      <td>-0.844216</td>\n",
       "      <td>0.409280</td>\n",
       "      <td>0.086437</td>\n",
       "      <td>92.746895</td>\n",
       "      <td>-36.879684</td>\n",
       "      <td>-11.741077</td>\n",
       "      <td>STD</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1295410262000</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>-1.406354</td>\n",
       "      <td>9.612960</td>\n",
       "      <td>-2.084512</td>\n",
       "      <td>-0.711047</td>\n",
       "      <td>0.346971</td>\n",
       "      <td>0.076358</td>\n",
       "      <td>92.205360</td>\n",
       "      <td>-37.470173</td>\n",
       "      <td>-11.839779</td>\n",
       "      <td>STD</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1295415352000</td>\n",
       "      <td>0.010091</td>\n",
       "      <td>-1.405380</td>\n",
       "      <td>9.611498</td>\n",
       "      <td>-2.082320</td>\n",
       "      <td>-0.598953</td>\n",
       "      <td>0.093462</td>\n",
       "      <td>0.025045</td>\n",
       "      <td>91.743050</td>\n",
       "      <td>-38.090790</td>\n",
       "      <td>-11.880902</td>\n",
       "      <td>STD</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1295420307000</td>\n",
       "      <td>0.015046</td>\n",
       "      <td>-1.404432</td>\n",
       "      <td>9.610076</td>\n",
       "      <td>-2.080186</td>\n",
       "      <td>-0.128893</td>\n",
       "      <td>-0.012828</td>\n",
       "      <td>-0.002443</td>\n",
       "      <td>91.267319</td>\n",
       "      <td>-38.842915</td>\n",
       "      <td>-11.933741</td>\n",
       "      <td>STD</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1295425257000</td>\n",
       "      <td>0.019996</td>\n",
       "      <td>-1.403484</td>\n",
       "      <td>9.608654</td>\n",
       "      <td>-2.078054</td>\n",
       "      <td>0.049480</td>\n",
       "      <td>0.018326</td>\n",
       "      <td>0.016493</td>\n",
       "      <td>90.819679</td>\n",
       "      <td>-39.538643</td>\n",
       "      <td>-11.957446</td>\n",
       "      <td>STD</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16756320</th>\n",
       "      <td>10354577784000</td>\n",
       "      <td>299.969995</td>\n",
       "      <td>-0.907934</td>\n",
       "      <td>13.533889</td>\n",
       "      <td>4.335380</td>\n",
       "      <td>1.207070</td>\n",
       "      <td>-6.215859</td>\n",
       "      <td>1.962099</td>\n",
       "      <td>218.442352</td>\n",
       "      <td>-56.026966</td>\n",
       "      <td>-33.223778</td>\n",
       "      <td>WAL</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16756321</th>\n",
       "      <td>10354582775000</td>\n",
       "      <td>299.974986</td>\n",
       "      <td>-1.867024</td>\n",
       "      <td>12.331459</td>\n",
       "      <td>2.439285</td>\n",
       "      <td>0.968221</td>\n",
       "      <td>-6.103155</td>\n",
       "      <td>1.773953</td>\n",
       "      <td>220.688690</td>\n",
       "      <td>-57.077301</td>\n",
       "      <td>-31.897688</td>\n",
       "      <td>WAL</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16756322</th>\n",
       "      <td>10354588060000</td>\n",
       "      <td>299.980271</td>\n",
       "      <td>-2.924407</td>\n",
       "      <td>11.485553</td>\n",
       "      <td>0.782717</td>\n",
       "      <td>0.740674</td>\n",
       "      <td>-6.034738</td>\n",
       "      <td>1.459663</td>\n",
       "      <td>222.816406</td>\n",
       "      <td>-58.044624</td>\n",
       "      <td>-30.614605</td>\n",
       "      <td>WAL</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16756323</th>\n",
       "      <td>10354592749000</td>\n",
       "      <td>299.984960</td>\n",
       "      <td>-3.726923</td>\n",
       "      <td>11.084407</td>\n",
       "      <td>-0.258194</td>\n",
       "      <td>0.536645</td>\n",
       "      <td>-5.905845</td>\n",
       "      <td>1.027781</td>\n",
       "      <td>224.671646</td>\n",
       "      <td>-58.777103</td>\n",
       "      <td>-29.624798</td>\n",
       "      <td>WAL</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16756324</th>\n",
       "      <td>10354597768000</td>\n",
       "      <td>299.989979</td>\n",
       "      <td>-4.531702</td>\n",
       "      <td>10.794686</td>\n",
       "      <td>-1.200935</td>\n",
       "      <td>0.355524</td>\n",
       "      <td>-5.699373</td>\n",
       "      <td>0.550390</td>\n",
       "      <td>226.457153</td>\n",
       "      <td>-59.391144</td>\n",
       "      <td>-28.733915</td>\n",
       "      <td>WAL</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16756325 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp    rel_time     acc_x      acc_y     acc_z    gyro_x  \\\n",
       "0          1295405261000    0.000000 -1.407311   9.614395 -2.086666 -0.844216   \n",
       "1          1295410262000    0.005001 -1.406354   9.612960 -2.084512 -0.711047   \n",
       "2          1295415352000    0.010091 -1.405380   9.611498 -2.082320 -0.598953   \n",
       "3          1295420307000    0.015046 -1.404432   9.610076 -2.080186 -0.128893   \n",
       "4          1295425257000    0.019996 -1.403484   9.608654 -2.078054  0.049480   \n",
       "...                  ...         ...       ...        ...       ...       ...   \n",
       "16756320  10354577784000  299.969995 -0.907934  13.533889  4.335380  1.207070   \n",
       "16756321  10354582775000  299.974986 -1.867024  12.331459  2.439285  0.968221   \n",
       "16756322  10354588060000  299.980271 -2.924407  11.485553  0.782717  0.740674   \n",
       "16756323  10354592749000  299.984960 -3.726923  11.084407 -0.258194  0.536645   \n",
       "16756324  10354597768000  299.989979 -4.531702  10.794686 -1.200935  0.355524   \n",
       "\n",
       "            gyro_y    gyro_z     azimuth      pitch       roll label  \\\n",
       "0         0.409280  0.086437   92.746895 -36.879684 -11.741077   STD   \n",
       "1         0.346971  0.076358   92.205360 -37.470173 -11.839779   STD   \n",
       "2         0.093462  0.025045   91.743050 -38.090790 -11.880902   STD   \n",
       "3        -0.012828 -0.002443   91.267319 -38.842915 -11.933741   STD   \n",
       "4         0.018326  0.016493   90.819679 -39.538643 -11.957446   STD   \n",
       "...            ...       ...         ...        ...        ...   ...   \n",
       "16756320 -6.215859  1.962099  218.442352 -56.026966 -33.223778   WAL   \n",
       "16756321 -6.103155  1.773953  220.688690 -57.077301 -31.897688   WAL   \n",
       "16756322 -6.034738  1.459663  222.816406 -58.044624 -30.614605   WAL   \n",
       "16756323 -5.905845  1.027781  224.671646 -58.777103 -29.624798   WAL   \n",
       "16756324 -5.699373  0.550390  226.457153 -59.391144 -28.733915   WAL   \n",
       "\n",
       "          subject_id  trial  \n",
       "0                 10      1  \n",
       "1                 10      1  \n",
       "2                 10      1  \n",
       "3                 10      1  \n",
       "4                 10      1  \n",
       "...              ...    ...  \n",
       "16756320           9      1  \n",
       "16756321           9      1  \n",
       "16756322           9      1  \n",
       "16756323           9      1  \n",
       "16756324           9      1  \n",
       "\n",
       "[16756325 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b078cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fall_labels = ['BSC', 'FKL', 'SDL', 'FOL']\n",
    "post_fall = ['LYI']\n",
    "\n",
    "df['fall_label'] = df['label'].apply(\n",
    "    lambda x: 'FALL' if x in fall_labels else ('POST_FALL' if x in post_fall else 'ADL')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8db88954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal as signal\n",
    "def apply_low_pass_filter(data, cutoff=3, fs=10, order=4):\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = signal.butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    df_filtered = data.copy()\n",
    "    for col in ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z']:\n",
    "        df_filtered[col] = signal.filtfilt(b, a, data[col])\n",
    "    return df_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb065bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = apply_low_pass_filter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b106fd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "sensor_cols = ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z', 'azimuth','pitch','roll']\n",
    "df[sensor_cols] = scaler.fit_transform(df[sensor_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a1ed3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../app/models/scaler.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, joblib\n",
    "\n",
    "# create models folder if it doesn’t exist\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# 1. Save your scaler (after you call scaler.fit_transform)\n",
    "joblib.dump(scaler, \"../app/models/scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ced70b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train subjects: {2, 3, 4, 7, 8, 11, 12, 14, 15, 16, 18, 20, 21, 22, 23, 25, 28, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 54, 56, 57, 58, 61, 63, 64, 66, 67}\n",
      "Val subjects: {59, 9, 19, 53, 55, 24, 27}\n",
      "Test subjects: {1, 65, 37, 5, 6, 41, 10, 13, 46, 17, 26, 60, 29, 62}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# Get your subject group array\n",
    "groups = df['subject_id'].values\n",
    "\n",
    "# 1. Split off test subjects\n",
    "gss1 = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "trainval_idx, test_idx = next(gss1.split(df, df['label'], groups=groups))\n",
    "\n",
    "trainval_subjects = df.iloc[trainval_idx]['subject_id'].unique()\n",
    "test_subjects = df.iloc[test_idx]['subject_id'].unique()\n",
    "\n",
    "df_trainval = df[df['subject_id'].isin(trainval_subjects)].copy()\n",
    "df_test     = df[df['subject_id'].isin(test_subjects)].copy()\n",
    "\n",
    "# 2. Split val subjects from trainval\n",
    "groups_trainval = df_trainval['subject_id'].values\n",
    "gss2 = GroupShuffleSplit(n_splits=1, test_size=0.125, random_state=42)\n",
    "train_idx, val_idx = next(gss2.split(df_trainval, df_trainval['label'], groups=groups_trainval))\n",
    "\n",
    "train_subjects = df_trainval.iloc[train_idx]['subject_id'].unique()\n",
    "val_subjects   = df_trainval.iloc[val_idx]['subject_id'].unique()\n",
    "\n",
    "df_train = df_trainval[df_trainval['subject_id'].isin(train_subjects)].copy()\n",
    "df_val   = df_trainval[df_trainval['subject_id'].isin(val_subjects)].copy()\n",
    "\n",
    "print(\"Train subjects:\", set(train_subjects))\n",
    "print(\"Val subjects:\", set(val_subjects))\n",
    "print(\"Test subjects:\", set(test_subjects))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3cfe1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[sensor_cols]\n",
    "X_val = df_val[sensor_cols]\n",
    "X_test = df_test[sensor_cols]\n",
    "\n",
    "y_train = df_train['fall_label']\n",
    "y_val= df_val['fall_label']\n",
    "y_test = df_test['fall_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57572789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>pitch</th>\n",
       "      <th>roll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5909</th>\n",
       "      <td>0.630989</td>\n",
       "      <td>0.365547</td>\n",
       "      <td>0.290961</td>\n",
       "      <td>-0.845714</td>\n",
       "      <td>0.544943</td>\n",
       "      <td>0.021701</td>\n",
       "      <td>-1.438502</td>\n",
       "      <td>0.827826</td>\n",
       "      <td>2.419112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5910</th>\n",
       "      <td>0.102306</td>\n",
       "      <td>0.644049</td>\n",
       "      <td>0.072772</td>\n",
       "      <td>-1.157569</td>\n",
       "      <td>0.752584</td>\n",
       "      <td>0.035295</td>\n",
       "      <td>-1.437745</td>\n",
       "      <td>0.822384</td>\n",
       "      <td>2.415175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5911</th>\n",
       "      <td>0.251167</td>\n",
       "      <td>0.557365</td>\n",
       "      <td>0.143087</td>\n",
       "      <td>-1.054991</td>\n",
       "      <td>0.703504</td>\n",
       "      <td>0.025325</td>\n",
       "      <td>-1.436687</td>\n",
       "      <td>0.816758</td>\n",
       "      <td>2.408868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5912</th>\n",
       "      <td>0.340463</td>\n",
       "      <td>0.502126</td>\n",
       "      <td>0.188847</td>\n",
       "      <td>-1.003387</td>\n",
       "      <td>0.684684</td>\n",
       "      <td>0.021753</td>\n",
       "      <td>-1.435659</td>\n",
       "      <td>0.811031</td>\n",
       "      <td>2.402353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5913</th>\n",
       "      <td>0.242279</td>\n",
       "      <td>0.551189</td>\n",
       "      <td>0.152063</td>\n",
       "      <td>-1.084589</td>\n",
       "      <td>0.737607</td>\n",
       "      <td>0.031794</td>\n",
       "      <td>-1.434582</td>\n",
       "      <td>0.805163</td>\n",
       "      <td>2.394990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16696321</th>\n",
       "      <td>0.094151</td>\n",
       "      <td>0.216117</td>\n",
       "      <td>0.895978</td>\n",
       "      <td>1.410470</td>\n",
       "      <td>-0.890444</td>\n",
       "      <td>1.176046</td>\n",
       "      <td>0.661639</td>\n",
       "      <td>-0.353977</td>\n",
       "      <td>-0.138863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16696322</th>\n",
       "      <td>-0.018138</td>\n",
       "      <td>0.239386</td>\n",
       "      <td>1.012633</td>\n",
       "      <td>1.296096</td>\n",
       "      <td>-0.795988</td>\n",
       "      <td>1.282239</td>\n",
       "      <td>0.663706</td>\n",
       "      <td>-0.357465</td>\n",
       "      <td>-0.126698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16696323</th>\n",
       "      <td>0.071032</td>\n",
       "      <td>0.468271</td>\n",
       "      <td>1.393800</td>\n",
       "      <td>1.366662</td>\n",
       "      <td>-0.821939</td>\n",
       "      <td>1.544532</td>\n",
       "      <td>0.665571</td>\n",
       "      <td>-0.360720</td>\n",
       "      <td>-0.113490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16696324</th>\n",
       "      <td>0.145940</td>\n",
       "      <td>0.819790</td>\n",
       "      <td>1.897802</td>\n",
       "      <td>1.422104</td>\n",
       "      <td>-0.822488</td>\n",
       "      <td>1.792295</td>\n",
       "      <td>0.666245</td>\n",
       "      <td>-0.361143</td>\n",
       "      <td>-0.099987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16696325</th>\n",
       "      <td>-0.658568</td>\n",
       "      <td>0.570295</td>\n",
       "      <td>1.571646</td>\n",
       "      <td>0.661952</td>\n",
       "      <td>-0.335581</td>\n",
       "      <td>1.338744</td>\n",
       "      <td>0.666646</td>\n",
       "      <td>-0.360869</td>\n",
       "      <td>-0.086314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11248316 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             acc_x     acc_y     acc_z    gyro_x    gyro_y    gyro_z  \\\n",
       "5909      0.630989  0.365547  0.290961 -0.845714  0.544943  0.021701   \n",
       "5910      0.102306  0.644049  0.072772 -1.157569  0.752584  0.035295   \n",
       "5911      0.251167  0.557365  0.143087 -1.054991  0.703504  0.025325   \n",
       "5912      0.340463  0.502126  0.188847 -1.003387  0.684684  0.021753   \n",
       "5913      0.242279  0.551189  0.152063 -1.084589  0.737607  0.031794   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "16696321  0.094151  0.216117  0.895978  1.410470 -0.890444  1.176046   \n",
       "16696322 -0.018138  0.239386  1.012633  1.296096 -0.795988  1.282239   \n",
       "16696323  0.071032  0.468271  1.393800  1.366662 -0.821939  1.544532   \n",
       "16696324  0.145940  0.819790  1.897802  1.422104 -0.822488  1.792295   \n",
       "16696325 -0.658568  0.570295  1.571646  0.661952 -0.335581  1.338744   \n",
       "\n",
       "           azimuth     pitch      roll  \n",
       "5909     -1.438502  0.827826  2.419112  \n",
       "5910     -1.437745  0.822384  2.415175  \n",
       "5911     -1.436687  0.816758  2.408868  \n",
       "5912     -1.435659  0.811031  2.402353  \n",
       "5913     -1.434582  0.805163  2.394990  \n",
       "...            ...       ...       ...  \n",
       "16696321  0.661639 -0.353977 -0.138863  \n",
       "16696322  0.663706 -0.357465 -0.126698  \n",
       "16696323  0.665571 -0.360720 -0.113490  \n",
       "16696324  0.666245 -0.361143 -0.099987  \n",
       "16696325  0.666646 -0.360869 -0.086314  \n",
       "\n",
       "[11248316 rows x 9 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c7aec9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fall_label\n",
       "ADL          10279606\n",
       "POST_FALL      711873\n",
       "FALL           256837\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1fef5d",
   "metadata": {},
   "source": [
    "### Segment into Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72814fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_cols = ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z', 'azimuth', 'pitch', 'roll']\n",
    "\n",
    "def create_windows(X, y, window_size=500, step_size = 250):\n",
    "    X_windows, y_windows = [], []\n",
    "\n",
    "    for start in range(0, len(X) - window_size + 1, step_size):  # No overlap\n",
    "        end = start + window_size\n",
    "        window_data = X[start:end]\n",
    "        window_labels = y[start:end]\n",
    "        unique_labels = set(window_labels)\n",
    "\n",
    "        # Labeling logic (you can simplify this now)\n",
    "        if \"ADL\" in unique_labels and \"FALL\" in unique_labels:\n",
    "            continue\n",
    "        elif \"POST_FALL\" in unique_labels and \"ADL\" in unique_labels:\n",
    "            continue\n",
    "        elif \"FALL\" in unique_labels and \"POST_FALL\" in unique_labels:\n",
    "            label = \"FALL\"\n",
    "        elif \"FALL\" in unique_labels:\n",
    "            label = \"FALL\"\n",
    "        elif \"ADL\" in unique_labels:\n",
    "            label = \"ADL\"\n",
    "\n",
    "        X_windows.append(window_data)\n",
    "        y_windows.append(label)\n",
    "\n",
    "    return np.array(X_windows), np.array(y_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "932ff65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_windows, y_train_windows = create_windows(X_train, y_train)\n",
    "X_val_windows, y_val_windows = create_windows(X_val, y_val)\n",
    "X_test_windows, y_test_windows = create_windows(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7a1ac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train_windows)\n",
    "y_val_encoded = le.transform(y_val_windows)\n",
    "y_test_encoded = le.transform(y_test_windows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2dd7821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure they are NumPy arrays\n",
    "y_train_encoded = np.array(y_train_encoded)\n",
    "y_val_encoded = np.array(y_val_encoded)\n",
    "y_test_encoded = np.array(y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18d3ae11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../app/models/label_encoder.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(le, \"../app/models/label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9ab8e1",
   "metadata": {},
   "source": [
    "### Encode Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d15f952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_windows.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c852635f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vega7unk/anaconda3/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,376</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">123</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">115</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">115</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m5,376\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m246\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m123\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m115\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m115\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m258\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">106,818</span> (417.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m106,818\u001b[0m (417.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">106,562</span> (416.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m106,562\u001b[0m (416.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Conv1D, MaxPooling1D, BatchNormalization\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "\n",
    "\n",
    "# Implementation of \"LSTM-CNN Architecture for Human Activity Recognition\" by Kun Xia et al. (IEEE Access, 2020)\n",
    "# Adapted from https://github.com/quotation2520/CAGE4HAR/blob/main/models/LSTM_CNN.py\n",
    "\n",
    "## X_train_windows.shape == (n_samples, 100, 6)\n",
    "input_shape = (X_train_windows.shape[1], X_train_windows.shape[2]) \n",
    "num_classes = len(set(y_train_encoded))                  \n",
    "\n",
    "model_lstm_conv = Sequential([\n",
    "\n",
    "    # ——— LSTM stack ———\n",
    "    # first LSTM returns full sequence\n",
    "    LSTM(32, return_sequences=True, input_shape=input_shape),\n",
    "    # second LSTM also returns full sequence\n",
    "    LSTM(32, return_sequences=True),\n",
    "\n",
    "    # ——— 1D‐Conv + Pool ———\n",
    "    Conv1D(\n",
    "        filters=64,\n",
    "        kernel_size=9,\n",
    "        strides=2,\n",
    "        activation='relu',\n",
    "        padding='valid'   # matches PyTorch default\n",
    "    ),\n",
    "    MaxPooling1D(pool_size=2, strides=2),\n",
    "\n",
    "    # ——— second Conv block ———\n",
    "    Conv1D(\n",
    "        filters=128,\n",
    "        kernel_size=9,\n",
    "        strides=1,\n",
    "        activation='relu',\n",
    "        padding='valid'\n",
    "    ),\n",
    "\n",
    "    # ——— batch‐norm & spatial collapse ———\n",
    "    BatchNormalization(),            # normalise over feature‐axis\n",
    "    GlobalAveragePooling1D(),        # mean over time dimension\n",
    "\n",
    "    # ——— classification head ———\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model_lstm_conv.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_lstm_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c05daa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "817510a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights to handle imbalance\n",
    "y_train_array = np.array(y_train_encoded)\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train_array),\n",
    "    y=y_train_array\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb7b333b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5344189126223116, 1: 7.76344852155326}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e6289a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 268ms/step - accuracy: 0.8292 - loss: 0.3338 - val_accuracy: 0.9051 - val_loss: 0.3337\n",
      "Epoch 2/20\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 257ms/step - accuracy: 0.9259 - loss: 0.1615 - val_accuracy: 0.9264 - val_loss: 0.2852\n",
      "Epoch 3/20\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 262ms/step - accuracy: 0.9329 - loss: 0.1360 - val_accuracy: 0.8886 - val_loss: 0.4754\n",
      "Epoch 4/20\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 253ms/step - accuracy: 0.9376 - loss: 0.1291 - val_accuracy: 0.8883 - val_loss: 0.3912\n",
      "Epoch 5/20\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 256ms/step - accuracy: 0.9445 - loss: 0.1160 - val_accuracy: 0.8938 - val_loss: 0.4015\n",
      "Epoch 6/20\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 255ms/step - accuracy: 0.9482 - loss: 0.1101 - val_accuracy: 0.9126 - val_loss: 0.3370\n",
      "Epoch 7/20\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 252ms/step - accuracy: 0.9557 - loss: 0.1029 - val_accuracy: 0.9212 - val_loss: 0.3547\n",
      "Epoch 8/20\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 256ms/step - accuracy: 0.9597 - loss: 0.0956 - val_accuracy: 0.9239 - val_loss: 0.3830\n",
      "Epoch 9/20\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 256ms/step - accuracy: 0.9611 - loss: 0.0816 - val_accuracy: 0.9351 - val_loss: 0.2533\n",
      "Epoch 10/20\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 256ms/step - accuracy: 0.9602 - loss: 0.0866 - val_accuracy: 0.9129 - val_loss: 0.4102\n",
      "Epoch 11/20\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 254ms/step - accuracy: 0.9618 - loss: 0.0814 - val_accuracy: 0.9130 - val_loss: 0.3691\n",
      "Epoch 12/20\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 253ms/step - accuracy: 0.9669 - loss: 0.0714 - val_accuracy: 0.9088 - val_loss: 0.3465\n",
      "Epoch 13/20\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 253ms/step - accuracy: 0.9660 - loss: 0.0726 - val_accuracy: 0.9333 - val_loss: 0.2710\n",
      "Epoch 14/20\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 252ms/step - accuracy: 0.9643 - loss: 0.0779 - val_accuracy: 0.9163 - val_loss: 0.3699\n",
      "Epoch 15/20\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 252ms/step - accuracy: 0.9672 - loss: 0.0710 - val_accuracy: 0.9235 - val_loss: 0.3262\n",
      "Epoch 16/20\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 253ms/step - accuracy: 0.9699 - loss: 0.0647 - val_accuracy: 0.9128 - val_loss: 0.4044\n",
      "Epoch 17/20\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 253ms/step - accuracy: 0.9688 - loss: 0.0663 - val_accuracy: 0.9278 - val_loss: 0.3418\n",
      "Epoch 18/20\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 254ms/step - accuracy: 0.9724 - loss: 0.0632 - val_accuracy: 0.9335 - val_loss: 0.3436\n",
      "Epoch 19/20\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 255ms/step - accuracy: 0.9691 - loss: 0.0761 - val_accuracy: 0.9241 - val_loss: 0.3574\n",
      "Epoch 20/20\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 261ms/step - accuracy: 0.9726 - loss: 0.0626 - val_accuracy: 0.9139 - val_loss: 0.4590\n"
     ]
    }
   ],
   "source": [
    "history = model_lstm_conv.fit(\n",
    "    X_train_windows, y_train_encoded,\n",
    "    validation_data=(X_val_windows, y_val_encoded),\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51a30c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (confusion_matrix, classification_report, \n",
    "                             precision_score, recall_score, f1_score)\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, label_classes=None, plot_confusion_matrix=True, plot_roc=False):\n",
    "    # Evaluate the model\n",
    "    results = model.evaluate(X_test, y_test, verbose=0)\n",
    "    metric_names = model.metrics_names\n",
    "    metrics_dict = dict(zip(metric_names, results))\n",
    "\n",
    "    print(\"Evaluation Metrics:\")\n",
    "    for name, value in metrics_dict.items():\n",
    "        print(f\"{name.capitalize()}: {value:.4f}\")\n",
    "\n",
    "    # Predict class probabilities and take argmax for predicted class\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    if plot_confusion_matrix:\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues',\n",
    "                    xticklabels=label_classes if label_classes else np.unique(y_test),\n",
    "                    yticklabels=label_classes if label_classes else np.unique(y_test))\n",
    "        plt.xlabel(\"Predicted Label\")\n",
    "        plt.ylabel(\"True Label\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.show()\n",
    "\n",
    "    # Classification report\n",
    "    report = classification_report(y_test, y_pred, target_names=label_classes if label_classes else None)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "    # Macro-averaged metrics across all classes\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(\"Macro Precision (sklearn): {:.4f}\".format(precision))\n",
    "    print(\"Macro Recall (sklearn): {:.4f}\".format(recall))\n",
    "    print(\"Macro F1 Score: {:.4f}\".format(f1))\n",
    "\n",
    "    # Update metrics dictionary to include sklearn metrics\n",
    "    metrics_dict.update({\n",
    "        'macro_precision': precision,\n",
    "        'macro_recall': recall,\n",
    "        'macro_f1_score': f1\n",
    "    })\n",
    "\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d89fa750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Loss: 0.2333\n",
      "Compile_metrics: 0.9508\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 51ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ADL       1.00      0.95      0.97     13341\n",
      "        FALL       0.54      0.93      0.68       797\n",
      "\n",
      "    accuracy                           0.95     14138\n",
      "   macro avg       0.77      0.94      0.83     14138\n",
      "weighted avg       0.97      0.95      0.96     14138\n",
      "\n",
      "Macro Precision (sklearn): 0.7661\n",
      "Macro Recall (sklearn): 0.9391\n",
      "Macro F1 Score: 0.8264\n"
     ]
    }
   ],
   "source": [
    "label_classes = le.classes_.tolist()\n",
    "metrics = evaluate_model(model_lstm_conv, X_test_windows, y_test_encoded, label_classes=label_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "666783a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model_lstm_conv.save(\"../app/models/cnn_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4718ad1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
