{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2ea3f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb9ea3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../../data/raw/MobiAct_combined.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75e2198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_map = {\n",
    "    \"subject_id\": \"int16\",\n",
    "    \"trial\": \"int16\",\n",
    "    \"acc_x\": \"float32\", \"acc_y\": \"float32\", \"acc_z\": \"float32\",\n",
    "    \"gyro_x\": \"float32\",\"gyro_y\": \"float32\",\"gyro_z\": \"float32\",\n",
    "    \"azimuth\": \"float32\",\t\"pitch\": \"float32\",\t\"roll\": \"float32\",\n",
    "    \"label\": \"category\"\n",
    "}\n",
    "\n",
    "df = pd.read_csv(\n",
    "    file_path,\n",
    "    dtype=dtype_map,        # reduces memory footprint \n",
    "    engine='c')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83f459fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rel_time</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>pitch</th>\n",
       "      <th>roll</th>\n",
       "      <th>label</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>trial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1295405261000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.407311</td>\n",
       "      <td>9.614395</td>\n",
       "      <td>-2.086666</td>\n",
       "      <td>-0.844216</td>\n",
       "      <td>0.409280</td>\n",
       "      <td>0.086437</td>\n",
       "      <td>92.746895</td>\n",
       "      <td>-36.879684</td>\n",
       "      <td>-11.741077</td>\n",
       "      <td>STD</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1295410262000</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>-1.406354</td>\n",
       "      <td>9.612960</td>\n",
       "      <td>-2.084512</td>\n",
       "      <td>-0.711047</td>\n",
       "      <td>0.346971</td>\n",
       "      <td>0.076358</td>\n",
       "      <td>92.205360</td>\n",
       "      <td>-37.470173</td>\n",
       "      <td>-11.839779</td>\n",
       "      <td>STD</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1295415352000</td>\n",
       "      <td>0.010091</td>\n",
       "      <td>-1.405380</td>\n",
       "      <td>9.611498</td>\n",
       "      <td>-2.082320</td>\n",
       "      <td>-0.598953</td>\n",
       "      <td>0.093462</td>\n",
       "      <td>0.025045</td>\n",
       "      <td>91.743050</td>\n",
       "      <td>-38.090790</td>\n",
       "      <td>-11.880902</td>\n",
       "      <td>STD</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1295420307000</td>\n",
       "      <td>0.015046</td>\n",
       "      <td>-1.404432</td>\n",
       "      <td>9.610076</td>\n",
       "      <td>-2.080186</td>\n",
       "      <td>-0.128893</td>\n",
       "      <td>-0.012828</td>\n",
       "      <td>-0.002443</td>\n",
       "      <td>91.267319</td>\n",
       "      <td>-38.842915</td>\n",
       "      <td>-11.933741</td>\n",
       "      <td>STD</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1295425257000</td>\n",
       "      <td>0.019996</td>\n",
       "      <td>-1.403484</td>\n",
       "      <td>9.608654</td>\n",
       "      <td>-2.078054</td>\n",
       "      <td>0.049480</td>\n",
       "      <td>0.018326</td>\n",
       "      <td>0.016493</td>\n",
       "      <td>90.819679</td>\n",
       "      <td>-39.538643</td>\n",
       "      <td>-11.957446</td>\n",
       "      <td>STD</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16756320</th>\n",
       "      <td>10354577784000</td>\n",
       "      <td>299.969995</td>\n",
       "      <td>-0.907934</td>\n",
       "      <td>13.533889</td>\n",
       "      <td>4.335380</td>\n",
       "      <td>1.207070</td>\n",
       "      <td>-6.215859</td>\n",
       "      <td>1.962099</td>\n",
       "      <td>218.442352</td>\n",
       "      <td>-56.026966</td>\n",
       "      <td>-33.223778</td>\n",
       "      <td>WAL</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16756321</th>\n",
       "      <td>10354582775000</td>\n",
       "      <td>299.974986</td>\n",
       "      <td>-1.867024</td>\n",
       "      <td>12.331459</td>\n",
       "      <td>2.439285</td>\n",
       "      <td>0.968221</td>\n",
       "      <td>-6.103155</td>\n",
       "      <td>1.773953</td>\n",
       "      <td>220.688690</td>\n",
       "      <td>-57.077301</td>\n",
       "      <td>-31.897688</td>\n",
       "      <td>WAL</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16756322</th>\n",
       "      <td>10354588060000</td>\n",
       "      <td>299.980271</td>\n",
       "      <td>-2.924407</td>\n",
       "      <td>11.485553</td>\n",
       "      <td>0.782717</td>\n",
       "      <td>0.740674</td>\n",
       "      <td>-6.034738</td>\n",
       "      <td>1.459663</td>\n",
       "      <td>222.816406</td>\n",
       "      <td>-58.044624</td>\n",
       "      <td>-30.614605</td>\n",
       "      <td>WAL</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16756323</th>\n",
       "      <td>10354592749000</td>\n",
       "      <td>299.984960</td>\n",
       "      <td>-3.726923</td>\n",
       "      <td>11.084407</td>\n",
       "      <td>-0.258194</td>\n",
       "      <td>0.536645</td>\n",
       "      <td>-5.905845</td>\n",
       "      <td>1.027781</td>\n",
       "      <td>224.671646</td>\n",
       "      <td>-58.777103</td>\n",
       "      <td>-29.624798</td>\n",
       "      <td>WAL</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16756324</th>\n",
       "      <td>10354597768000</td>\n",
       "      <td>299.989979</td>\n",
       "      <td>-4.531702</td>\n",
       "      <td>10.794686</td>\n",
       "      <td>-1.200935</td>\n",
       "      <td>0.355524</td>\n",
       "      <td>-5.699373</td>\n",
       "      <td>0.550390</td>\n",
       "      <td>226.457153</td>\n",
       "      <td>-59.391144</td>\n",
       "      <td>-28.733915</td>\n",
       "      <td>WAL</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16756325 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp    rel_time     acc_x      acc_y     acc_z    gyro_x  \\\n",
       "0          1295405261000    0.000000 -1.407311   9.614395 -2.086666 -0.844216   \n",
       "1          1295410262000    0.005001 -1.406354   9.612960 -2.084512 -0.711047   \n",
       "2          1295415352000    0.010091 -1.405380   9.611498 -2.082320 -0.598953   \n",
       "3          1295420307000    0.015046 -1.404432   9.610076 -2.080186 -0.128893   \n",
       "4          1295425257000    0.019996 -1.403484   9.608654 -2.078054  0.049480   \n",
       "...                  ...         ...       ...        ...       ...       ...   \n",
       "16756320  10354577784000  299.969995 -0.907934  13.533889  4.335380  1.207070   \n",
       "16756321  10354582775000  299.974986 -1.867024  12.331459  2.439285  0.968221   \n",
       "16756322  10354588060000  299.980271 -2.924407  11.485553  0.782717  0.740674   \n",
       "16756323  10354592749000  299.984960 -3.726923  11.084407 -0.258194  0.536645   \n",
       "16756324  10354597768000  299.989979 -4.531702  10.794686 -1.200935  0.355524   \n",
       "\n",
       "            gyro_y    gyro_z     azimuth      pitch       roll label  \\\n",
       "0         0.409280  0.086437   92.746895 -36.879684 -11.741077   STD   \n",
       "1         0.346971  0.076358   92.205360 -37.470173 -11.839779   STD   \n",
       "2         0.093462  0.025045   91.743050 -38.090790 -11.880902   STD   \n",
       "3        -0.012828 -0.002443   91.267319 -38.842915 -11.933741   STD   \n",
       "4         0.018326  0.016493   90.819679 -39.538643 -11.957446   STD   \n",
       "...            ...       ...         ...        ...        ...   ...   \n",
       "16756320 -6.215859  1.962099  218.442352 -56.026966 -33.223778   WAL   \n",
       "16756321 -6.103155  1.773953  220.688690 -57.077301 -31.897688   WAL   \n",
       "16756322 -6.034738  1.459663  222.816406 -58.044624 -30.614605   WAL   \n",
       "16756323 -5.905845  1.027781  224.671646 -58.777103 -29.624798   WAL   \n",
       "16756324 -5.699373  0.550390  226.457153 -59.391144 -28.733915   WAL   \n",
       "\n",
       "          subject_id  trial  \n",
       "0                 10      1  \n",
       "1                 10      1  \n",
       "2                 10      1  \n",
       "3                 10      1  \n",
       "4                 10      1  \n",
       "...              ...    ...  \n",
       "16756320           9      1  \n",
       "16756321           9      1  \n",
       "16756322           9      1  \n",
       "16756323           9      1  \n",
       "16756324           9      1  \n",
       "\n",
       "[16756325 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b078cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fall_labels = ['BSC', 'FKL', 'SDL', 'FOL']\n",
    "post_fall = ['LYI']\n",
    "\n",
    "df['fall_label'] = df['label'].apply(\n",
    "    lambda x: 'FALL' if x in fall_labels else ('POST_FALL' if x in post_fall else 'ADL')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8db88954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal as signal\n",
    "def apply_low_pass_filter(data, cutoff=3, fs=10, order=4):\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = signal.butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    df_filtered = data.copy()\n",
    "    for col in ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z']:\n",
    "        df_filtered[col] = signal.filtfilt(b, a, data[col])\n",
    "    return df_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb065bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = apply_low_pass_filter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b106fd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "sensor_cols = ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z', 'azimuth','pitch','roll']\n",
    "df[sensor_cols] = scaler.fit_transform(df[sensor_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9e678e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[sensor_cols]\n",
    "y = df['fall_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db51d583",
   "metadata": {},
   "source": [
    "### Extract window / Label data based on dynamic window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56b44f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "\n",
    "def sliding_multi_window(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    fs: int = 200,\n",
    "    subwindow_duration: float = 0.2,\n",
    "    overlap: float = 0.5,\n",
    "    include_post_fall: bool = True\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Implements label-based main windows with fixed-size, overlapping sub-windows.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray, shape (n_samples, n_features)\n",
    "        Time-series sensor data (e.g., acc_x, acc_y, ..., gyro_z).\n",
    "    y : np.ndarray, shape (n_samples,)\n",
    "        Frame-level labels: 'ADL', 'FALL', 'POST_FALL', etc.\n",
    "    fs : int\n",
    "        Sampling rate in Hz (e.g., 200).\n",
    "    subwindow_duration : float\n",
    "        Duration of each sub-window in seconds (e.g., 0.2).\n",
    "    overlap : float\n",
    "        Fractional overlap between sub-windows (0 to <1, e.g., 0.5 for 50%).\n",
    "    include_post_fall : bool\n",
    "        If True, emits 'POST_FALL' windows; if False, merges POST_FALL into 'FALL'.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X_sub : np.ndarray, shape (n_subwindows, window_size, n_features)\n",
    "        Array of all extracted sub-windows.\n",
    "    y_sub : np.ndarray, shape (n_subwindows,)\n",
    "        Corresponding labels for each sub-window.\n",
    "    \"\"\"\n",
    "    # Compute window parameters\n",
    "    window_size = int(fs * subwindow_duration)\n",
    "    step_size = int(window_size * (1 - overlap))\n",
    "    if step_size < 1:\n",
    "        raise ValueError(\"Overlap too large: step size <1 sample.\")\n",
    "    \n",
    "    # Ensure proper indexing\n",
    "    X_arr = np.asarray(X)\n",
    "    y_arr = np.asarray(y)\n",
    "    \n",
    "    X_sub, y_sub = [], []\n",
    "    \n",
    "    # Helper to slice sub-windows within a main segment\n",
    "    def emit_windows(segment: np.ndarray, label: str):\n",
    "        for start in range(0, len(segment) - window_size + 1, step_size):\n",
    "            end = start + window_size\n",
    "            X_sub.append(segment[start:end])\n",
    "            y_sub.append(label)\n",
    "    \n",
    "    # Find contiguous main windows by label\n",
    "    curr_label = y_arr[0]\n",
    "    seg_start = 0\n",
    "    for i in range(1, len(y_arr)):\n",
    "        if y_arr[i] != curr_label:\n",
    "            segment = X_arr[seg_start:i]\n",
    "            if curr_label == \"ADL\":\n",
    "                emit_windows(segment, \"ADL\")\n",
    "            elif curr_label == \"FALL\":\n",
    "                emit_windows(segment, \"FALL\")\n",
    "            elif curr_label == \"POST_FALL\":\n",
    "                if include_post_fall:\n",
    "                    emit_windows(segment, \"POST_FALL\")\n",
    "                else:\n",
    "                    emit_windows(segment, \"FALL\")\n",
    "            # start next main window\n",
    "            seg_start = i\n",
    "            curr_label = y_arr[i]\n",
    "    \n",
    "    # Handle the last main window\n",
    "    segment = X_arr[seg_start:]\n",
    "    if curr_label == \"ADL\":\n",
    "        emit_windows(segment, \"ADL\")\n",
    "    elif curr_label == \"FALL\":\n",
    "        emit_windows(segment, \"FALL\")\n",
    "    elif curr_label == \"POST_FALL\":\n",
    "        if include_post_fall:\n",
    "            emit_windows(segment, \"POST_FALL\")\n",
    "        else:\n",
    "            emit_windows(segment, \"FALL\")\n",
    "    \n",
    "    return np.stack(X_sub, axis=0), np.array(y_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9356847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_windows, y_windows = sliding_multi_window(X, y, fs =200,subwindow_duration=0.4, overlap=0.5,include_post_fall=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d415d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   \n",
       "ADL     306463\n",
       "FALL     25266\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_windows).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43524836",
   "metadata": {},
   "source": [
    "### Train/val/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8062655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1) First split off the test set (e.g., 20% of the data):\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X_windows,\n",
    "    y_windows,\n",
    "    test_size=0.2,\n",
    "    stratify=y_windows,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2) Now split the remaining ‘temp’ into train and val (e.g., 10% of original → 12.5% of temp):\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    test_size=0.125,            # so that val ≈ 0.125 of temp → 0.1 of total\n",
    "    stratify=y_temp,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c7aec9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   \n",
       "ADL     214524\n",
       "FALL     17686\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1fef5d",
   "metadata": {},
   "source": [
    "### Encode variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7a1ac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_val_encoded = le.transform(y_val)\n",
    "y_test_encoded = le.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2dd7821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure they are NumPy arrays\n",
    "y_train_encoded = np.array(y_train_encoded)\n",
    "y_val_encoded = np.array(y_val_encoded)\n",
    "y_test_encoded = np.array(y_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9ab8e1",
   "metadata": {},
   "source": [
    "### Encode Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d15f952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232210, 100, 9)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c852635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import Loss\n",
    "\n",
    "class SparseCategoricalFocalLoss(Loss):\n",
    "    def __init__(self, gamma=2., alpha=1., from_logits=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.from_logits = from_logits\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.int32)\n",
    "        y_true_one_hot = tf.one_hot(y_true, depth=tf.shape(y_pred)[-1])\n",
    "\n",
    "        if self.from_logits:\n",
    "            y_pred = tf.nn.softmax(y_pred)\n",
    "\n",
    "        pt = tf.reduce_sum(y_pred * y_true_one_hot, axis=-1)\n",
    "        loss = -self.alpha * tf.pow(1. - pt, self.gamma) * tf.math.log(tf.clip_by_value(pt, 1e-8, 1.0))\n",
    "        return tf.reduce_mean(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c88c7dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sovan\\Desktop\\Fall Detection\\New ilab\\ilab-group-12-1-fall-detection\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,376</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m5,376\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m24,704\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m258\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,378</span> (177.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m45,378\u001b[0m (177.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,122</span> (176.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m45,122\u001b[0m (176.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Conv1D, MaxPooling1D, BatchNormalization\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "\n",
    "# Implementation of \"LSTM-CNN Architecture for Human Activity Recognition\" by Kun Xia et al. (IEEE Access, 2020)\n",
    "# Adapted from https://github.com/quotation2520/CAGE4HAR/blob/main/models/LSTM_CNN.py\n",
    "\n",
    "## X_train_windows.shape == (n_samples, 100, 6)\n",
    "input_shape = (X_train.shape[1], X_train.shape[2]) \n",
    "num_classes = len(set(y_train_encoded))                  \n",
    "\n",
    "model_lstm_conv = Sequential([\n",
    "\n",
    "    # ——— LSTM stack ———\n",
    "    # first LSTM returns full sequence\n",
    "    LSTM(32, return_sequences=True, input_shape=input_shape),\n",
    "    # second LSTM also returns full sequence\n",
    "    LSTM(32, return_sequences=True),\n",
    "\n",
    "    # ——— 1D‐Conv + Pool ———\n",
    "    Conv1D(\n",
    "        filters=64,\n",
    "        kernel_size=3,\n",
    "        strides=2,\n",
    "        activation='relu',\n",
    "        padding='valid'   # matches PyTorch default\n",
    "    ),\n",
    "    MaxPooling1D(pool_size=2, strides=2),\n",
    "\n",
    "    # ——— second Conv block ———\n",
    "    Conv1D(\n",
    "        filters=128,\n",
    "        kernel_size=3,\n",
    "        strides=1,\n",
    "        activation='relu',\n",
    "        padding='valid'\n",
    "    ),\n",
    "\n",
    "    # ——— batch‐norm & spatial collapse ———\n",
    "    BatchNormalization(),            # normalise over feature‐axis\n",
    "    GlobalAveragePooling1D(),        # mean over time dimension\n",
    "\n",
    "    # ——— classification head ———\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model_lstm_conv.compile(\n",
    "    optimizer=Adam(1e-3),\n",
    "    loss=SparseCategoricalFocalLoss(gamma=2., alpha=1.0),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_lstm_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e6289a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m3629/3629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 74ms/step - accuracy: 0.9222 - loss: 0.0561 - val_accuracy: 0.9599 - val_loss: 0.0286\n",
      "Epoch 2/20\n",
      "\u001b[1m3629/3629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 75ms/step - accuracy: 0.9616 - loss: 0.0270 - val_accuracy: 0.9682 - val_loss: 0.0227\n",
      "Epoch 3/20\n",
      "\u001b[1m3629/3629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 74ms/step - accuracy: 0.9695 - loss: 0.0220 - val_accuracy: 0.9734 - val_loss: 0.0199\n",
      "Epoch 4/20\n",
      "\u001b[1m3629/3629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 74ms/step - accuracy: 0.9732 - loss: 0.0197 - val_accuracy: 0.9755 - val_loss: 0.0178\n",
      "Epoch 5/20\n",
      "\u001b[1m3629/3629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 74ms/step - accuracy: 0.9761 - loss: 0.0175 - val_accuracy: 0.9770 - val_loss: 0.0171\n",
      "Epoch 6/20\n",
      "\u001b[1m3629/3629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 71ms/step - accuracy: 0.9782 - loss: 0.0162 - val_accuracy: 0.9793 - val_loss: 0.0153\n",
      "Epoch 7/20\n",
      "\u001b[1m3629/3629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 64ms/step - accuracy: 0.9801 - loss: 0.0148 - val_accuracy: 0.9797 - val_loss: 0.0152\n",
      "Epoch 8/20\n",
      "\u001b[1m3629/3629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 56ms/step - accuracy: 0.9813 - loss: 0.0136 - val_accuracy: 0.9792 - val_loss: 0.0143\n",
      "Epoch 9/20\n",
      "\u001b[1m3629/3629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 58ms/step - accuracy: 0.9821 - loss: 0.0131 - val_accuracy: 0.9821 - val_loss: 0.0131\n",
      "Epoch 10/20\n",
      "\u001b[1m3629/3629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 59ms/step - accuracy: 0.9829 - loss: 0.0123 - val_accuracy: 0.9833 - val_loss: 0.0127\n",
      "Epoch 11/20\n",
      "\u001b[1m3629/3629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 58ms/step - accuracy: 0.9838 - loss: 0.0112 - val_accuracy: 0.9818 - val_loss: 0.0128\n",
      "Epoch 12/20\n",
      "\u001b[1m3629/3629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 58ms/step - accuracy: 0.9852 - loss: 0.0110 - val_accuracy: 0.9850 - val_loss: 0.0112\n",
      "Epoch 13/20\n",
      "\u001b[1m3629/3629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 57ms/step - accuracy: 0.9854 - loss: 0.0105 - val_accuracy: 0.9854 - val_loss: 0.0110\n",
      "Epoch 14/20\n",
      "\u001b[1m3629/3629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 57ms/step - accuracy: 0.9869 - loss: 0.0096 - val_accuracy: 0.9843 - val_loss: 0.0122\n",
      "Epoch 15/20\n",
      "\u001b[1m3629/3629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 58ms/step - accuracy: 0.9869 - loss: 0.0095 - val_accuracy: 0.9833 - val_loss: 0.0124\n",
      "Epoch 16/20\n",
      "\u001b[1m3629/3629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 55ms/step - accuracy: 0.9868 - loss: 0.0094 - val_accuracy: 0.9854 - val_loss: 0.0107\n",
      "Epoch 17/20\n",
      "\u001b[1m3629/3629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 54ms/step - accuracy: 0.9883 - loss: 0.0086 - val_accuracy: 0.9860 - val_loss: 0.0105\n",
      "Epoch 18/20\n",
      "\u001b[1m3629/3629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 51ms/step - accuracy: 0.9881 - loss: 0.0084 - val_accuracy: 0.9859 - val_loss: 0.0103\n",
      "Epoch 19/20\n",
      "\u001b[1m3629/3629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 57ms/step - accuracy: 0.9888 - loss: 0.0081 - val_accuracy: 0.9868 - val_loss: 0.0100\n",
      "Epoch 20/20\n",
      "\u001b[1m3629/3629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 56ms/step - accuracy: 0.9893 - loss: 0.0076 - val_accuracy: 0.9866 - val_loss: 0.0106\n"
     ]
    }
   ],
   "source": [
    "history = model_lstm_conv.fit(\n",
    "    X_train, y_train_encoded,\n",
    "    validation_data=(X_val, y_val_encoded),\n",
    "    epochs=20,\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "51a30c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (confusion_matrix, classification_report, \n",
    "                             precision_score, recall_score, f1_score)\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, label_classes=None, plot_confusion_matrix=True, plot_roc=False):\n",
    "    # Evaluate the model\n",
    "    results = model.evaluate(X_test, y_test, verbose=0)\n",
    "    metric_names = model.metrics_names\n",
    "    metrics_dict = dict(zip(metric_names, results))\n",
    "\n",
    "    print(\"Evaluation Metrics:\")\n",
    "    for name, value in metrics_dict.items():\n",
    "        print(f\"{name.capitalize()}: {value:.4f}\")\n",
    "\n",
    "    # Predict class probabilities and take argmax for predicted class\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm_percent = cm.astype('float') / cm.sum(axis=1, keepdims=True) * 100  # row-wise normalization\n",
    "\n",
    "    if plot_confusion_matrix:\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm_percent, annot=True, fmt=\".2f\", cmap='Blues',\n",
    "                    xticklabels=label_classes if label_classes else np.unique(y_test),\n",
    "                    yticklabels=label_classes if label_classes else np.unique(y_test))\n",
    "        plt.xlabel(\"Predicted Label\")\n",
    "        plt.ylabel(\"True Label\")\n",
    "        plt.title(\"Confusion Matrix (%)\")\n",
    "        plt.show()\n",
    "\n",
    "    # Classification report\n",
    "    report = classification_report(y_test, y_pred, target_names=label_classes if label_classes else None)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "    # Macro-averaged metrics across all classes\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(\"Macro Precision (sklearn): {:.4f}\".format(precision))\n",
    "    print(\"Macro Recall (sklearn): {:.4f}\".format(recall))\n",
    "    print(\"Macro F1 Score: {:.4f}\".format(f1))\n",
    "\n",
    "    # Update metrics dictionary to include sklearn metrics\n",
    "    metrics_dict.update({\n",
    "        'macro_precision': precision,\n",
    "        'macro_recall': recall,\n",
    "        'macro_f1_score': f1\n",
    "    })\n",
    "\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d89fa750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Loss: 0.0102\n",
      "Compile_metrics: 0.9866\n",
      "\u001b[1m2074/2074\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 13ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ADL       0.99      0.99      0.99     61293\n",
      "        FALL       0.90      0.93      0.91      5053\n",
      "\n",
      "    accuracy                           0.99     66346\n",
      "   macro avg       0.95      0.96      0.95     66346\n",
      "weighted avg       0.99      0.99      0.99     66346\n",
      "\n",
      "Macro Precision (sklearn): 0.9467\n",
      "Macro Recall (sklearn): 0.9600\n",
      "Macro F1 Score: 0.9532\n"
     ]
    }
   ],
   "source": [
    "label_classes = le.classes_.tolist()\n",
    "metrics = evaluate_model(model_lstm_conv, X_test, y_test_encoded, label_classes=label_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaea926d",
   "metadata": {},
   "source": [
    "### 10-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4cede8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        LSTM(32, return_sequences=True, input_shape=input_shape),\n",
    "        LSTM(32, return_sequences=True),\n",
    "        Conv1D(64, kernel_size=3, strides=2, activation='relu', padding='valid'),\n",
    "        MaxPooling1D(pool_size=2, strides=2),\n",
    "        Conv1D(128, kernel_size=3, strides=1, activation='relu', padding='valid'),\n",
    "        BatchNormalization(),\n",
    "        GlobalAveragePooling1D(),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=Adam(1e-3),\n",
    "        loss=SparseCategoricalFocalLoss(gamma=2., alpha=1.0),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcdef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1s = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train, y_train_encoded)):\n",
    "    print(f\"\\n🟦 Fold {fold+1}\")\n",
    "\n",
    "    # Split the data\n",
    "    X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "    y_tr, y_val = y_train_encoded[train_idx], y_train_encoded[val_idx]\n",
    "\n",
    "    # Create and train the model\n",
    "    model = create_model(input_shape, num_classes)\n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=20,\n",
    "        batch_size=64,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Predict\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision = precision_score(y_val, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_val, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_val, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "    print(f\"✅ Fold {fold+1} Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1s.append(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f4e213",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n📊 Mean Precision: {np.mean(fold_precisions):.4f} ± {np.std(fold_precisions):.4f}\")\n",
    "print(f\"📊 Mean Recall:    {np.mean(fold_recalls):.4f} ± {np.std(fold_recalls):.4f}\")\n",
    "print(f\"📊 Mean F1 Score:  {np.mean(fold_f1s):.4f} ± {np.std(fold_f1s):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
