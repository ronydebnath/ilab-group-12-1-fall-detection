{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2ea3f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb9ea3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../../data/raw/MobiAct_combined.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75e2198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_map = {\n",
    "    \"subject_id\": \"int16\",\n",
    "    \"trial\": \"int16\",\n",
    "    \"acc_x\": \"float32\", \"acc_y\": \"float32\", \"acc_z\": \"float32\",\n",
    "    \"gyro_x\": \"float32\",\"gyro_y\": \"float32\",\"gyro_z\": \"float32\",\n",
    "    \"azimuth\": \"float32\",\t\"pitch\": \"float32\",\t\"roll\": \"float32\",\n",
    "    \"label\": \"category\"\n",
    "}\n",
    "\n",
    "df = pd.read_csv(\n",
    "    file_path,\n",
    "    dtype=dtype_map,        # reduces memory footprint \n",
    "    engine='c')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83f459fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rel_time</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>pitch</th>\n",
       "      <th>roll</th>\n",
       "      <th>label</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>trial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1295405261000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.407311</td>\n",
       "      <td>9.614395</td>\n",
       "      <td>-2.086666</td>\n",
       "      <td>-0.844216</td>\n",
       "      <td>0.409280</td>\n",
       "      <td>0.086437</td>\n",
       "      <td>92.746895</td>\n",
       "      <td>-36.879684</td>\n",
       "      <td>-11.741077</td>\n",
       "      <td>STD</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1295410262000</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>-1.406354</td>\n",
       "      <td>9.612960</td>\n",
       "      <td>-2.084512</td>\n",
       "      <td>-0.711047</td>\n",
       "      <td>0.346971</td>\n",
       "      <td>0.076358</td>\n",
       "      <td>92.205360</td>\n",
       "      <td>-37.470173</td>\n",
       "      <td>-11.839779</td>\n",
       "      <td>STD</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1295415352000</td>\n",
       "      <td>0.010091</td>\n",
       "      <td>-1.405380</td>\n",
       "      <td>9.611498</td>\n",
       "      <td>-2.082320</td>\n",
       "      <td>-0.598953</td>\n",
       "      <td>0.093462</td>\n",
       "      <td>0.025045</td>\n",
       "      <td>91.743050</td>\n",
       "      <td>-38.090790</td>\n",
       "      <td>-11.880902</td>\n",
       "      <td>STD</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1295420307000</td>\n",
       "      <td>0.015046</td>\n",
       "      <td>-1.404432</td>\n",
       "      <td>9.610076</td>\n",
       "      <td>-2.080186</td>\n",
       "      <td>-0.128893</td>\n",
       "      <td>-0.012828</td>\n",
       "      <td>-0.002443</td>\n",
       "      <td>91.267319</td>\n",
       "      <td>-38.842915</td>\n",
       "      <td>-11.933741</td>\n",
       "      <td>STD</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1295425257000</td>\n",
       "      <td>0.019996</td>\n",
       "      <td>-1.403484</td>\n",
       "      <td>9.608654</td>\n",
       "      <td>-2.078054</td>\n",
       "      <td>0.049480</td>\n",
       "      <td>0.018326</td>\n",
       "      <td>0.016493</td>\n",
       "      <td>90.819679</td>\n",
       "      <td>-39.538643</td>\n",
       "      <td>-11.957446</td>\n",
       "      <td>STD</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16756320</th>\n",
       "      <td>10354577784000</td>\n",
       "      <td>299.969995</td>\n",
       "      <td>-0.907934</td>\n",
       "      <td>13.533889</td>\n",
       "      <td>4.335380</td>\n",
       "      <td>1.207070</td>\n",
       "      <td>-6.215859</td>\n",
       "      <td>1.962099</td>\n",
       "      <td>218.442352</td>\n",
       "      <td>-56.026966</td>\n",
       "      <td>-33.223778</td>\n",
       "      <td>WAL</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16756321</th>\n",
       "      <td>10354582775000</td>\n",
       "      <td>299.974986</td>\n",
       "      <td>-1.867024</td>\n",
       "      <td>12.331459</td>\n",
       "      <td>2.439285</td>\n",
       "      <td>0.968221</td>\n",
       "      <td>-6.103155</td>\n",
       "      <td>1.773953</td>\n",
       "      <td>220.688690</td>\n",
       "      <td>-57.077301</td>\n",
       "      <td>-31.897688</td>\n",
       "      <td>WAL</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16756322</th>\n",
       "      <td>10354588060000</td>\n",
       "      <td>299.980271</td>\n",
       "      <td>-2.924407</td>\n",
       "      <td>11.485553</td>\n",
       "      <td>0.782717</td>\n",
       "      <td>0.740674</td>\n",
       "      <td>-6.034738</td>\n",
       "      <td>1.459663</td>\n",
       "      <td>222.816406</td>\n",
       "      <td>-58.044624</td>\n",
       "      <td>-30.614605</td>\n",
       "      <td>WAL</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16756323</th>\n",
       "      <td>10354592749000</td>\n",
       "      <td>299.984960</td>\n",
       "      <td>-3.726923</td>\n",
       "      <td>11.084407</td>\n",
       "      <td>-0.258194</td>\n",
       "      <td>0.536645</td>\n",
       "      <td>-5.905845</td>\n",
       "      <td>1.027781</td>\n",
       "      <td>224.671646</td>\n",
       "      <td>-58.777103</td>\n",
       "      <td>-29.624798</td>\n",
       "      <td>WAL</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16756324</th>\n",
       "      <td>10354597768000</td>\n",
       "      <td>299.989979</td>\n",
       "      <td>-4.531702</td>\n",
       "      <td>10.794686</td>\n",
       "      <td>-1.200935</td>\n",
       "      <td>0.355524</td>\n",
       "      <td>-5.699373</td>\n",
       "      <td>0.550390</td>\n",
       "      <td>226.457153</td>\n",
       "      <td>-59.391144</td>\n",
       "      <td>-28.733915</td>\n",
       "      <td>WAL</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16756325 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp    rel_time     acc_x      acc_y     acc_z    gyro_x  \\\n",
       "0          1295405261000    0.000000 -1.407311   9.614395 -2.086666 -0.844216   \n",
       "1          1295410262000    0.005001 -1.406354   9.612960 -2.084512 -0.711047   \n",
       "2          1295415352000    0.010091 -1.405380   9.611498 -2.082320 -0.598953   \n",
       "3          1295420307000    0.015046 -1.404432   9.610076 -2.080186 -0.128893   \n",
       "4          1295425257000    0.019996 -1.403484   9.608654 -2.078054  0.049480   \n",
       "...                  ...         ...       ...        ...       ...       ...   \n",
       "16756320  10354577784000  299.969995 -0.907934  13.533889  4.335380  1.207070   \n",
       "16756321  10354582775000  299.974986 -1.867024  12.331459  2.439285  0.968221   \n",
       "16756322  10354588060000  299.980271 -2.924407  11.485553  0.782717  0.740674   \n",
       "16756323  10354592749000  299.984960 -3.726923  11.084407 -0.258194  0.536645   \n",
       "16756324  10354597768000  299.989979 -4.531702  10.794686 -1.200935  0.355524   \n",
       "\n",
       "            gyro_y    gyro_z     azimuth      pitch       roll label  \\\n",
       "0         0.409280  0.086437   92.746895 -36.879684 -11.741077   STD   \n",
       "1         0.346971  0.076358   92.205360 -37.470173 -11.839779   STD   \n",
       "2         0.093462  0.025045   91.743050 -38.090790 -11.880902   STD   \n",
       "3        -0.012828 -0.002443   91.267319 -38.842915 -11.933741   STD   \n",
       "4         0.018326  0.016493   90.819679 -39.538643 -11.957446   STD   \n",
       "...            ...       ...         ...        ...        ...   ...   \n",
       "16756320 -6.215859  1.962099  218.442352 -56.026966 -33.223778   WAL   \n",
       "16756321 -6.103155  1.773953  220.688690 -57.077301 -31.897688   WAL   \n",
       "16756322 -6.034738  1.459663  222.816406 -58.044624 -30.614605   WAL   \n",
       "16756323 -5.905845  1.027781  224.671646 -58.777103 -29.624798   WAL   \n",
       "16756324 -5.699373  0.550390  226.457153 -59.391144 -28.733915   WAL   \n",
       "\n",
       "          subject_id  trial  \n",
       "0                 10      1  \n",
       "1                 10      1  \n",
       "2                 10      1  \n",
       "3                 10      1  \n",
       "4                 10      1  \n",
       "...              ...    ...  \n",
       "16756320           9      1  \n",
       "16756321           9      1  \n",
       "16756322           9      1  \n",
       "16756323           9      1  \n",
       "16756324           9      1  \n",
       "\n",
       "[16756325 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b078cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fall_labels = ['BSC', 'FKL', 'SDL', 'FOL']\n",
    "post_fall = ['LYI']\n",
    "\n",
    "df['fall_label'] = df['label'].apply(\n",
    "    lambda x: 'FALL' if x in fall_labels else ('POST_FALL' if x in post_fall else 'ADL')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8db88954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal as signal\n",
    "def apply_low_pass_filter(data, cutoff=3, fs=10, order=4):\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = signal.butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    df_filtered = data.copy()\n",
    "    for col in ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z']:\n",
    "        df_filtered[col] = signal.filtfilt(b, a, data[col])\n",
    "    return df_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb065bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = apply_low_pass_filter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b106fd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "sensor_cols = ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z', 'azimuth','pitch','roll']\n",
    "df[sensor_cols] = scaler.fit_transform(df[sensor_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ced70b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train subjects: {np.int16(2), np.int16(3), np.int16(4), np.int16(7), np.int16(8), np.int16(11), np.int16(12), np.int16(14), np.int16(15), np.int16(16), np.int16(18), np.int16(20), np.int16(21), np.int16(22), np.int16(23), np.int16(25), np.int16(28), np.int16(30), np.int16(31), np.int16(32), np.int16(33), np.int16(34), np.int16(35), np.int16(36), np.int16(38), np.int16(39), np.int16(40), np.int16(42), np.int16(43), np.int16(44), np.int16(45), np.int16(47), np.int16(48), np.int16(49), np.int16(50), np.int16(51), np.int16(52), np.int16(54), np.int16(56), np.int16(57), np.int16(58), np.int16(61), np.int16(63), np.int16(64), np.int16(66), np.int16(67)}\n",
      "Val subjects: {np.int16(59), np.int16(9), np.int16(19), np.int16(53), np.int16(55), np.int16(24), np.int16(27)}\n",
      "Test subjects: {np.int16(1), np.int16(65), np.int16(37), np.int16(5), np.int16(6), np.int16(41), np.int16(10), np.int16(13), np.int16(46), np.int16(17), np.int16(26), np.int16(60), np.int16(29), np.int16(62)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# Get your subject group array\n",
    "groups = df['subject_id'].values\n",
    "\n",
    "# 1. Split off test subjects\n",
    "gss1 = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "trainval_idx, test_idx = next(gss1.split(df, df['label'], groups=groups))\n",
    "\n",
    "trainval_subjects = df.iloc[trainval_idx]['subject_id'].unique()\n",
    "test_subjects = df.iloc[test_idx]['subject_id'].unique()\n",
    "\n",
    "df_trainval = df[df['subject_id'].isin(trainval_subjects)].copy()\n",
    "df_test     = df[df['subject_id'].isin(test_subjects)].copy()\n",
    "\n",
    "# 2. Split val subjects from trainval\n",
    "groups_trainval = df_trainval['subject_id'].values\n",
    "gss2 = GroupShuffleSplit(n_splits=1, test_size=0.125, random_state=42)\n",
    "train_idx, val_idx = next(gss2.split(df_trainval, df_trainval['label'], groups=groups_trainval))\n",
    "\n",
    "train_subjects = df_trainval.iloc[train_idx]['subject_id'].unique()\n",
    "val_subjects   = df_trainval.iloc[val_idx]['subject_id'].unique()\n",
    "\n",
    "df_train = df_trainval[df_trainval['subject_id'].isin(train_subjects)].copy()\n",
    "df_val   = df_trainval[df_trainval['subject_id'].isin(val_subjects)].copy()\n",
    "\n",
    "print(\"Train subjects:\", set(train_subjects))\n",
    "print(\"Val subjects:\", set(val_subjects))\n",
    "print(\"Test subjects:\", set(test_subjects))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3cfe1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[sensor_cols]\n",
    "X_val = df_val[sensor_cols]\n",
    "X_test = df_test[sensor_cols]\n",
    "\n",
    "y_train = df_train['fall_label']\n",
    "y_val= df_val['fall_label']\n",
    "y_test = df_test['fall_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57572789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>pitch</th>\n",
       "      <th>roll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5909</th>\n",
       "      <td>0.630989</td>\n",
       "      <td>0.365547</td>\n",
       "      <td>0.290961</td>\n",
       "      <td>-0.845714</td>\n",
       "      <td>0.544943</td>\n",
       "      <td>0.021701</td>\n",
       "      <td>-1.438502</td>\n",
       "      <td>0.827826</td>\n",
       "      <td>2.419112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5910</th>\n",
       "      <td>0.102306</td>\n",
       "      <td>0.644049</td>\n",
       "      <td>0.072772</td>\n",
       "      <td>-1.157569</td>\n",
       "      <td>0.752584</td>\n",
       "      <td>0.035295</td>\n",
       "      <td>-1.437745</td>\n",
       "      <td>0.822384</td>\n",
       "      <td>2.415175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5911</th>\n",
       "      <td>0.251167</td>\n",
       "      <td>0.557365</td>\n",
       "      <td>0.143087</td>\n",
       "      <td>-1.054991</td>\n",
       "      <td>0.703504</td>\n",
       "      <td>0.025325</td>\n",
       "      <td>-1.436687</td>\n",
       "      <td>0.816758</td>\n",
       "      <td>2.408868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5912</th>\n",
       "      <td>0.340463</td>\n",
       "      <td>0.502126</td>\n",
       "      <td>0.188847</td>\n",
       "      <td>-1.003387</td>\n",
       "      <td>0.684684</td>\n",
       "      <td>0.021753</td>\n",
       "      <td>-1.435659</td>\n",
       "      <td>0.811031</td>\n",
       "      <td>2.402353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5913</th>\n",
       "      <td>0.242279</td>\n",
       "      <td>0.551189</td>\n",
       "      <td>0.152063</td>\n",
       "      <td>-1.084589</td>\n",
       "      <td>0.737607</td>\n",
       "      <td>0.031794</td>\n",
       "      <td>-1.434582</td>\n",
       "      <td>0.805163</td>\n",
       "      <td>2.394990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16696321</th>\n",
       "      <td>0.094151</td>\n",
       "      <td>0.216117</td>\n",
       "      <td>0.895978</td>\n",
       "      <td>1.410470</td>\n",
       "      <td>-0.890444</td>\n",
       "      <td>1.176046</td>\n",
       "      <td>0.661639</td>\n",
       "      <td>-0.353977</td>\n",
       "      <td>-0.138863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16696322</th>\n",
       "      <td>-0.018138</td>\n",
       "      <td>0.239386</td>\n",
       "      <td>1.012633</td>\n",
       "      <td>1.296096</td>\n",
       "      <td>-0.795988</td>\n",
       "      <td>1.282239</td>\n",
       "      <td>0.663706</td>\n",
       "      <td>-0.357465</td>\n",
       "      <td>-0.126698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16696323</th>\n",
       "      <td>0.071032</td>\n",
       "      <td>0.468271</td>\n",
       "      <td>1.393800</td>\n",
       "      <td>1.366662</td>\n",
       "      <td>-0.821939</td>\n",
       "      <td>1.544532</td>\n",
       "      <td>0.665571</td>\n",
       "      <td>-0.360720</td>\n",
       "      <td>-0.113490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16696324</th>\n",
       "      <td>0.145940</td>\n",
       "      <td>0.819790</td>\n",
       "      <td>1.897802</td>\n",
       "      <td>1.422104</td>\n",
       "      <td>-0.822488</td>\n",
       "      <td>1.792295</td>\n",
       "      <td>0.666245</td>\n",
       "      <td>-0.361143</td>\n",
       "      <td>-0.099987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16696325</th>\n",
       "      <td>-0.658568</td>\n",
       "      <td>0.570295</td>\n",
       "      <td>1.571646</td>\n",
       "      <td>0.661952</td>\n",
       "      <td>-0.335581</td>\n",
       "      <td>1.338744</td>\n",
       "      <td>0.666646</td>\n",
       "      <td>-0.360869</td>\n",
       "      <td>-0.086314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11248316 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             acc_x     acc_y     acc_z    gyro_x    gyro_y    gyro_z  \\\n",
       "5909      0.630989  0.365547  0.290961 -0.845714  0.544943  0.021701   \n",
       "5910      0.102306  0.644049  0.072772 -1.157569  0.752584  0.035295   \n",
       "5911      0.251167  0.557365  0.143087 -1.054991  0.703504  0.025325   \n",
       "5912      0.340463  0.502126  0.188847 -1.003387  0.684684  0.021753   \n",
       "5913      0.242279  0.551189  0.152063 -1.084589  0.737607  0.031794   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "16696321  0.094151  0.216117  0.895978  1.410470 -0.890444  1.176046   \n",
       "16696322 -0.018138  0.239386  1.012633  1.296096 -0.795988  1.282239   \n",
       "16696323  0.071032  0.468271  1.393800  1.366662 -0.821939  1.544532   \n",
       "16696324  0.145940  0.819790  1.897802  1.422104 -0.822488  1.792295   \n",
       "16696325 -0.658568  0.570295  1.571646  0.661952 -0.335581  1.338744   \n",
       "\n",
       "           azimuth     pitch      roll  \n",
       "5909     -1.438502  0.827826  2.419112  \n",
       "5910     -1.437745  0.822384  2.415175  \n",
       "5911     -1.436687  0.816758  2.408868  \n",
       "5912     -1.435659  0.811031  2.402353  \n",
       "5913     -1.434582  0.805163  2.394990  \n",
       "...            ...       ...       ...  \n",
       "16696321  0.661639 -0.353977 -0.138863  \n",
       "16696322  0.663706 -0.357465 -0.126698  \n",
       "16696323  0.665571 -0.360720 -0.113490  \n",
       "16696324  0.666245 -0.361143 -0.099987  \n",
       "16696325  0.666646 -0.360869 -0.086314  \n",
       "\n",
       "[11248316 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c7aec9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fall_label\n",
       "ADL          10279606\n",
       "POST_FALL      711873\n",
       "FALL           256837\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f09d93b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fall_label\n",
       "ADL          1735914\n",
       "POST_FALL      95726\n",
       "FALL           34540\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1fef5d",
   "metadata": {},
   "source": [
    "### Segment into Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72814fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_cols = ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z', 'azimuth', 'pitch', 'roll']\n",
    "\n",
    "from typing import Tuple, List\n",
    "\n",
    "def sliding_multi_window(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    fs: int = 200,\n",
    "    subwindow_duration: float = 0.2,\n",
    "    overlap: float = 0.5,\n",
    "    include_post_fall: bool = True\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Implements label-based main windows with fixed-size, overlapping sub-windows.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray, shape (n_samples, n_features)\n",
    "        Time-series sensor data (e.g., acc_x, acc_y, ..., gyro_z).\n",
    "    y : np.ndarray, shape (n_samples,)\n",
    "        Frame-level labels: 'ADL', 'FALL', 'POST_FALL', etc.\n",
    "    fs : int\n",
    "        Sampling rate in Hz (e.g., 200).\n",
    "    subwindow_duration : float\n",
    "        Duration of each sub-window in seconds (e.g., 0.2).\n",
    "    overlap : float\n",
    "        Fractional overlap between sub-windows (0 to <1, e.g., 0.5 for 50%).\n",
    "    include_post_fall : bool\n",
    "        If True, emits 'POST_FALL' windows; if False, merges POST_FALL into 'FALL'.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X_sub : np.ndarray, shape (n_subwindows, window_size, n_features)\n",
    "        Array of all extracted sub-windows.\n",
    "    y_sub : np.ndarray, shape (n_subwindows,)\n",
    "        Corresponding labels for each sub-window.\n",
    "    \"\"\"\n",
    "    # Compute window parameters\n",
    "    window_size = int(fs * subwindow_duration)\n",
    "    step_size = int(window_size * (1 - overlap))\n",
    "    if step_size < 1:\n",
    "        raise ValueError(\"Overlap too large: step size <1 sample.\")\n",
    "    \n",
    "    # Ensure proper indexing\n",
    "    X_arr = np.asarray(X)\n",
    "    y_arr = np.asarray(y)\n",
    "    \n",
    "    X_sub, y_sub = [], []\n",
    "    \n",
    "    # Helper to slice sub-windows within a main segment\n",
    "    def emit_windows(segment: np.ndarray, label: str):\n",
    "        for start in range(0, len(segment) - window_size + 1, step_size):\n",
    "            end = start + window_size\n",
    "            X_sub.append(segment[start:end])\n",
    "            y_sub.append(label)\n",
    "    \n",
    "    # Find contiguous main windows by label\n",
    "    curr_label = y_arr[0]\n",
    "    seg_start = 0\n",
    "    for i in range(1, len(y_arr)):\n",
    "        if y_arr[i] != curr_label:\n",
    "            segment = X_arr[seg_start:i]\n",
    "            if curr_label == \"ADL\":\n",
    "                emit_windows(segment, \"ADL\")\n",
    "            elif curr_label == \"FALL\":\n",
    "                emit_windows(segment, \"FALL\")\n",
    "            elif curr_label == \"POST_FALL\":\n",
    "                if include_post_fall:\n",
    "                    emit_windows(segment, \"POST_FALL\")\n",
    "                else:\n",
    "                    emit_windows(segment, \"FALL\")\n",
    "            # start next main window\n",
    "            seg_start = i\n",
    "            curr_label = y_arr[i]\n",
    "    \n",
    "    # Handle the last main window\n",
    "    segment = X_arr[seg_start:]\n",
    "    if curr_label == \"ADL\":\n",
    "        emit_windows(segment, \"ADL\")\n",
    "    elif curr_label == \"FALL\":\n",
    "        emit_windows(segment, \"FALL\")\n",
    "    elif curr_label == \"POST_FALL\":\n",
    "        if include_post_fall:\n",
    "            emit_windows(segment, \"POST_FALL\")\n",
    "        else:\n",
    "            emit_windows(segment, \"FALL\")\n",
    "    \n",
    "    return np.stack(X_sub, axis=0), np.array(y_sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "932ff65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_windows, y_train_windows = sliding_multi_window(X_train, y_train, fs =200,subwindow_duration=0.2, overlap=0.4,include_post_fall=False)\n",
    "X_val_windows, y_val_windows = sliding_multi_window(X_val, y_val, fs =200,subwindow_duration=0.2, overlap=0.4,include_post_fall=False)\n",
    "X_test_windows, y_test_windows = sliding_multi_window(X_test, y_test, fs =200,subwindow_duration=0.2, overlap=0.4,include_post_fall=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "afaa816d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   \n",
       "ADL     427687\n",
       "FALL     39142\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train_windows).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a7a1ac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train_windows)\n",
    "y_val_encoded = le.transform(y_val_windows)\n",
    "y_test_encoded = le.transform(y_test_windows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e2dd7821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure they are NumPy arrays\n",
    "y_train_encoded = np.array(y_train_encoded)\n",
    "y_val_encoded = np.array(y_val_encoded)\n",
    "y_test_encoded = np.array(y_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9ab8e1",
   "metadata": {},
   "source": [
    "### Encode Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1d15f952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_windows.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3453f162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import Loss\n",
    "\n",
    "class SparseCategoricalFocalLoss(Loss):\n",
    "    def __init__(self, gamma=2., alpha=1., from_logits=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.from_logits = from_logits\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.int32)\n",
    "        y_true_one_hot = tf.one_hot(y_true, depth=tf.shape(y_pred)[-1])\n",
    "\n",
    "        if self.from_logits:\n",
    "            y_pred = tf.nn.softmax(y_pred)\n",
    "\n",
    "        pt = tf.reduce_sum(y_pred * y_true_one_hot, axis=-1)\n",
    "        loss = -self.alpha * tf.pow(1. - pt, self.gamma) * tf.math.log(tf.clip_by_value(pt, 1e-8, 1.0))\n",
    "        return tf.reduce_mean(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c852635f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sovan\\Desktop\\Fall Detection\\New ilab\\ilab-group-12-1-fall-detection\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,376</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_4      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m5,376\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_4      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m258\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,898</span> (97.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,898\u001b[0m (97.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,642</span> (96.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24,642\u001b[0m (96.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Conv1D, MaxPooling1D, BatchNormalization\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "\n",
    "# Implementation of \"LSTM-CNN Architecture for Human Activity Recognition\" by Kun Xia et al. (IEEE Access, 2020)\n",
    "# Adapted from https://github.com/quotation2520/CAGE4HAR/blob/main/models/LSTM_CNN.py\n",
    "\n",
    "## X_train_windows.shape == (n_samples, 100, 6)\n",
    "input_shape = (X_train_windows.shape[1], X_train_windows.shape[2]) \n",
    "num_classes = len(set(y_train_encoded))                  \n",
    "\n",
    "model_lstm_conv = Sequential([\n",
    "\n",
    "    # ——— LSTM stack ———\n",
    "    # first LSTM returns full sequence\n",
    "    LSTM(32, return_sequences=True, input_shape=input_shape),\n",
    "    # second LSTM also returns full sequence\n",
    "    LSTM(32, return_sequences=True),\n",
    "\n",
    "    # ——— 1D‐Conv + Pool ———\n",
    "    Conv1D(\n",
    "        filters=64,\n",
    "        kernel_size=1,\n",
    "        strides=2,\n",
    "        activation='relu',\n",
    "        padding='valid'   # matches PyTorch default\n",
    "    ),\n",
    "    MaxPooling1D(pool_size=2, strides=2),\n",
    "\n",
    "    # ——— second Conv block ———\n",
    "    Conv1D(\n",
    "        filters=128,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        activation='relu',\n",
    "        padding='valid'\n",
    "    ),\n",
    "\n",
    "    # ——— batch‐norm & spatial collapse ———\n",
    "    BatchNormalization(),            # normalise over feature‐axis\n",
    "    GlobalAveragePooling1D(),        # mean over time dimension\n",
    "\n",
    "    # ——— classification head ———\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model_lstm_conv.compile(\n",
    "    optimizer=Adam(1e-3),\n",
    "    loss=SparseCategoricalFocalLoss(gamma=2., alpha=1.0),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_lstm_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0c05daa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "817510a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights to handle imbalance\n",
    "y_train_array = np.array(y_train_encoded)\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train_array),\n",
    "    y=y_train_array\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cb7b333b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: np.float64(0.545760100260237), 1: np.float64(5.963274743242553)}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6289a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m7295/7295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 34ms/step - accuracy: 0.9374 - loss: 0.0453 - val_accuracy: 0.9328 - val_loss: 0.0532\n",
      "Epoch 2/20\n",
      "\u001b[1m7295/7295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 32ms/step - accuracy: 0.9691 - loss: 0.0237 - val_accuracy: 0.9166 - val_loss: 0.1115\n",
      "Epoch 3/20\n",
      "\u001b[1m7295/7295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 32ms/step - accuracy: 0.9763 - loss: 0.0189 - val_accuracy: 0.9224 - val_loss: 0.0673\n",
      "Epoch 4/20\n",
      "\u001b[1m7295/7295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 31ms/step - accuracy: 0.9785 - loss: 0.0169 - val_accuracy: 0.9294 - val_loss: 0.0775\n",
      "Epoch 5/20\n",
      "\u001b[1m7295/7295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 26ms/step - accuracy: 0.9805 - loss: 0.0151 - val_accuracy: 0.9233 - val_loss: 0.0806\n",
      "Epoch 6/20\n",
      "\u001b[1m7295/7295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 26ms/step - accuracy: 0.9827 - loss: 0.0136 - val_accuracy: 0.9304 - val_loss: 0.0949\n",
      "Epoch 7/20\n",
      "\u001b[1m7295/7295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 25ms/step - accuracy: 0.9835 - loss: 0.0128 - val_accuracy: 0.9253 - val_loss: 0.0873\n",
      "Epoch 8/20\n",
      "\u001b[1m7295/7295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 25ms/step - accuracy: 0.9841 - loss: 0.0120 - val_accuracy: 0.9265 - val_loss: 0.0985\n",
      "Epoch 9/20\n",
      "\u001b[1m7295/7295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 25ms/step - accuracy: 0.9858 - loss: 0.0111 - val_accuracy: 0.9270 - val_loss: 0.0990\n",
      "Epoch 10/20\n",
      "\u001b[1m7295/7295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 25ms/step - accuracy: 0.9864 - loss: 0.0104 - val_accuracy: 0.9276 - val_loss: 0.0879\n",
      "Epoch 11/20\n",
      "\u001b[1m7295/7295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 25ms/step - accuracy: 0.9869 - loss: 0.0101 - val_accuracy: 0.9264 - val_loss: 0.0952\n",
      "Epoch 12/20\n",
      "\u001b[1m7295/7295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27386s\u001b[0m 4s/step - accuracy: 0.9878 - loss: 0.0095 - val_accuracy: 0.9281 - val_loss: 0.1140\n",
      "Epoch 13/20\n",
      "\u001b[1m7295/7295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 23ms/step - accuracy: 0.9880 - loss: 0.0092 - val_accuracy: 0.9301 - val_loss: 0.1067\n",
      "Epoch 14/20\n",
      "\u001b[1m7295/7295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 27ms/step - accuracy: 0.9885 - loss: 0.0088 - val_accuracy: 0.9290 - val_loss: 0.1062\n",
      "Epoch 15/20\n",
      "\u001b[1m7295/7295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 25ms/step - accuracy: 0.9892 - loss: 0.0084 - val_accuracy: 0.9258 - val_loss: 0.1304\n",
      "Epoch 16/20\n",
      "\u001b[1m7295/7295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 25ms/step - accuracy: 0.9894 - loss: 0.0083 - val_accuracy: 0.9250 - val_loss: 0.1049\n",
      "Epoch 17/20\n",
      "\u001b[1m7295/7295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 27ms/step - accuracy: 0.9896 - loss: 0.0079 - val_accuracy: 0.9222 - val_loss: 0.1184\n",
      "Epoch 18/20\n",
      "\u001b[1m7295/7295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 25ms/step - accuracy: 0.9904 - loss: 0.0076 - val_accuracy: 0.9326 - val_loss: 0.0788\n",
      "Epoch 19/20\n",
      "\u001b[1m7295/7295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 26ms/step - accuracy: 0.9906 - loss: 0.0072 - val_accuracy: 0.9312 - val_loss: 0.0996\n",
      "Epoch 20/20\n",
      "\u001b[1m7295/7295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 26ms/step - accuracy: 0.9907 - loss: 0.0071 - val_accuracy: 0.9281 - val_loss: 0.1147\n"
     ]
    }
   ],
   "source": [
    "history = model_lstm_conv.fit(\n",
    "    X_train_windows, y_train_encoded,\n",
    "    validation_data=(X_val_windows, y_val_encoded),\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "51a30c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (confusion_matrix, classification_report, \n",
    "                             precision_score, recall_score, f1_score)\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, label_classes=None, plot_confusion_matrix=True, plot_roc=False):\n",
    "    # Evaluate the model\n",
    "    results = model.evaluate(X_test, y_test, verbose=0)\n",
    "    metric_names = model.metrics_names\n",
    "    metrics_dict = dict(zip(metric_names, results))\n",
    "\n",
    "    print(\"Evaluation Metrics:\")\n",
    "    for name, value in metrics_dict.items():\n",
    "        print(f\"{name.capitalize()}: {value:.4f}\")\n",
    "\n",
    "    # Predict class probabilities and take argmax for predicted class\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    if plot_confusion_matrix:\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues',\n",
    "                    xticklabels=label_classes if label_classes else np.unique(y_test),\n",
    "                    yticklabels=label_classes if label_classes else np.unique(y_test))\n",
    "        plt.xlabel(\"Predicted Label\")\n",
    "        plt.ylabel(\"True Label\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.show()\n",
    "\n",
    "    # Classification report\n",
    "    report = classification_report(y_test, y_pred, target_names=label_classes if label_classes else None)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "    # Macro-averaged metrics across all classes\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(\"Macro Precision (sklearn): {:.4f}\".format(precision))\n",
    "    print(\"Macro Recall (sklearn): {:.4f}\".format(recall))\n",
    "    print(\"Macro F1 Score: {:.4f}\".format(f1))\n",
    "\n",
    "    # Update metrics dictionary to include sklearn metrics\n",
    "    metrics_dict.update({\n",
    "        'macro_precision': precision,\n",
    "        'macro_recall': recall,\n",
    "        'macro_f1_score': f1\n",
    "    })\n",
    "\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d89fa750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Loss: 0.0454\n",
      "Compile_metrics: 0.9655\n",
      "\u001b[1m4725/4725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ADL       0.98      0.98      0.98    139954\n",
      "        FALL       0.77      0.76      0.77     11244\n",
      "\n",
      "    accuracy                           0.97    151198\n",
      "   macro avg       0.88      0.87      0.87    151198\n",
      "weighted avg       0.97      0.97      0.97    151198\n",
      "\n",
      "Macro Precision (sklearn): 0.8769\n",
      "Macro Recall (sklearn): 0.8703\n",
      "Macro F1 Score: 0.8736\n"
     ]
    }
   ],
   "source": [
    "label_classes = le.classes_.tolist()\n",
    "metrics = evaluate_model(model_lstm_conv, X_test_windows, y_test_encoded, label_classes=label_classes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
