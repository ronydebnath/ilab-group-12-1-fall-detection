{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2ea3f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb9ea3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../../data/raw/MobiAct_combined.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75e2198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_map = {\n",
    "    \"subject_id\": \"int16\",\n",
    "    \"trial\": \"int16\",\n",
    "    \"acc_x\": \"float32\", \"acc_y\": \"float32\", \"acc_z\": \"float32\",\n",
    "    \"gyro_x\": \"float32\",\"gyro_y\": \"float32\",\"gyro_z\": \"float32\",\n",
    "    \"azimuth\": \"float32\",\t\"pitch\": \"float32\",\t\"roll\": \"float32\",\n",
    "    \"label\": \"category\"\n",
    "}\n",
    "\n",
    "df = pd.read_csv(\n",
    "    file_path,\n",
    "    dtype=dtype_map,        # reduces memory footprint \n",
    "    engine='c')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83f459fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rel_time</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>pitch</th>\n",
       "      <th>roll</th>\n",
       "      <th>label</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>trial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1295405261000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.407311</td>\n",
       "      <td>9.614395</td>\n",
       "      <td>-2.086666</td>\n",
       "      <td>-0.844216</td>\n",
       "      <td>0.409280</td>\n",
       "      <td>0.086437</td>\n",
       "      <td>92.746895</td>\n",
       "      <td>-36.879684</td>\n",
       "      <td>-11.741077</td>\n",
       "      <td>STD</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1295410262000</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>-1.406354</td>\n",
       "      <td>9.612960</td>\n",
       "      <td>-2.084512</td>\n",
       "      <td>-0.711047</td>\n",
       "      <td>0.346971</td>\n",
       "      <td>0.076358</td>\n",
       "      <td>92.205360</td>\n",
       "      <td>-37.470173</td>\n",
       "      <td>-11.839779</td>\n",
       "      <td>STD</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1295415352000</td>\n",
       "      <td>0.010091</td>\n",
       "      <td>-1.405380</td>\n",
       "      <td>9.611498</td>\n",
       "      <td>-2.082320</td>\n",
       "      <td>-0.598953</td>\n",
       "      <td>0.093462</td>\n",
       "      <td>0.025045</td>\n",
       "      <td>91.743050</td>\n",
       "      <td>-38.090790</td>\n",
       "      <td>-11.880902</td>\n",
       "      <td>STD</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1295420307000</td>\n",
       "      <td>0.015046</td>\n",
       "      <td>-1.404432</td>\n",
       "      <td>9.610076</td>\n",
       "      <td>-2.080186</td>\n",
       "      <td>-0.128893</td>\n",
       "      <td>-0.012828</td>\n",
       "      <td>-0.002443</td>\n",
       "      <td>91.267319</td>\n",
       "      <td>-38.842915</td>\n",
       "      <td>-11.933741</td>\n",
       "      <td>STD</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1295425257000</td>\n",
       "      <td>0.019996</td>\n",
       "      <td>-1.403484</td>\n",
       "      <td>9.608654</td>\n",
       "      <td>-2.078054</td>\n",
       "      <td>0.049480</td>\n",
       "      <td>0.018326</td>\n",
       "      <td>0.016493</td>\n",
       "      <td>90.819679</td>\n",
       "      <td>-39.538643</td>\n",
       "      <td>-11.957446</td>\n",
       "      <td>STD</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16756320</th>\n",
       "      <td>10354577784000</td>\n",
       "      <td>299.969995</td>\n",
       "      <td>-0.907934</td>\n",
       "      <td>13.533889</td>\n",
       "      <td>4.335380</td>\n",
       "      <td>1.207070</td>\n",
       "      <td>-6.215859</td>\n",
       "      <td>1.962099</td>\n",
       "      <td>218.442352</td>\n",
       "      <td>-56.026966</td>\n",
       "      <td>-33.223778</td>\n",
       "      <td>WAL</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16756321</th>\n",
       "      <td>10354582775000</td>\n",
       "      <td>299.974986</td>\n",
       "      <td>-1.867024</td>\n",
       "      <td>12.331459</td>\n",
       "      <td>2.439285</td>\n",
       "      <td>0.968221</td>\n",
       "      <td>-6.103155</td>\n",
       "      <td>1.773953</td>\n",
       "      <td>220.688690</td>\n",
       "      <td>-57.077301</td>\n",
       "      <td>-31.897688</td>\n",
       "      <td>WAL</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16756322</th>\n",
       "      <td>10354588060000</td>\n",
       "      <td>299.980271</td>\n",
       "      <td>-2.924407</td>\n",
       "      <td>11.485553</td>\n",
       "      <td>0.782717</td>\n",
       "      <td>0.740674</td>\n",
       "      <td>-6.034738</td>\n",
       "      <td>1.459663</td>\n",
       "      <td>222.816406</td>\n",
       "      <td>-58.044624</td>\n",
       "      <td>-30.614605</td>\n",
       "      <td>WAL</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16756323</th>\n",
       "      <td>10354592749000</td>\n",
       "      <td>299.984960</td>\n",
       "      <td>-3.726923</td>\n",
       "      <td>11.084407</td>\n",
       "      <td>-0.258194</td>\n",
       "      <td>0.536645</td>\n",
       "      <td>-5.905845</td>\n",
       "      <td>1.027781</td>\n",
       "      <td>224.671646</td>\n",
       "      <td>-58.777103</td>\n",
       "      <td>-29.624798</td>\n",
       "      <td>WAL</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16756324</th>\n",
       "      <td>10354597768000</td>\n",
       "      <td>299.989979</td>\n",
       "      <td>-4.531702</td>\n",
       "      <td>10.794686</td>\n",
       "      <td>-1.200935</td>\n",
       "      <td>0.355524</td>\n",
       "      <td>-5.699373</td>\n",
       "      <td>0.550390</td>\n",
       "      <td>226.457153</td>\n",
       "      <td>-59.391144</td>\n",
       "      <td>-28.733915</td>\n",
       "      <td>WAL</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16756325 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp    rel_time     acc_x      acc_y     acc_z    gyro_x  \\\n",
       "0          1295405261000    0.000000 -1.407311   9.614395 -2.086666 -0.844216   \n",
       "1          1295410262000    0.005001 -1.406354   9.612960 -2.084512 -0.711047   \n",
       "2          1295415352000    0.010091 -1.405380   9.611498 -2.082320 -0.598953   \n",
       "3          1295420307000    0.015046 -1.404432   9.610076 -2.080186 -0.128893   \n",
       "4          1295425257000    0.019996 -1.403484   9.608654 -2.078054  0.049480   \n",
       "...                  ...         ...       ...        ...       ...       ...   \n",
       "16756320  10354577784000  299.969995 -0.907934  13.533889  4.335380  1.207070   \n",
       "16756321  10354582775000  299.974986 -1.867024  12.331459  2.439285  0.968221   \n",
       "16756322  10354588060000  299.980271 -2.924407  11.485553  0.782717  0.740674   \n",
       "16756323  10354592749000  299.984960 -3.726923  11.084407 -0.258194  0.536645   \n",
       "16756324  10354597768000  299.989979 -4.531702  10.794686 -1.200935  0.355524   \n",
       "\n",
       "            gyro_y    gyro_z     azimuth      pitch       roll label  \\\n",
       "0         0.409280  0.086437   92.746895 -36.879684 -11.741077   STD   \n",
       "1         0.346971  0.076358   92.205360 -37.470173 -11.839779   STD   \n",
       "2         0.093462  0.025045   91.743050 -38.090790 -11.880902   STD   \n",
       "3        -0.012828 -0.002443   91.267319 -38.842915 -11.933741   STD   \n",
       "4         0.018326  0.016493   90.819679 -39.538643 -11.957446   STD   \n",
       "...            ...       ...         ...        ...        ...   ...   \n",
       "16756320 -6.215859  1.962099  218.442352 -56.026966 -33.223778   WAL   \n",
       "16756321 -6.103155  1.773953  220.688690 -57.077301 -31.897688   WAL   \n",
       "16756322 -6.034738  1.459663  222.816406 -58.044624 -30.614605   WAL   \n",
       "16756323 -5.905845  1.027781  224.671646 -58.777103 -29.624798   WAL   \n",
       "16756324 -5.699373  0.550390  226.457153 -59.391144 -28.733915   WAL   \n",
       "\n",
       "          subject_id  trial  \n",
       "0                 10      1  \n",
       "1                 10      1  \n",
       "2                 10      1  \n",
       "3                 10      1  \n",
       "4                 10      1  \n",
       "...              ...    ...  \n",
       "16756320           9      1  \n",
       "16756321           9      1  \n",
       "16756322           9      1  \n",
       "16756323           9      1  \n",
       "16756324           9      1  \n",
       "\n",
       "[16756325 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b078cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fall_labels = ['BSC', 'FKL', 'SDL', 'FOL']\n",
    "post_fall = ['LYI']\n",
    "\n",
    "df['fall_label'] = df['label'].apply(\n",
    "    lambda x: 'FALL' if x in fall_labels else ('POST_FALL' if x in post_fall else 'ADL')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8db88954",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy.signal as signal\n",
    "def apply_low_pass_filter(data, cutoff=3, fs=10, order=4):\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = signal.butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    df_filtered = data.copy()\n",
    "    for col in ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z']:\n",
    "        df_filtered[col] = signal.filtfilt(b, a, data[col])\n",
    "    return df_filtered\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb065bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = apply_low_pass_filter(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b106fd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "sensor_cols = ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z', 'azimuth', 'pitch', 'roll']\n",
    "df[sensor_cols] = scaler.fit_transform(df[sensor_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ced70b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train subjects: {np.int16(2), np.int16(3), np.int16(4), np.int16(7), np.int16(8), np.int16(11), np.int16(12), np.int16(14), np.int16(15), np.int16(16), np.int16(18), np.int16(20), np.int16(21), np.int16(22), np.int16(23), np.int16(25), np.int16(28), np.int16(30), np.int16(31), np.int16(32), np.int16(33), np.int16(34), np.int16(35), np.int16(36), np.int16(38), np.int16(39), np.int16(40), np.int16(42), np.int16(43), np.int16(44), np.int16(45), np.int16(47), np.int16(48), np.int16(49), np.int16(50), np.int16(51), np.int16(52), np.int16(54), np.int16(56), np.int16(57), np.int16(58), np.int16(61), np.int16(63), np.int16(64), np.int16(66), np.int16(67)}\n",
      "Val subjects: {np.int16(59), np.int16(9), np.int16(19), np.int16(53), np.int16(55), np.int16(24), np.int16(27)}\n",
      "Test subjects: {np.int16(1), np.int16(65), np.int16(37), np.int16(5), np.int16(6), np.int16(41), np.int16(10), np.int16(13), np.int16(46), np.int16(17), np.int16(26), np.int16(60), np.int16(29), np.int16(62)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# Get your subject group array\n",
    "groups = df['subject_id'].values\n",
    "\n",
    "# 1. Split off test subjects\n",
    "gss1 = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "trainval_idx, test_idx = next(gss1.split(df, df['label'], groups=groups))\n",
    "\n",
    "trainval_subjects = df.iloc[trainval_idx]['subject_id'].unique()\n",
    "test_subjects = df.iloc[test_idx]['subject_id'].unique()\n",
    "\n",
    "df_trainval = df[df['subject_id'].isin(trainval_subjects)].copy()\n",
    "df_test     = df[df['subject_id'].isin(test_subjects)].copy()\n",
    "\n",
    "# 2. Split val subjects from trainval\n",
    "groups_trainval = df_trainval['subject_id'].values\n",
    "gss2 = GroupShuffleSplit(n_splits=1, test_size=0.125, random_state=42)\n",
    "train_idx, val_idx = next(gss2.split(df_trainval, df_trainval['label'], groups=groups_trainval))\n",
    "\n",
    "train_subjects = df_trainval.iloc[train_idx]['subject_id'].unique()\n",
    "val_subjects   = df_trainval.iloc[val_idx]['subject_id'].unique()\n",
    "\n",
    "df_train = df_trainval[df_trainval['subject_id'].isin(train_subjects)].copy()\n",
    "df_val   = df_trainval[df_trainval['subject_id'].isin(val_subjects)].copy()\n",
    "\n",
    "print(\"Train subjects:\", set(train_subjects))\n",
    "print(\"Val subjects:\", set(val_subjects))\n",
    "print(\"Test subjects:\", set(test_subjects))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32a0be4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_cols = ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z', 'azimuth','pitch','roll']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3cfe1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[sensor_cols]\n",
    "X_val = df_val[sensor_cols]\n",
    "X_test = df_test[sensor_cols]\n",
    "\n",
    "y_train = df_train['fall_label']\n",
    "y_val= df_val['fall_label']\n",
    "y_test = df_test['fall_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57572789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>pitch</th>\n",
       "      <th>roll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5909</th>\n",
       "      <td>0.574711</td>\n",
       "      <td>0.688770</td>\n",
       "      <td>0.548061</td>\n",
       "      <td>0.498774</td>\n",
       "      <td>0.525496</td>\n",
       "      <td>0.505237</td>\n",
       "      <td>0.248811</td>\n",
       "      <td>0.498245</td>\n",
       "      <td>0.803802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5910</th>\n",
       "      <td>0.523214</td>\n",
       "      <td>0.733431</td>\n",
       "      <td>0.526113</td>\n",
       "      <td>0.485675</td>\n",
       "      <td>0.533352</td>\n",
       "      <td>0.505626</td>\n",
       "      <td>0.248992</td>\n",
       "      <td>0.497208</td>\n",
       "      <td>0.803323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5911</th>\n",
       "      <td>0.537714</td>\n",
       "      <td>0.719530</td>\n",
       "      <td>0.533186</td>\n",
       "      <td>0.489984</td>\n",
       "      <td>0.531495</td>\n",
       "      <td>0.505340</td>\n",
       "      <td>0.249246</td>\n",
       "      <td>0.496138</td>\n",
       "      <td>0.802555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5912</th>\n",
       "      <td>0.546412</td>\n",
       "      <td>0.710672</td>\n",
       "      <td>0.537789</td>\n",
       "      <td>0.492151</td>\n",
       "      <td>0.530783</td>\n",
       "      <td>0.505238</td>\n",
       "      <td>0.249492</td>\n",
       "      <td>0.495047</td>\n",
       "      <td>0.801762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5913</th>\n",
       "      <td>0.536848</td>\n",
       "      <td>0.718540</td>\n",
       "      <td>0.534089</td>\n",
       "      <td>0.488740</td>\n",
       "      <td>0.532785</td>\n",
       "      <td>0.505525</td>\n",
       "      <td>0.249750</td>\n",
       "      <td>0.493930</td>\n",
       "      <td>0.800865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16696321</th>\n",
       "      <td>0.522420</td>\n",
       "      <td>0.664807</td>\n",
       "      <td>0.608921</td>\n",
       "      <td>0.593540</td>\n",
       "      <td>0.471194</td>\n",
       "      <td>0.538274</td>\n",
       "      <td>0.751832</td>\n",
       "      <td>0.273277</td>\n",
       "      <td>0.492306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16696322</th>\n",
       "      <td>0.511482</td>\n",
       "      <td>0.668538</td>\n",
       "      <td>0.620656</td>\n",
       "      <td>0.588736</td>\n",
       "      <td>0.474768</td>\n",
       "      <td>0.541313</td>\n",
       "      <td>0.752327</td>\n",
       "      <td>0.272613</td>\n",
       "      <td>0.493788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16696323</th>\n",
       "      <td>0.520168</td>\n",
       "      <td>0.705243</td>\n",
       "      <td>0.658998</td>\n",
       "      <td>0.591700</td>\n",
       "      <td>0.473786</td>\n",
       "      <td>0.548820</td>\n",
       "      <td>0.752773</td>\n",
       "      <td>0.271993</td>\n",
       "      <td>0.495396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16696324</th>\n",
       "      <td>0.527464</td>\n",
       "      <td>0.761613</td>\n",
       "      <td>0.709697</td>\n",
       "      <td>0.594029</td>\n",
       "      <td>0.473765</td>\n",
       "      <td>0.555911</td>\n",
       "      <td>0.752935</td>\n",
       "      <td>0.271913</td>\n",
       "      <td>0.497041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16696325</th>\n",
       "      <td>0.449101</td>\n",
       "      <td>0.721604</td>\n",
       "      <td>0.676888</td>\n",
       "      <td>0.562100</td>\n",
       "      <td>0.492185</td>\n",
       "      <td>0.542930</td>\n",
       "      <td>0.753031</td>\n",
       "      <td>0.271965</td>\n",
       "      <td>0.498706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11248316 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             acc_x     acc_y     acc_z    gyro_x    gyro_y    gyro_z  \\\n",
       "5909      0.574711  0.688770  0.548061  0.498774  0.525496  0.505237   \n",
       "5910      0.523214  0.733431  0.526113  0.485675  0.533352  0.505626   \n",
       "5911      0.537714  0.719530  0.533186  0.489984  0.531495  0.505340   \n",
       "5912      0.546412  0.710672  0.537789  0.492151  0.530783  0.505238   \n",
       "5913      0.536848  0.718540  0.534089  0.488740  0.532785  0.505525   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "16696321  0.522420  0.664807  0.608921  0.593540  0.471194  0.538274   \n",
       "16696322  0.511482  0.668538  0.620656  0.588736  0.474768  0.541313   \n",
       "16696323  0.520168  0.705243  0.658998  0.591700  0.473786  0.548820   \n",
       "16696324  0.527464  0.761613  0.709697  0.594029  0.473765  0.555911   \n",
       "16696325  0.449101  0.721604  0.676888  0.562100  0.492185  0.542930   \n",
       "\n",
       "           azimuth     pitch      roll  \n",
       "5909      0.248811  0.498245  0.803802  \n",
       "5910      0.248992  0.497208  0.803323  \n",
       "5911      0.249246  0.496138  0.802555  \n",
       "5912      0.249492  0.495047  0.801762  \n",
       "5913      0.249750  0.493930  0.800865  \n",
       "...            ...       ...       ...  \n",
       "16696321  0.751832  0.273277  0.492306  \n",
       "16696322  0.752327  0.272613  0.493788  \n",
       "16696323  0.752773  0.271993  0.495396  \n",
       "16696324  0.752935  0.271913  0.497041  \n",
       "16696325  0.753031  0.271965  0.498706  \n",
       "\n",
       "[11248316 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c7aec9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fall_label\n",
       "ADL          10279606\n",
       "POST_FALL      711873\n",
       "FALL           256837\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f09d93b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fall_label\n",
       "ADL          1735914\n",
       "POST_FALL      95726\n",
       "FALL           34540\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1fef5d",
   "metadata": {},
   "source": [
    "### Segment into Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72814fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_cols = ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z', 'azimuth', 'pitch', 'roll']\n",
    "\n",
    "from typing import Tuple, List\n",
    "\n",
    "def sliding_multi_window(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    fs: int = 200,\n",
    "    subwindow_duration: float = 0.2,\n",
    "    overlap: float = 0.5,\n",
    "    include_post_fall: bool = True\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Implements label-based main windows with fixed-size, overlapping sub-windows.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray, shape (n_samples, n_features)\n",
    "        Time-series sensor data (e.g., acc_x, acc_y, ..., gyro_z).\n",
    "    y : np.ndarray, shape (n_samples,)\n",
    "        Frame-level labels: 'ADL', 'FALL', 'POST_FALL', etc.\n",
    "    fs : int\n",
    "        Sampling rate in Hz (e.g., 200).\n",
    "    subwindow_duration : float\n",
    "        Duration of each sub-window in seconds (e.g., 0.2).\n",
    "    overlap : float\n",
    "        Fractional overlap between sub-windows (0 to <1, e.g., 0.5 for 50%).\n",
    "    include_post_fall : bool\n",
    "        If True, emits 'POST_FALL' windows; if False, merges POST_FALL into 'FALL'.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X_sub : np.ndarray, shape (n_subwindows, window_size, n_features)\n",
    "        Array of all extracted sub-windows.\n",
    "    y_sub : np.ndarray, shape (n_subwindows,)\n",
    "        Corresponding labels for each sub-window.\n",
    "    \"\"\"\n",
    "    # Compute window parameters\n",
    "    window_size = int(fs * subwindow_duration)\n",
    "    step_size = int(window_size * (1 - overlap))\n",
    "    if step_size < 1:\n",
    "        raise ValueError(\"Overlap too large: step size <1 sample.\")\n",
    "    \n",
    "    # Ensure proper indexing\n",
    "    X_arr = np.asarray(X)\n",
    "    y_arr = np.asarray(y)\n",
    "    \n",
    "    X_sub, y_sub = [], []\n",
    "    \n",
    "    # Helper to slice sub-windows within a main segment\n",
    "    def emit_windows(segment: np.ndarray, label: str):\n",
    "        for start in range(0, len(segment) - window_size + 1, step_size):\n",
    "            end = start + window_size\n",
    "            X_sub.append(segment[start:end])\n",
    "            y_sub.append(label)\n",
    "    \n",
    "    # Find contiguous main windows by label\n",
    "    curr_label = y_arr[0]\n",
    "    seg_start = 0\n",
    "    for i in range(1, len(y_arr)):\n",
    "        if y_arr[i] != curr_label:\n",
    "            segment = X_arr[seg_start:i]\n",
    "            if curr_label == \"ADL\":\n",
    "                emit_windows(segment, \"ADL\")\n",
    "            elif curr_label == \"FALL\":\n",
    "                emit_windows(segment, \"FALL\")\n",
    "            elif curr_label == \"POST_FALL\":\n",
    "                if include_post_fall:\n",
    "                    emit_windows(segment, \"POST_FALL\")\n",
    "                else:\n",
    "                    emit_windows(segment, \"FALL\")\n",
    "            # start next main window\n",
    "            seg_start = i\n",
    "            curr_label = y_arr[i]\n",
    "    \n",
    "    # Handle the last main window\n",
    "    segment = X_arr[seg_start:]\n",
    "    if curr_label == \"ADL\":\n",
    "        emit_windows(segment, \"ADL\")\n",
    "    elif curr_label == \"FALL\":\n",
    "        emit_windows(segment, \"FALL\")\n",
    "    elif curr_label == \"POST_FALL\":\n",
    "        if include_post_fall:\n",
    "            emit_windows(segment, \"POST_FALL\")\n",
    "        else:\n",
    "            emit_windows(segment, \"FALL\")\n",
    "    \n",
    "    return np.stack(X_sub, axis=0), np.array(y_sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "932ff65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_windows, y_train_windows = sliding_multi_window(X_train, y_train, fs =200,subwindow_duration=0.2, overlap=0.5,include_post_fall=False)\n",
    "X_val_windows, y_val_windows = sliding_multi_window(X_val, y_val, fs =200,subwindow_duration=0.2, overlap=0.5,include_post_fall=False)\n",
    "X_test_windows, y_test_windows = sliding_multi_window(X_test, y_test, fs =200,subwindow_duration=0.2, overlap=0.5,include_post_fall=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afaa816d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   \n",
       "ADL     513186\n",
       "FALL     46857\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train_windows).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7a1ac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train_windows)\n",
    "y_val_encoded = le.transform(y_val_windows)\n",
    "y_test_encoded = le.transform(y_test_windows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2dd7821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure they are NumPy arrays\n",
    "y_train_encoded = np.array(y_train_encoded)\n",
    "y_val_encoded = np.array(y_val_encoded)\n",
    "y_test_encoded = np.array(y_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9ab8e1",
   "metadata": {},
   "source": [
    "### Encode Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d15f952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_windows.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3453f162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import Loss\n",
    "\n",
    "class SparseCategoricalFocalLoss(Loss):\n",
    "    def __init__(self, gamma=2., alpha=1., from_logits=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.from_logits = from_logits\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.int32)\n",
    "        y_true_one_hot = tf.one_hot(y_true, depth=tf.shape(y_pred)[-1])\n",
    "\n",
    "        if self.from_logits:\n",
    "            y_pred = tf.nn.softmax(y_pred)\n",
    "\n",
    "        pt = tf.reduce_sum(y_pred * y_true_one_hot, axis=-1)\n",
    "        loss = -self.alpha * tf.pow(1. - pt, self.gamma) * tf.math.log(tf.clip_by_value(pt, 1e-8, 1.0))\n",
    "        return tf.reduce_mean(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c852635f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sovan\\Desktop\\Fall Detection\\New ilab\\ilab-group-12-1-fall-detection\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,376</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m5,376\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m24,704\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m258\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,378</span> (177.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m45,378\u001b[0m (177.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,122</span> (176.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m45,122\u001b[0m (176.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Conv1D, MaxPooling1D, BatchNormalization\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "\n",
    "# Implementation of \"LSTM-CNN Architecture for Human Activity Recognition\" by Kun Xia et al. (IEEE Access, 2020)\n",
    "# Adapted from https://github.com/quotation2520/CAGE4HAR/blob/main/models/LSTM_CNN.py\n",
    "\n",
    "## X_train_windows.shape == (n_samples, 100, 6)\n",
    "input_shape = (X_train_windows.shape[1], X_train_windows.shape[2]) \n",
    "num_classes = len(set(y_train_encoded))                  \n",
    "\n",
    "model_lstm_conv = Sequential([\n",
    "\n",
    "    # ——— LSTM stack ———\n",
    "    # first LSTM returns full sequence\n",
    "    LSTM(32, return_sequences=True, input_shape=input_shape),\n",
    "    # second LSTM also returns full sequence\n",
    "    LSTM(32, return_sequences=True),\n",
    "\n",
    "    # ——— 1D‐Conv + Pool ———\n",
    "    Conv1D(\n",
    "        filters=64,\n",
    "        kernel_size=3,\n",
    "        strides=2,\n",
    "        activation='relu',\n",
    "        padding='valid'   # matches PyTorch default\n",
    "    ),\n",
    "    MaxPooling1D(pool_size=2, strides=2),\n",
    "\n",
    "    # ——— second Conv block ———\n",
    "    Conv1D(\n",
    "        filters=128,\n",
    "        kernel_size=3,\n",
    "        strides=1,\n",
    "        activation='relu',\n",
    "        padding='valid'\n",
    "    ),\n",
    "\n",
    "    # ——— batch‐norm & spatial collapse ———\n",
    "    BatchNormalization(),            # normalise over feature‐axis\n",
    "    GlobalAveragePooling1D(),        # mean over time dimension\n",
    "\n",
    "    # ——— classification head ———\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model_lstm_conv.compile(\n",
    "    optimizer=Adam(1e-3),\n",
    "    loss=SparseCategoricalFocalLoss(gamma=2., alpha=1.0),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_lstm_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c05daa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "817510a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights to handle imbalance\n",
    "y_train_array = np.array(y_train_encoded)\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train_array),\n",
    "    y=y_train_array\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb7b333b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: np.float64(0.5456530380797605), 1: np.float64(5.976086817337857)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e6289a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m8751/8751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 24ms/step - accuracy: 0.9226 - loss: 0.0548 - val_accuracy: 0.9311 - val_loss: 0.0451\n",
      "Epoch 2/20\n",
      "\u001b[1m8751/8751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 24ms/step - accuracy: 0.9490 - loss: 0.0388 - val_accuracy: 0.9296 - val_loss: 0.0423\n",
      "Epoch 3/20\n",
      "\u001b[1m8751/8751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 24ms/step - accuracy: 0.9567 - loss: 0.0340 - val_accuracy: 0.9237 - val_loss: 0.0483\n",
      "Epoch 4/20\n",
      "\u001b[1m8751/8751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 24ms/step - accuracy: 0.9626 - loss: 0.0308 - val_accuracy: 0.9299 - val_loss: 0.0431\n",
      "Epoch 5/20\n",
      "\u001b[1m8751/8751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 24ms/step - accuracy: 0.9667 - loss: 0.0284 - val_accuracy: 0.9225 - val_loss: 0.0487\n",
      "Epoch 6/20\n",
      "\u001b[1m8751/8751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 25ms/step - accuracy: 0.9693 - loss: 0.0267 - val_accuracy: 0.9354 - val_loss: 0.0462\n",
      "Epoch 7/20\n",
      "\u001b[1m8751/8751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 25ms/step - accuracy: 0.9705 - loss: 0.0255 - val_accuracy: 0.9311 - val_loss: 0.0584\n",
      "Epoch 8/20\n",
      "\u001b[1m8751/8751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 25ms/step - accuracy: 0.9720 - loss: 0.0247 - val_accuracy: 0.9318 - val_loss: 0.0517\n",
      "Epoch 9/20\n",
      "\u001b[1m8751/8751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 30ms/step - accuracy: 0.9737 - loss: 0.0234 - val_accuracy: 0.9184 - val_loss: 0.0628\n",
      "Epoch 10/20\n",
      "\u001b[1m8751/8751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 31ms/step - accuracy: 0.9746 - loss: 0.0230 - val_accuracy: 0.9271 - val_loss: 0.0484\n",
      "Epoch 11/20\n",
      "\u001b[1m8751/8751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 32ms/step - accuracy: 0.9751 - loss: 0.0223 - val_accuracy: 0.9333 - val_loss: 0.0625\n",
      "Epoch 12/20\n",
      "\u001b[1m8751/8751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 32ms/step - accuracy: 0.9763 - loss: 0.0217 - val_accuracy: 0.9333 - val_loss: 0.0672\n",
      "Epoch 13/20\n",
      "\u001b[1m8751/8751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 32ms/step - accuracy: 0.9768 - loss: 0.0210 - val_accuracy: 0.9338 - val_loss: 0.0491\n",
      "Epoch 14/20\n",
      "\u001b[1m8751/8751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 32ms/step - accuracy: 0.9772 - loss: 0.0204 - val_accuracy: 0.9312 - val_loss: 0.0596\n",
      "Epoch 15/20\n",
      "\u001b[1m8751/8751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 32ms/step - accuracy: 0.9780 - loss: 0.0199 - val_accuracy: 0.9251 - val_loss: 0.0782\n",
      "Epoch 16/20\n",
      "\u001b[1m8751/8751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 32ms/step - accuracy: 0.9785 - loss: 0.0194 - val_accuracy: 0.9379 - val_loss: 0.0568\n",
      "Epoch 17/20\n",
      "\u001b[1m8751/8751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 32ms/step - accuracy: 0.9793 - loss: 0.0190 - val_accuracy: 0.9379 - val_loss: 0.0821\n",
      "Epoch 18/20\n",
      "\u001b[1m8751/8751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 32ms/step - accuracy: 0.9796 - loss: 0.0187 - val_accuracy: 0.9258 - val_loss: 0.0660\n",
      "Epoch 19/20\n",
      "\u001b[1m8751/8751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 32ms/step - accuracy: 0.9804 - loss: 0.0180 - val_accuracy: 0.9343 - val_loss: 0.0520\n",
      "Epoch 20/20\n",
      "\u001b[1m8751/8751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 33ms/step - accuracy: 0.9805 - loss: 0.0176 - val_accuracy: 0.9340 - val_loss: 0.0532\n"
     ]
    }
   ],
   "source": [
    "history = model_lstm_conv.fit(\n",
    "    X_train_windows, y_train_encoded,\n",
    "    validation_data=(X_val_windows, y_val_encoded),\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51a30c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (confusion_matrix, classification_report, \n",
    "                             precision_score, recall_score, f1_score)\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, label_classes=None, plot_confusion_matrix=True, plot_roc=False):\n",
    "    # Evaluate the model\n",
    "    results = model.evaluate(X_test, y_test, verbose=0)\n",
    "    metric_names = model.metrics_names\n",
    "    metrics_dict = dict(zip(metric_names, results))\n",
    "\n",
    "    print(\"Evaluation Metrics:\")\n",
    "    for name, value in metrics_dict.items():\n",
    "        print(f\"{name.capitalize()}: {value:.4f}\")\n",
    "\n",
    "    # Predict class probabilities and take argmax for predicted class\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    if plot_confusion_matrix:\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues',\n",
    "                    xticklabels=label_classes if label_classes else np.unique(y_test),\n",
    "                    yticklabels=label_classes if label_classes else np.unique(y_test))\n",
    "        plt.xlabel(\"Predicted Label\")\n",
    "        plt.ylabel(\"True Label\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.show()\n",
    "\n",
    "    # Classification report\n",
    "    report = classification_report(y_test, y_pred, target_names=label_classes if label_classes else None)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "    # Macro-averaged metrics across all classes\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(\"Macro Precision (sklearn): {:.4f}\".format(precision))\n",
    "    print(\"Macro Recall (sklearn): {:.4f}\".format(recall))\n",
    "    print(\"Macro F1 Score: {:.4f}\".format(f1))\n",
    "\n",
    "    # Update metrics dictionary to include sklearn metrics\n",
    "    metrics_dict.update({\n",
    "        'macro_precision': precision,\n",
    "        'macro_recall': recall,\n",
    "        'macro_f1_score': f1\n",
    "    })\n",
    "\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d89fa750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Loss: 0.0323\n",
      "Compile_metrics: 0.9640\n",
      "\u001b[1m5669/5669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ADL       0.98      0.98      0.98    167936\n",
      "        FALL       0.76      0.75      0.76     13467\n",
      "\n",
      "    accuracy                           0.96    181403\n",
      "   macro avg       0.87      0.86      0.87    181403\n",
      "weighted avg       0.96      0.96      0.96    181403\n",
      "\n",
      "Macro Precision (sklearn): 0.8711\n",
      "Macro Recall (sklearn): 0.8647\n",
      "Macro F1 Score: 0.8679\n"
     ]
    }
   ],
   "source": [
    "label_classes = le.classes_.tolist()\n",
    "metrics = evaluate_model(model_lstm_conv, X_test_windows, y_test_encoded, label_classes=label_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd67199",
   "metadata": {},
   "source": [
    "### 10-Fold Subject Cross Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e6105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# assume X_windows, y_encoded, subject_ids are already defined:\n",
    "# X_windows: (n_samples, timesteps, n_features)\n",
    "# y_encoded: (n_samples,)\n",
    "# subject_ids: array of shape (n_samples,) with each sample's subject_id\n",
    "\n",
    "n_splits = 5\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "fold_metrics = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(gkf.split(X_windows, y_encoded, groups=subject_ids), 1):\n",
    "    print(f\"\\n=== Fold {fold}/{n_splits} ===\")\n",
    "    \n",
    "    # split data\n",
    "    X_train, X_val = X_windows[train_idx], X_windows[val_idx]\n",
    "    y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
    "\n",
    "    # build a fresh model for each fold\n",
    "    model = build_model(input_shape=X_train.shape[1:], num_classes=len(np.unique(y_encoded)))\n",
    "    \n",
    "    # optional: early stopping on validation loss\n",
    "    es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # train\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=50,\n",
    "        batch_size=64,\n",
    "        shuffle=True,               # shuffle within the training set each epoch\n",
    "        callbacks=[es],\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    # evaluate\n",
    "    loss, acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print(f\" → Val loss: {loss:.4f}, Val accuracy: {acc:.4f}\")\n",
    "    fold_metrics.append((loss, acc))\n",
    "\n",
    "# summarise\n",
    "losses, accs = zip(*fold_metrics)\n",
    "print(f\"\\nAverage val accuracy over {n_splits} folds: {np.mean(accs):.4f} ± {np.std(accs):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
