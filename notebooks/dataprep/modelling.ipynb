{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import packages and extracted python class for classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "#                                                            #\n",
    "#    Mark Hoogendoorn and Burkhardt Funk (2017)              #\n",
    "#    Machine Learning for the Quantified Self                #\n",
    "#    Springer                                                #\n",
    "#    Chapter 7                                               #\n",
    "#                                                            #\n",
    "##############################################################\n",
    "\n",
    "# Updated by Dave Ebbelaar on 12-01-2023\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "\n",
    "class ClassificationAlgorithms:\n",
    "\n",
    "    # Forward selection for classification which selects a pre-defined number of features (max_features)\n",
    "    # that show the best accuracy. We assume a decision tree learning for this purpose, but\n",
    "    # this can easily be changed. It return the best features.\n",
    "    def forward_selection(self, max_features, X_train, y_train):\n",
    "        # Start with no features.\n",
    "        ordered_features = []\n",
    "        ordered_scores = []\n",
    "        selected_features = []\n",
    "        ca = ClassificationAlgorithms()\n",
    "        prev_best_perf = 0\n",
    "\n",
    "        # Select the appropriate number of features.\n",
    "        for i in range(0, max_features):\n",
    "            print(i)\n",
    "\n",
    "            # Determine the features left to select.\n",
    "            features_left = list(set(X_train.columns) - set(selected_features))\n",
    "            best_perf = 0\n",
    "            best_attribute = \"\"\n",
    "\n",
    "            # For all features we can still select...\n",
    "            for f in features_left:\n",
    "                temp_selected_features = copy.deepcopy(selected_features)\n",
    "                temp_selected_features.append(f)\n",
    "\n",
    "                # Determine the accuracy of a decision tree learner if we were to add\n",
    "                # the feature.\n",
    "                (\n",
    "                    pred_y_train,\n",
    "                    pred_y_test,\n",
    "                    prob_training_y,\n",
    "                    prob_test_y,\n",
    "                ) = ca.decision_tree(\n",
    "                    X_train[temp_selected_features],\n",
    "                    y_train,\n",
    "                    X_train[temp_selected_features],\n",
    "                )\n",
    "                perf = accuracy_score(y_train, pred_y_train)\n",
    "\n",
    "                # If the performance is better than what we have seen so far (we aim for high accuracy)\n",
    "                # we set the current feature to the best feature and the same for the best performance.\n",
    "                if perf > best_perf:\n",
    "                    best_perf = perf\n",
    "                    best_feature = f\n",
    "            # We select the feature with the best performance.\n",
    "            selected_features.append(best_feature)\n",
    "            prev_best_perf = best_perf\n",
    "            ordered_features.append(best_feature)\n",
    "            ordered_scores.append(best_perf)\n",
    "        return selected_features, ordered_features, ordered_scores\n",
    "\n",
    "    # Apply a neural network for classification upon the training data (with the specified composition of\n",
    "    # hidden layers and number of iterations), and use the created network to predict the outcome for both the\n",
    "    # test and training set. It returns the categorical predictions for the training and test set as well as the\n",
    "    # probabilities associated with each class, each class being represented as a column in the data frame.\n",
    "    def feedforward_neural_network(\n",
    "        self,\n",
    "        train_X,\n",
    "        train_y,\n",
    "        test_X,\n",
    "        hidden_layer_sizes=(100,),\n",
    "        max_iter=2000,\n",
    "        activation=\"logistic\",\n",
    "        alpha=0.0001,\n",
    "        learning_rate=\"adaptive\",\n",
    "        gridsearch=True,\n",
    "        print_model_details=False,\n",
    "    ):\n",
    "\n",
    "        if gridsearch:\n",
    "            tuned_parameters = [\n",
    "                {\n",
    "                    \"hidden_layer_sizes\": [\n",
    "                        (5,),\n",
    "                        (10,),\n",
    "                        (25,),\n",
    "                        (100,),\n",
    "                        (\n",
    "                            100,\n",
    "                            5,\n",
    "                        ),\n",
    "                        (\n",
    "                            100,\n",
    "                            10,\n",
    "                        ),\n",
    "                    ],\n",
    "                    \"activation\": [activation],\n",
    "                    \"learning_rate\": [learning_rate],\n",
    "                    \"max_iter\": [1000, 2000],\n",
    "                    \"alpha\": [alpha],\n",
    "                }\n",
    "            ]\n",
    "            nn = GridSearchCV(\n",
    "                MLPClassifier(), tuned_parameters, cv=5, scoring=\"accuracy\"\n",
    "            )\n",
    "        else:\n",
    "            # Create the model\n",
    "            nn = MLPClassifier(\n",
    "                hidden_layer_sizes=hidden_layer_sizes,\n",
    "                activation=activation,\n",
    "                max_iter=max_iter,\n",
    "                learning_rate=learning_rate,\n",
    "                alpha=alpha,\n",
    "            )\n",
    "\n",
    "        # Fit the model\n",
    "        nn.fit(\n",
    "            train_X,\n",
    "            train_y.values.ravel(),\n",
    "        )\n",
    "\n",
    "        if gridsearch and print_model_details:\n",
    "            print(nn.best_params_)\n",
    "\n",
    "        if gridsearch:\n",
    "            nn = nn.best_estimator_\n",
    "\n",
    "        # Apply the model\n",
    "        pred_prob_training_y = nn.predict_proba(train_X)\n",
    "        pred_prob_test_y = nn.predict_proba(test_X)\n",
    "        pred_training_y = nn.predict(train_X)\n",
    "        pred_test_y = nn.predict(test_X)\n",
    "        frame_prob_training_y = pd.DataFrame(pred_prob_training_y, columns=nn.classes_)\n",
    "        frame_prob_test_y = pd.DataFrame(pred_prob_test_y, columns=nn.classes_)\n",
    "\n",
    "        return pred_training_y, pred_test_y, frame_prob_training_y, frame_prob_test_y\n",
    "\n",
    "    # Apply a support vector machine for classification upon the training data (with the specified value for\n",
    "    # C, epsilon and the kernel function), and use the created model to predict the outcome for both the\n",
    "    # test and training set. It returns the categorical predictions for the training and test set as well as the\n",
    "    # probabilities associated with each class, each class being represented as a column in the data frame.\n",
    "    def support_vector_machine_with_kernel(\n",
    "        self,\n",
    "        train_X,\n",
    "        train_y,\n",
    "        test_X,\n",
    "        kernel=\"rbf\",\n",
    "        C=1,\n",
    "        gamma=1e-3,\n",
    "        gridsearch=True,\n",
    "        print_model_details=False,\n",
    "    ):\n",
    "        # Create the model\n",
    "        if gridsearch:\n",
    "            tuned_parameters = [\n",
    "                {\"kernel\": [\"rbf\", \"poly\"], \"gamma\": [1e-3, 1e-4], \"C\": [1, 10, 100]}\n",
    "            ]\n",
    "            svm = GridSearchCV(\n",
    "                SVC(probability=True), tuned_parameters, cv=5, scoring=\"accuracy\"\n",
    "            )\n",
    "        else:\n",
    "            svm = SVC(\n",
    "                C=C, kernel=kernel, gamma=gamma, probability=True, cache_size=7000\n",
    "            )\n",
    "\n",
    "        # Fit the model\n",
    "        svm.fit(train_X, train_y.values.ravel())\n",
    "\n",
    "        if gridsearch and print_model_details:\n",
    "            print(svm.best_params_)\n",
    "\n",
    "        if gridsearch:\n",
    "            svm = svm.best_estimator_\n",
    "\n",
    "        # Apply the model\n",
    "        pred_prob_training_y = svm.predict_proba(train_X)\n",
    "        pred_prob_test_y = svm.predict_proba(test_X)\n",
    "        pred_training_y = svm.predict(train_X)\n",
    "        pred_test_y = svm.predict(test_X)\n",
    "        frame_prob_training_y = pd.DataFrame(pred_prob_training_y, columns=svm.classes_)\n",
    "        frame_prob_test_y = pd.DataFrame(pred_prob_test_y, columns=svm.classes_)\n",
    "\n",
    "        return pred_training_y, pred_test_y, frame_prob_training_y, frame_prob_test_y\n",
    "\n",
    "    # Apply a support vector machine for classification upon the training data (with the specified value for\n",
    "    # C, epsilon and the kernel function), and use the created model to predict the outcome for both the\n",
    "    # test and training set. It returns the categorical predictions for the training and test set as well as the\n",
    "    # probabilities associated with each class, each class being represented as a column in the data frame.\n",
    "    def support_vector_machine_without_kernel(\n",
    "        self,\n",
    "        train_X,\n",
    "        train_y,\n",
    "        test_X,\n",
    "        C=1,\n",
    "        tol=1e-3,\n",
    "        max_iter=1000,\n",
    "        gridsearch=True,\n",
    "        print_model_details=False,\n",
    "    ):\n",
    "        # Create the model\n",
    "        if gridsearch:\n",
    "            tuned_parameters = [\n",
    "                {\"max_iter\": [1000, 2000], \"tol\": [1e-3, 1e-4], \"C\": [1, 10, 100]}\n",
    "            ]\n",
    "            svm = GridSearchCV(LinearSVC(), tuned_parameters, cv=5, scoring=\"accuracy\")\n",
    "        else:\n",
    "            svm = LinearSVC(C=C, tol=tol, max_iter=max_iter)\n",
    "\n",
    "        # Fit the model\n",
    "        svm.fit(train_X, train_y.values.ravel())\n",
    "\n",
    "        if gridsearch and print_model_details:\n",
    "            print(svm.best_params_)\n",
    "\n",
    "        if gridsearch:\n",
    "            svm = svm.best_estimator_\n",
    "\n",
    "        # Apply the model\n",
    "\n",
    "        distance_training_platt = 1 / (1 + np.exp(svm.decision_function(train_X)))\n",
    "        pred_prob_training_y = (\n",
    "            distance_training_platt / distance_training_platt.sum(axis=1)[:, None]\n",
    "        )\n",
    "        distance_test_platt = 1 / (1 + np.exp(svm.decision_function(test_X)))\n",
    "        pred_prob_test_y = (\n",
    "            distance_test_platt / distance_test_platt.sum(axis=1)[:, None]\n",
    "        )\n",
    "        pred_training_y = svm.predict(train_X)\n",
    "        pred_test_y = svm.predict(test_X)\n",
    "        frame_prob_training_y = pd.DataFrame(pred_prob_training_y, columns=svm.classes_)\n",
    "        frame_prob_test_y = pd.DataFrame(pred_prob_test_y, columns=svm.classes_)\n",
    "\n",
    "        return pred_training_y, pred_test_y, frame_prob_training_y, frame_prob_test_y\n",
    "\n",
    "    # Apply a nearest neighbor approach for classification upon the training data (with the specified value for\n",
    "    # k), and use the created model to predict the outcome for both the\n",
    "    # test and training set. It returns the categorical predictions for the training and test set as well as the\n",
    "    # probabilities associated with each class, each class being represented as a column in the data frame.\n",
    "    def k_nearest_neighbor(\n",
    "        self,\n",
    "        train_X,\n",
    "        train_y,\n",
    "        test_X,\n",
    "        n_neighbors=5,\n",
    "        gridsearch=True,\n",
    "        print_model_details=False,\n",
    "    ):\n",
    "        # Create the model\n",
    "        if gridsearch:\n",
    "            tuned_parameters = [{\"n_neighbors\": [1, 2, 5, 10]}]\n",
    "            knn = GridSearchCV(\n",
    "                KNeighborsClassifier(), tuned_parameters, cv=5, scoring=\"accuracy\"\n",
    "            )\n",
    "        else:\n",
    "            knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "\n",
    "        # Fit the model\n",
    "        knn.fit(train_X, train_y.values.ravel())\n",
    "\n",
    "        if gridsearch and print_model_details:\n",
    "            print(knn.best_params_)\n",
    "\n",
    "        if gridsearch:\n",
    "            knn = knn.best_estimator_\n",
    "\n",
    "        # Apply the model\n",
    "        pred_prob_training_y = knn.predict_proba(train_X)\n",
    "        pred_prob_test_y = knn.predict_proba(test_X)\n",
    "        pred_training_y = knn.predict(train_X)\n",
    "        pred_test_y = knn.predict(test_X)\n",
    "        frame_prob_training_y = pd.DataFrame(pred_prob_training_y, columns=knn.classes_)\n",
    "        frame_prob_test_y = pd.DataFrame(pred_prob_test_y, columns=knn.classes_)\n",
    "\n",
    "        return pred_training_y, pred_test_y, frame_prob_training_y, frame_prob_test_y\n",
    "\n",
    "    # Apply a decision tree approach for classification upon the training data (with the specified value for\n",
    "    # the minimum samples in the leaf, and the export path and files if print_model_details=True)\n",
    "    # and use the created model to predict the outcome for both the\n",
    "    # test and training set. It returns the categorical predictions for the training and test set as well as the\n",
    "    # probabilities associated with each class, each class being represented as a column in the data frame.\n",
    "    def decision_tree(\n",
    "        self,\n",
    "        train_X,\n",
    "        train_y,\n",
    "        test_X,\n",
    "        min_samples_leaf=50,\n",
    "        criterion=\"gini\",\n",
    "        print_model_details=False,\n",
    "        export_tree_path=\"Example_graphs/Chapter7/\",\n",
    "        export_tree_name=\"tree.dot\",\n",
    "        gridsearch=True,\n",
    "    ):\n",
    "        # Create the model\n",
    "        if gridsearch:\n",
    "            tuned_parameters = [\n",
    "                {\n",
    "                    \"min_samples_leaf\": [2, 10, 50, 100, 200],\n",
    "                    \"criterion\": [\"gini\", \"entropy\"],\n",
    "                }\n",
    "            ]\n",
    "            dtree = GridSearchCV(\n",
    "                DecisionTreeClassifier(), tuned_parameters, cv=5, scoring=\"accuracy\"\n",
    "            )\n",
    "        else:\n",
    "            dtree = DecisionTreeClassifier(\n",
    "                min_samples_leaf=min_samples_leaf, criterion=criterion\n",
    "            )\n",
    "\n",
    "        # Fit the model\n",
    "\n",
    "        dtree.fit(train_X, train_y.values.ravel())\n",
    "\n",
    "        if gridsearch and print_model_details:\n",
    "            print(dtree.best_params_)\n",
    "\n",
    "        if gridsearch:\n",
    "            dtree = dtree.best_estimator_\n",
    "\n",
    "        # Apply the model\n",
    "        pred_prob_training_y = dtree.predict_proba(train_X)\n",
    "        pred_prob_test_y = dtree.predict_proba(test_X)\n",
    "        pred_training_y = dtree.predict(train_X)\n",
    "        pred_test_y = dtree.predict(test_X)\n",
    "        frame_prob_training_y = pd.DataFrame(\n",
    "            pred_prob_training_y, columns=dtree.classes_\n",
    "        )\n",
    "        frame_prob_test_y = pd.DataFrame(pred_prob_test_y, columns=dtree.classes_)\n",
    "\n",
    "        if print_model_details:\n",
    "            ordered_indices = [\n",
    "                i[0]\n",
    "                for i in sorted(\n",
    "                    enumerate(dtree.feature_importances_),\n",
    "                    key=lambda x: x[1],\n",
    "                    reverse=True,\n",
    "                )\n",
    "            ]\n",
    "            print(\"Feature importance decision tree:\")\n",
    "            for i in range(0, len(dtree.feature_importances_)):\n",
    "                print(\n",
    "                    train_X.columns[ordered_indices[i]],\n",
    "                )\n",
    "                print(\n",
    "                    \" & \",\n",
    "                )\n",
    "                print(dtree.feature_importances_[ordered_indices[i]])\n",
    "            tree.export_graphviz(\n",
    "                dtree,\n",
    "                out_file=export_tree_path + export_tree_name,\n",
    "                feature_names=train_X.columns,\n",
    "                class_names=dtree.classes_,\n",
    "            )\n",
    "\n",
    "        return pred_training_y, pred_test_y, frame_prob_training_y, frame_prob_test_y\n",
    "\n",
    "    # Apply a naive bayes approach for classification upon the training data\n",
    "    # and use the created model to predict the outcome for both the\n",
    "    # test and training set. It returns the categorical predictions for the training and test set as well as the\n",
    "    # probabilities associated with each class, each class being represented as a column in the data frame.\n",
    "    def naive_bayes(self, train_X, train_y, test_X):\n",
    "        # Create the model\n",
    "        nb = GaussianNB()\n",
    "\n",
    "        # Fit the model\n",
    "        nb.fit(train_X, train_y)\n",
    "\n",
    "        # Apply the model\n",
    "        pred_prob_training_y = nb.predict_proba(train_X)\n",
    "        pred_prob_test_y = nb.predict_proba(test_X)\n",
    "        pred_training_y = nb.predict(train_X)\n",
    "        pred_test_y = nb.predict(test_X)\n",
    "        frame_prob_training_y = pd.DataFrame(pred_prob_training_y, columns=nb.classes_)\n",
    "        frame_prob_test_y = pd.DataFrame(pred_prob_test_y, columns=nb.classes_)\n",
    "\n",
    "        return pred_training_y, pred_test_y, frame_prob_training_y, frame_prob_test_y\n",
    "\n",
    "    # Apply a random forest approach for classification upon the training data (with the specified value for\n",
    "    # the minimum samples in the leaf, the number of trees, and if we should print some of the details of the\n",
    "    # model print_model_details=True) and use the created model to predict the outcome for both the\n",
    "    # test and training set. It returns the categorical predictions for the training and test set as well as the\n",
    "    # probabilities associated with each class, each class being represented as a column in the data frame.\n",
    "    def random_forest(\n",
    "        self,\n",
    "        train_X,\n",
    "        train_y,\n",
    "        test_X,\n",
    "        n_estimators=10,\n",
    "        min_samples_leaf=5,\n",
    "        criterion=\"gini\",\n",
    "        print_model_details=False,\n",
    "        gridsearch=True,\n",
    "    ):\n",
    "\n",
    "        if gridsearch:\n",
    "            tuned_parameters = [\n",
    "                {\n",
    "                    \"min_samples_leaf\": [2, 10, 50, 100, 200],\n",
    "                    \"n_estimators\": [10, 50, 100],\n",
    "                    \"criterion\": [\"gini\", \"entropy\"],\n",
    "                }\n",
    "            ]\n",
    "            rf = GridSearchCV(\n",
    "                RandomForestClassifier(), tuned_parameters, cv=5, scoring=\"accuracy\"\n",
    "            )\n",
    "        else:\n",
    "            rf = RandomForestClassifier(\n",
    "                n_estimators=n_estimators,\n",
    "                min_samples_leaf=min_samples_leaf,\n",
    "                criterion=criterion,\n",
    "            )\n",
    "\n",
    "        # Fit the model\n",
    "\n",
    "        rf.fit(train_X, train_y.values.ravel())\n",
    "\n",
    "        if gridsearch and print_model_details:\n",
    "            print(rf.best_params_)\n",
    "\n",
    "        if gridsearch:\n",
    "            rf = rf.best_estimator_\n",
    "\n",
    "        pred_prob_training_y = rf.predict_proba(train_X)\n",
    "        pred_prob_test_y = rf.predict_proba(test_X)\n",
    "        pred_training_y = rf.predict(train_X)\n",
    "        pred_test_y = rf.predict(test_X)\n",
    "        frame_prob_training_y = pd.DataFrame(pred_prob_training_y, columns=rf.classes_)\n",
    "        frame_prob_test_y = pd.DataFrame(pred_prob_test_y, columns=rf.classes_)\n",
    "\n",
    "        if print_model_details:\n",
    "            ordered_indices = [\n",
    "                i[0]\n",
    "                for i in sorted(\n",
    "                    enumerate(rf.feature_importances_), key=lambda x: x[1], reverse=True\n",
    "                )\n",
    "            ]\n",
    "            print(\"Feature importance random forest:\")\n",
    "            for i in range(0, len(rf.feature_importances_)):\n",
    "                print(\n",
    "                    train_X.columns[ordered_indices[i]],\n",
    "                )\n",
    "                print(\n",
    "                    \" & \",\n",
    "                )\n",
    "                print(rf.feature_importances_[ordered_indices[i]])\n",
    "\n",
    "        return (\n",
    "            pred_training_y,\n",
    "            pred_test_y,\n",
    "            frame_prob_training_y,\n",
    "            frame_prob_test_y,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../../data/interim/df_81_features.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>label</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>trial</th>\n",
       "      <th>age</th>\n",
       "      <th>...</th>\n",
       "      <th>acc_z_entropy</th>\n",
       "      <th>gyro_x_fft</th>\n",
       "      <th>gyro_x_psd</th>\n",
       "      <th>gyro_x_entropy</th>\n",
       "      <th>gyro_y_fft</th>\n",
       "      <th>gyro_y_psd</th>\n",
       "      <th>gyro_y_entropy</th>\n",
       "      <th>gyro_z_fft</th>\n",
       "      <th>gyro_z_psd</th>\n",
       "      <th>gyro_z_entropy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:38:39.700</th>\n",
       "      <td>-0.068994</td>\n",
       "      <td>-6.987095</td>\n",
       "      <td>5.288118</td>\n",
       "      <td>1.340131</td>\n",
       "      <td>0.254273</td>\n",
       "      <td>0.553948</td>\n",
       "      <td>BSC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.552713</td>\n",
       "      <td>2.237175</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.920616</td>\n",
       "      <td>0.363307</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>1.282563</td>\n",
       "      <td>0.614725</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>1.354238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:38:40.200</th>\n",
       "      <td>-0.470804</td>\n",
       "      <td>-1.801783</td>\n",
       "      <td>8.929937</td>\n",
       "      <td>1.701367</td>\n",
       "      <td>0.193919</td>\n",
       "      <td>0.328752</td>\n",
       "      <td>BSC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697146</td>\n",
       "      <td>1.886452</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.905243</td>\n",
       "      <td>0.727568</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>1.175494</td>\n",
       "      <td>1.138423</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>1.415926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:38:40.700</th>\n",
       "      <td>-9.901018</td>\n",
       "      <td>13.441229</td>\n",
       "      <td>7.822155</td>\n",
       "      <td>-0.351828</td>\n",
       "      <td>0.343581</td>\n",
       "      <td>-0.851439</td>\n",
       "      <td>BSC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.074713</td>\n",
       "      <td>3.329770</td>\n",
       "      <td>0.005098</td>\n",
       "      <td>1.203505</td>\n",
       "      <td>1.706857</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.936669</td>\n",
       "      <td>3.093796</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.577150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:38:41.200</th>\n",
       "      <td>-5.150726</td>\n",
       "      <td>6.613287</td>\n",
       "      <td>3.195224</td>\n",
       "      <td>-0.107008</td>\n",
       "      <td>-1.118601</td>\n",
       "      <td>-0.638797</td>\n",
       "      <td>BSC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.461785</td>\n",
       "      <td>9.083104</td>\n",
       "      <td>0.043227</td>\n",
       "      <td>1.271543</td>\n",
       "      <td>2.602335</td>\n",
       "      <td>0.005232</td>\n",
       "      <td>1.358140</td>\n",
       "      <td>3.267480</td>\n",
       "      <td>0.006812</td>\n",
       "      <td>0.745639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:38:41.700</th>\n",
       "      <td>-4.931030</td>\n",
       "      <td>5.574285</td>\n",
       "      <td>6.261700</td>\n",
       "      <td>-0.019441</td>\n",
       "      <td>0.012431</td>\n",
       "      <td>0.115133</td>\n",
       "      <td>BSC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.176317</td>\n",
       "      <td>1.104385</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>1.366146</td>\n",
       "      <td>3.538939</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>1.667364</td>\n",
       "      <td>0.830726</td>\n",
       "      <td>0.003255</td>\n",
       "      <td>1.440714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 04:49:53.200</th>\n",
       "      <td>0.586223</td>\n",
       "      <td>5.443400</td>\n",
       "      <td>1.029336</td>\n",
       "      <td>-0.737727</td>\n",
       "      <td>1.443459</td>\n",
       "      <td>1.335214</td>\n",
       "      <td>WAL</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.343248</td>\n",
       "      <td>7.967362</td>\n",
       "      <td>0.019501</td>\n",
       "      <td>0.917517</td>\n",
       "      <td>3.978832</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>1.133685</td>\n",
       "      <td>9.439387</td>\n",
       "      <td>0.030438</td>\n",
       "      <td>0.913799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 04:49:53.700</th>\n",
       "      <td>2.286937</td>\n",
       "      <td>11.130139</td>\n",
       "      <td>-1.195925</td>\n",
       "      <td>1.260658</td>\n",
       "      <td>-0.457721</td>\n",
       "      <td>-0.981431</td>\n",
       "      <td>WAL</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.502760</td>\n",
       "      <td>7.253110</td>\n",
       "      <td>0.017147</td>\n",
       "      <td>0.899968</td>\n",
       "      <td>6.142548</td>\n",
       "      <td>0.022069</td>\n",
       "      <td>1.258938</td>\n",
       "      <td>8.046604</td>\n",
       "      <td>0.023517</td>\n",
       "      <td>0.994088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 04:49:54.200</th>\n",
       "      <td>-5.076769</td>\n",
       "      <td>14.152212</td>\n",
       "      <td>2.039380</td>\n",
       "      <td>-2.541764</td>\n",
       "      <td>-1.378478</td>\n",
       "      <td>2.412521</td>\n",
       "      <td>WAL</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.377740</td>\n",
       "      <td>5.479225</td>\n",
       "      <td>0.007237</td>\n",
       "      <td>1.008082</td>\n",
       "      <td>3.459003</td>\n",
       "      <td>0.006143</td>\n",
       "      <td>1.726653</td>\n",
       "      <td>5.018624</td>\n",
       "      <td>0.007999</td>\n",
       "      <td>1.087638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 04:49:54.700</th>\n",
       "      <td>1.671382</td>\n",
       "      <td>11.554947</td>\n",
       "      <td>-1.548809</td>\n",
       "      <td>0.596082</td>\n",
       "      <td>-1.174618</td>\n",
       "      <td>-0.679053</td>\n",
       "      <td>WAL</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.449325</td>\n",
       "      <td>7.200013</td>\n",
       "      <td>0.037785</td>\n",
       "      <td>1.189187</td>\n",
       "      <td>3.266761</td>\n",
       "      <td>0.013842</td>\n",
       "      <td>1.523287</td>\n",
       "      <td>7.761068</td>\n",
       "      <td>0.044975</td>\n",
       "      <td>1.151021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 04:49:55.200</th>\n",
       "      <td>2.128992</td>\n",
       "      <td>14.084110</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>-1.022787</td>\n",
       "      <td>0.162796</td>\n",
       "      <td>0.609964</td>\n",
       "      <td>WAL</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489078</td>\n",
       "      <td>5.413554</td>\n",
       "      <td>0.007328</td>\n",
       "      <td>1.100799</td>\n",
       "      <td>3.660993</td>\n",
       "      <td>0.006653</td>\n",
       "      <td>1.503933</td>\n",
       "      <td>5.857457</td>\n",
       "      <td>0.009425</td>\n",
       "      <td>1.177872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167662 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            acc_x      acc_y     acc_z    gyro_x    gyro_y  \\\n",
       "timestamp                                                                    \n",
       "1970-01-01 00:38:39.700 -0.068994  -6.987095  5.288118  1.340131  0.254273   \n",
       "1970-01-01 00:38:40.200 -0.470804  -1.801783  8.929937  1.701367  0.193919   \n",
       "1970-01-01 00:38:40.700 -9.901018  13.441229  7.822155 -0.351828  0.343581   \n",
       "1970-01-01 00:38:41.200 -5.150726   6.613287  3.195224 -0.107008 -1.118601   \n",
       "1970-01-01 00:38:41.700 -4.931030   5.574285  6.261700 -0.019441  0.012431   \n",
       "...                           ...        ...       ...       ...       ...   \n",
       "1970-01-01 04:49:53.200  0.586223   5.443400  1.029336 -0.737727  1.443459   \n",
       "1970-01-01 04:49:53.700  2.286937  11.130139 -1.195925  1.260658 -0.457721   \n",
       "1970-01-01 04:49:54.200 -5.076769  14.152212  2.039380 -2.541764 -1.378478   \n",
       "1970-01-01 04:49:54.700  1.671382  11.554947 -1.548809  0.596082 -1.174618   \n",
       "1970-01-01 04:49:55.200  2.128992  14.084110  0.907692 -1.022787  0.162796   \n",
       "\n",
       "                           gyro_z label  subject_id  trial   age  ...  \\\n",
       "timestamp                                                         ...   \n",
       "1970-01-01 00:38:39.700  0.553948   BSC         1.0    1.0  32.0  ...   \n",
       "1970-01-01 00:38:40.200  0.328752   BSC         1.0    1.0  32.0  ...   \n",
       "1970-01-01 00:38:40.700 -0.851439   BSC         1.0    1.0  32.0  ...   \n",
       "1970-01-01 00:38:41.200 -0.638797   BSC         1.0    1.0  32.0  ...   \n",
       "1970-01-01 00:38:41.700  0.115133   BSC         1.0    1.0  32.0  ...   \n",
       "...                           ...   ...         ...    ...   ...  ...   \n",
       "1970-01-01 04:49:53.200  1.335214   WAL        67.0    1.0  23.0  ...   \n",
       "1970-01-01 04:49:53.700 -0.981431   WAL        67.0    1.0  23.0  ...   \n",
       "1970-01-01 04:49:54.200  2.412521   WAL        67.0    1.0  23.0  ...   \n",
       "1970-01-01 04:49:54.700 -0.679053   WAL        67.0    1.0  23.0  ...   \n",
       "1970-01-01 04:49:55.200  0.609964   WAL        67.0    1.0  23.0  ...   \n",
       "\n",
       "                         acc_z_entropy  gyro_x_fft gyro_x_psd  gyro_x_entropy  \\\n",
       "timestamp                                                                       \n",
       "1970-01-01 00:38:39.700       0.552713    2.237175   0.000722        0.920616   \n",
       "1970-01-01 00:38:40.200       0.697146    1.886452   0.000581        0.905243   \n",
       "1970-01-01 00:38:40.700       1.074713    3.329770   0.005098        1.203505   \n",
       "1970-01-01 00:38:41.200       1.461785    9.083104   0.043227        1.271543   \n",
       "1970-01-01 00:38:41.700       1.176317    1.104385   0.000710        1.366146   \n",
       "...                                ...         ...        ...             ...   \n",
       "1970-01-01 04:49:53.200       1.343248    7.967362   0.019501        0.917517   \n",
       "1970-01-01 04:49:53.700       1.502760    7.253110   0.017147        0.899968   \n",
       "1970-01-01 04:49:54.200       1.377740    5.479225   0.007237        1.008082   \n",
       "1970-01-01 04:49:54.700       1.449325    7.200013   0.037785        1.189187   \n",
       "1970-01-01 04:49:55.200       1.489078    5.413554   0.007328        1.100799   \n",
       "\n",
       "                         gyro_y_fft  gyro_y_psd  gyro_y_entropy  gyro_z_fft  \\\n",
       "timestamp                                                                     \n",
       "1970-01-01 00:38:39.700    0.363307    0.000888        1.282563    0.614725   \n",
       "1970-01-01 00:38:40.200    0.727568    0.000668        1.175494    1.138423   \n",
       "1970-01-01 00:38:40.700    1.706857    0.000565        0.936669    3.093796   \n",
       "1970-01-01 00:38:41.200    2.602335    0.005232        1.358140    3.267480   \n",
       "1970-01-01 00:38:41.700    3.538939    0.009700        1.667364    0.830726   \n",
       "...                             ...         ...             ...         ...   \n",
       "1970-01-01 04:49:53.200    3.978832    0.003662        1.133685    9.439387   \n",
       "1970-01-01 04:49:53.700    6.142548    0.022069        1.258938    8.046604   \n",
       "1970-01-01 04:49:54.200    3.459003    0.006143        1.726653    5.018624   \n",
       "1970-01-01 04:49:54.700    3.266761    0.013842        1.523287    7.761068   \n",
       "1970-01-01 04:49:55.200    3.660993    0.006653        1.503933    5.857457   \n",
       "\n",
       "                         gyro_z_psd  gyro_z_entropy  \n",
       "timestamp                                            \n",
       "1970-01-01 00:38:39.700    0.000267        1.354238  \n",
       "1970-01-01 00:38:40.200    0.000603        1.415926  \n",
       "1970-01-01 00:38:40.700    0.002285        0.577150  \n",
       "1970-01-01 00:38:41.200    0.006812        0.745639  \n",
       "1970-01-01 00:38:41.700    0.003255        1.440714  \n",
       "...                             ...             ...  \n",
       "1970-01-01 04:49:53.200    0.030438        0.913799  \n",
       "1970-01-01 04:49:53.700    0.023517        0.994088  \n",
       "1970-01-01 04:49:54.200    0.007999        1.087638  \n",
       "1970-01-01 04:49:54.700    0.044975        1.151021  \n",
       "1970-01-01 04:49:55.200    0.009425        1.177872  \n",
       "\n",
       "[167662 rows x 81 columns]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop subject ID and trail\n",
    "df_train = df.drop([\"subject_id\", \"trial\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(\"label\", axis =1)\n",
    "y = df_train[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "1970-01-01 00:38:39.700    0.855605\n",
       "1970-01-01 00:38:40.200    0.162012\n",
       "1970-01-01 00:38:40.700   -1.726724\n",
       "1970-01-01 00:38:41.200   -4.307600\n",
       "1970-01-01 00:38:41.700   -5.465859\n",
       "Name: acc_x_mean, dtype: float64"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['acc_x_mean'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "1970-01-01 00:38:39.700    BSC\n",
       "1970-01-01 00:38:40.200    BSC\n",
       "1970-01-01 00:38:40.700    BSC\n",
       "1970-01-01 00:38:41.200    BSC\n",
       "1970-01-01 00:38:41.700    BSC\n",
       "                          ... \n",
       "1970-01-01 04:49:53.200    WAL\n",
       "1970-01-01 04:49:53.700    WAL\n",
       "1970-01-01 04:49:54.200    WAL\n",
       "1970-01-01 04:49:54.700    WAL\n",
       "1970-01-01 04:49:55.200    WAL\n",
       "Name: label, Length: 167662, dtype: object"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split with stratify\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "STD    37368\n",
       "WAL    36817\n",
       "SIT     8956\n",
       "JOG     8653\n",
       "JUM     8347\n",
       "LYI     7581\n",
       "STU     4910\n",
       "STN     4504\n",
       "CSO     2335\n",
       "CSI     2198\n",
       "SCH     1190\n",
       "BSC      762\n",
       "SDL      644\n",
       "FKL      609\n",
       "FOL      536\n",
       "CHU      336\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "STD    12456\n",
       "WAL    12273\n",
       "SIT     2985\n",
       "JOG     2884\n",
       "JUM     2783\n",
       "LYI     2527\n",
       "STU     1637\n",
       "STN     1501\n",
       "CSO      779\n",
       "CSI      733\n",
       "SCH      397\n",
       "BSC      254\n",
       "SDL      214\n",
       "FKL      203\n",
       "FOL      178\n",
       "CHU      112\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z', 'label', 'age',\n",
       "       'height', 'weight', 'gender', 'acc_mag', 'gyro_mag', 'acc_x_mean',\n",
       "       'acc_x_std', 'acc_x_skew', 'acc_x_kurtosis', 'acc_x_jerk', 'acc_x_min',\n",
       "       'acc_x_max', 'acc_x_minmax_diff', 'acc_y_mean', 'acc_y_std',\n",
       "       'acc_y_skew', 'acc_y_kurtosis', 'acc_y_jerk', 'acc_y_min', 'acc_y_max',\n",
       "       'acc_y_minmax_diff', 'acc_z_mean', 'acc_z_std', 'acc_z_skew',\n",
       "       'acc_z_kurtosis', 'acc_z_jerk', 'acc_z_min', 'acc_z_max',\n",
       "       'acc_z_minmax_diff', 'gyro_x_mean', 'gyro_x_std', 'gyro_x_skew',\n",
       "       'gyro_x_kurtosis', 'gyro_x_jerk', 'gyro_x_min', 'gyro_x_max',\n",
       "       'gyro_x_minmax_diff', 'gyro_y_mean', 'gyro_y_std', 'gyro_y_skew',\n",
       "       'gyro_y_kurtosis', 'gyro_y_jerk', 'gyro_y_min', 'gyro_y_max',\n",
       "       'gyro_y_minmax_diff', 'gyro_z_mean', 'gyro_z_std', 'gyro_z_skew',\n",
       "       'gyro_z_kurtosis', 'gyro_z_jerk', 'gyro_z_min', 'gyro_z_max',\n",
       "       'gyro_z_minmax_diff', 'acc_x_fft', 'acc_x_psd', 'acc_x_entropy',\n",
       "       'acc_y_fft', 'acc_y_psd', 'acc_y_entropy', 'acc_z_fft', 'acc_z_psd',\n",
       "       'acc_z_entropy', 'gyro_x_fft', 'gyro_x_psd', 'gyro_x_entropy',\n",
       "       'gyro_y_fft', 'gyro_y_psd', 'gyro_y_entropy', 'gyro_z_fft',\n",
       "       'gyro_z_psd', 'gyro_z_entropy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features\n",
    "\n",
    "basic_features = ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z', 'acc_mag', 'gyro_mag']\n",
    "subject_features = ['age', 'height', 'weight']\n",
    "frequency_features = [f for f in df_train.columns if any(suffix in f for suffix in ['psd', 'entropy', 'fft'])]\n",
    "time_features = [f for f in df_train.columns if any(suffix in f for suffix in ['mean', 'std', 'skew', 'kurtosis','jerk','min','max','minmax_diff'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z', 'age',\n",
       "       'height', 'weight', 'gender', 'acc_mag', 'gyro_mag', 'acc_x_mean',\n",
       "       'acc_x_std', 'acc_x_skew', 'acc_x_kurtosis', 'acc_x_jerk', 'acc_x_min',\n",
       "       'acc_x_max', 'acc_x_minmax_diff', 'acc_y_mean', 'acc_y_std',\n",
       "       'acc_y_skew', 'acc_y_kurtosis', 'acc_y_jerk', 'acc_y_min', 'acc_y_max',\n",
       "       'acc_y_minmax_diff', 'acc_z_mean', 'acc_z_std', 'acc_z_skew',\n",
       "       'acc_z_kurtosis', 'acc_z_jerk', 'acc_z_min', 'acc_z_max',\n",
       "       'acc_z_minmax_diff', 'gyro_x_mean', 'gyro_x_std', 'gyro_x_skew',\n",
       "       'gyro_x_kurtosis', 'gyro_x_jerk', 'gyro_x_min', 'gyro_x_max',\n",
       "       'gyro_x_minmax_diff', 'gyro_y_mean', 'gyro_y_std', 'gyro_y_skew',\n",
       "       'gyro_y_kurtosis', 'gyro_y_jerk', 'gyro_y_min', 'gyro_y_max',\n",
       "       'gyro_y_minmax_diff', 'gyro_z_mean', 'gyro_z_std', 'gyro_z_skew',\n",
       "       'gyro_z_kurtosis', 'gyro_z_jerk', 'gyro_z_min', 'gyro_z_max',\n",
       "       'gyro_z_minmax_diff', 'acc_x_fft', 'acc_x_psd', 'acc_x_entropy',\n",
       "       'acc_y_fft', 'acc_y_psd', 'acc_y_entropy', 'acc_z_fft', 'acc_z_psd',\n",
       "       'acc_z_entropy', 'gyro_x_fft', 'gyro_x_psd', 'gyro_x_entropy',\n",
       "       'gyro_y_fft', 'gyro_y_psd', 'gyro_y_entropy', 'gyro_z_fft',\n",
       "       'gyro_z_psd', 'gyro_z_entropy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_1 = list(set(basic_features))\n",
    "feature_set_2 = list(set(basic_features + subject_features))\n",
    "feature_set_3 = list(set(feature_set_2 + frequency_features))\n",
    "feature_set_4 = list(set(feature_set_2 + time_features))\n",
    "feature_set_5 = list(set(feature_set_3 + time_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acc_x_skew',\n",
       " 'acc_x_kurtosis',\n",
       " 'gyro_z_minmax_diff',\n",
       " 'acc_x_min',\n",
       " 'acc_z_jerk',\n",
       " 'gyro_z_jerk',\n",
       " 'acc_y_kurtosis',\n",
       " 'acc_y_std',\n",
       " 'gyro_y_std',\n",
       " 'acc_x_mean',\n",
       " 'acc_x_std',\n",
       " 'acc_z_kurtosis',\n",
       " 'acc_y_jerk',\n",
       " 'gyro_x_jerk',\n",
       " 'acc_y_skew',\n",
       " 'gyro_y_jerk',\n",
       " 'gyro_z_skew',\n",
       " 'gyro_z_min',\n",
       " 'gyro_y_minmax_diff',\n",
       " 'gyro_y_min',\n",
       " 'acc_y_min',\n",
       " 'acc_z_max',\n",
       " 'acc_x_max',\n",
       " 'acc_z_min',\n",
       " 'gyro_x_skew',\n",
       " 'acc_z_std',\n",
       " 'gyro_x_kurtosis',\n",
       " 'gyro_x',\n",
       " 'gyro_z_kurtosis',\n",
       " 'weight',\n",
       " 'gyro_x_min',\n",
       " 'acc_z',\n",
       " 'gyro_y_mean',\n",
       " 'gyro_mag',\n",
       " 'acc_y',\n",
       " 'acc_y_mean',\n",
       " 'gyro_y_max',\n",
       " 'acc_y_max',\n",
       " 'acc_mag',\n",
       " 'acc_y_minmax_diff',\n",
       " 'gyro_x_minmax_diff',\n",
       " 'acc_z_mean',\n",
       " 'gyro_z_mean',\n",
       " 'gyro_z',\n",
       " 'gyro_x_max',\n",
       " 'gyro_y',\n",
       " 'gyro_y_skew',\n",
       " 'gyro_x_std',\n",
       " 'gyro_y_kurtosis',\n",
       " 'acc_x',\n",
       " 'acc_x_jerk',\n",
       " 'gyro_z_std',\n",
       " 'age',\n",
       " 'height',\n",
       " 'gyro_z_max',\n",
       " 'gyro_x_mean',\n",
       " 'acc_x_minmax_diff',\n",
       " 'acc_z_minmax_diff',\n",
       " 'acc_z_skew']"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_set_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_feature_sets = [\n",
    "    feature_set_1,\n",
    "    feature_set_2,\n",
    "    feature_set_3,\n",
    "    feature_set_4,\n",
    "    feature_set_5\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "    \"Feature Set 1\",\n",
    "    \"Feature Set 2\",\n",
    "    \"Feature Set 3\",\n",
    "    \"Only timewindow\",\n",
    "    \"ALL Features\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the class defined abovce as learner\n",
    "\n",
    "learner = ClassificationAlgorithms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature set: 0\n",
      "\tTraining neural network, 0\n",
      "\tTraining random forest, 0\n",
      "\tTraining KNN\n",
      "\tTraining decision tree\n",
      "\tTraining naive bayes\n",
      "Feature set: 1\n",
      "\tTraining neural network, 0\n",
      "\tTraining random forest, 0\n",
      "\tTraining KNN\n",
      "\tTraining decision tree\n",
      "\tTraining naive bayes\n",
      "Feature set: 2\n",
      "\tTraining neural network, 0\n",
      "\tTraining random forest, 0\n",
      "\tTraining KNN\n",
      "\tTraining decision tree\n",
      "\tTraining naive bayes\n",
      "Feature set: 3\n",
      "\tTraining neural network, 0\n",
      "\tTraining random forest, 0\n",
      "\tTraining KNN\n",
      "\tTraining decision tree\n",
      "\tTraining naive bayes\n",
      "Feature set: 4\n",
      "\tTraining neural network, 0\n",
      "\tTraining random forest, 0\n",
      "\tTraining KNN\n",
      "\tTraining decision tree\n",
      "\tTraining naive bayes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "iterations = 1\n",
    "score_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "for i, f in zip(range(len(possible_feature_sets)), feature_names):\n",
    "    print(\"Feature set:\", i)\n",
    "    selected_train_X = X_train[possible_feature_sets[i]]\n",
    "    selected_test_X = X_test[possible_feature_sets[i]]\n",
    "\n",
    "    # First run non deterministic classifiers to average their score.\n",
    "    performance_test_nn = 0\n",
    "    performance_test_rf = 0\n",
    "\n",
    "    for it in range(0, iterations):\n",
    "        print(\"\\tTraining neural network,\", it)\n",
    "        (\n",
    "            class_train_y,\n",
    "            class_test_y,\n",
    "            class_train_prob_y,\n",
    "            class_test_prob_y,\n",
    "        ) = learner.feedforward_neural_network(\n",
    "            selected_train_X,\n",
    "            y_train,\n",
    "            selected_test_X,\n",
    "            gridsearch=False,\n",
    "        )\n",
    "        performance_test_nn += accuracy_score(y_test, class_test_y)\n",
    "\n",
    "        print(\"\\tTraining random forest,\", it)\n",
    "        (\n",
    "            class_train_y,\n",
    "            class_test_y,\n",
    "            class_train_prob_y,\n",
    "            class_test_prob_y,\n",
    "        ) = learner.random_forest(\n",
    "            selected_train_X, y_train, selected_test_X, gridsearch=False\n",
    "        )\n",
    "        performance_test_rf += accuracy_score(y_test, class_test_y)\n",
    "\n",
    "    performance_test_nn = performance_test_nn / iterations\n",
    "    performance_test_rf = performance_test_rf / iterations\n",
    "\n",
    "    # And we run our deterministic classifiers:\n",
    "    print(\"\\tTraining KNN\")\n",
    "    (\n",
    "        class_train_y,\n",
    "        class_test_y,\n",
    "        class_train_prob_y,\n",
    "        class_test_prob_y,\n",
    "    ) = learner.k_nearest_neighbor(\n",
    "        selected_train_X, y_train, selected_test_X, gridsearch=False\n",
    "    )\n",
    "    performance_test_knn = accuracy_score(y_test, class_test_y)\n",
    "\n",
    "    print(\"\\tTraining decision tree\")\n",
    "    (\n",
    "        class_train_y,\n",
    "        class_test_y,\n",
    "        class_train_prob_y,\n",
    "        class_test_prob_y,\n",
    "    ) = learner.decision_tree(\n",
    "        selected_train_X, y_train, selected_test_X, gridsearch=False\n",
    "    )\n",
    "    performance_test_dt = accuracy_score(y_test, class_test_y)\n",
    "\n",
    "    print(\"\\tTraining naive bayes\")\n",
    "    (\n",
    "        class_train_y,\n",
    "        class_test_y,\n",
    "        class_train_prob_y,\n",
    "        class_test_prob_y,\n",
    "    ) = learner.naive_bayes(selected_train_X, y_train, selected_test_X)\n",
    "\n",
    "    performance_test_nb = accuracy_score(y_test, class_test_y)\n",
    "\n",
    "    # Save results to dataframe\n",
    "    models = [\"NN\", \"RF\", \"KNN\", \"DT\", \"NB\"]\n",
    "    new_scores = pd.DataFrame(\n",
    "        {\n",
    "            \"model\": models,\n",
    "            \"feature_set\": f,\n",
    "            \"accuracy\": [\n",
    "                performance_test_nn,\n",
    "                performance_test_rf,\n",
    "                performance_test_knn,\n",
    "                performance_test_dt,\n",
    "                performance_test_nb,\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "    score_df = pd.concat([score_df, new_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAANGCAYAAAARSHTOAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAZnpJREFUeJzt3Xl8Tdf+//H3kTkiCVKJIZIoNVNDRah5SJWWotKWtKmpaE3RQShiqBBjUW6NodXS0tLeL1rVmi5XSwXF11SaVGMeYowM5/eHn/PtaRKEFTG8no/HftRee+21Pjs9t/G+a+99LFar1SoAAAAAwF3Jl9cFAAAAAMDDgHAFAAAAAAYQrgAAAADAAMIVAAAAABhAuAIAAAAAAwhXAAAAAGAA4QoAAAAADCBcAQAAAIABhCsAAAAAMIBwBQAAAAAG5Gm4Wr9+vZ577jkVK1ZMFotFy5Ytu+U569atU40aNeTq6qpSpUrpX//6V6Y+S5cuVYUKFeTi4qIKFSro66+/zoXqAQAAAOD/5Gm4unTpkqpWrapp06bdVv/Dhw/r2WefVb169bR9+3YNGjRIffr00dKlS219Nm/erLCwMIWHh2vHjh0KDw9Xhw4dtGXLlty6DAAAAACQxWq1WvO6CEmyWCz6+uuv1aZNm2z7vPfee/rmm2+0d+9eW1uPHj20Y8cObd68WZIUFham5ORkrVy50tbnmWeeUcGCBfX555/nWv0AAAAAHm2OeV1ATmzevFnNmze3awsNDdWcOXOUmpoqJycnbd68Wf3798/UZ/LkydmOm5KSopSUFNt+RkaGzpw5o8KFC8tisRi9BgAAAAAPDqvVqgsXLqhYsWLKl+/mN/49UOHq2LFj8vX1tWvz9fVVWlqaTp06paJFi2bb59ixY9mOGxMTo+HDh+dKzQAAAAAefImJiSpRosRN+zxQ4UpSppWkG3c1/r09qz43W4GKiopSZGSkbf/8+fMqWbKkEhMT5enpaaJsAAAAAA+g5ORk+fv7q0CBArfs+0CFKz8/v0wrUCdOnJCjo6MKFy580z7/XM36OxcXF7m4uGRq9/T0JFwBAAAAuK3HhR6o77kKCQnR6tWr7dq+//571axZU05OTjftU6dOnXtWJwAAAIBHT56uXF28eFEHDx607R8+fFjx8fEqVKiQSpYsqaioKB09elQLFiyQdP3NgNOmTVNkZKS6deumzZs3a86cOXZvAezbt6/q16+vsWPHqnXr1lq+fLl++OEHbdy48Z5fHwAAAIBHR56uXG3dulXVqlVTtWrVJEmRkZGqVq2ahg4dKklKSkpSQkKCrX9QUJBWrFihtWvX6sknn9TIkSM1ZcoUtWvXztanTp06WrRokebNm6cqVaooLi5OixcvVnBw8L29OAAAAACPlPvme67uJ8nJyfLy8tL58+d55goAAAB4hOUkGzxQz1wBAAAAwP2KcAUAAAAABhCuAAAAAMAAwhUAAAAAGEC4AgAAAAADCFcAAAAAYADhCgAAAAAMIFwBAAAAgAGEKwAAAAAwgHAFAAAAAAYQrgAAAADAAMIVAAAAABhAuAIAAAAAAwhXAAAAAGAA4QoAAAAADCBcAQAAAIABhCsAAAAAMIBwBQAAAAAGEK4AAAAAwADCFQAAAAAYQLgCAAAAAAMIVwAAAABgAOEKAAAAAAwgXAEAAACAAYQrAAAAADCAcAUAAAAABhCuAAAAAMAAwhUAAAAAGEC4AgAAAAADCFcAAAAAYADhCgAAAAAMIFwBAAAAgAGEKwAAAAAwgHAFAAAAAAYQrgAAAADAAMIVAAAAABhAuAIAAAAAAwhXAAAAAGAA4QoAAAAADCBcAQAAAIABhCsAAAAAMIBwBQAAAAAGEK4AAAAAwADCFQAAAAAYQLgCAAAAAAMIVwAAAABgAOEKAAAAAAwgXAEAAACAAYQrAAAAADCAcAUAAAAABhCuAAAAAMAAwhUAAAAAGEC4AgAAAAADCFcAAAAAYADhCgAAAAAMIFwBAAAAgAGEKwAAAAAwgHAFAAAAAAYQrgAAAADAAMIVAAAAABhAuAIAAAAAAwhXAAAAAGAA4QoAAAAADCBcAQAAAIABhCsAAAAAMIBwBQAAAAAGEK4AAAAAwADCFQAAAAAYQLgCAAAAAAMIVwAAAABgAOEKAAAAAAwgXAEAAACAAYQrAAAAADCAcAUAAAAABhCuAAAAAMAAwhUAAAAAGEC4AgAAAAADCFcAAAAAYADhCgAAAAAMIFwBAAAAgAGEKwAAAAAwgHAFAAAAAAYQrgAAAADAAMIVAAAAABhAuAIAAAAAAwhXAAAAAGAA4QoAAAAADCBcAQAAAIABhCsAAAAAMIBwBQAAAAAGEK4AAAAAwADCFQAAAAAYQLgCAAAAAAMIVwAAAABgAOEKAAAAAAwgXAEAAACAAYQrAAAAADCAcAUAAAAABhCuAAAAAMAAwhUAAAAAGEC4AgAAAAADCFcAAAAAYADhCgAAAAAMIFwBAAAAgAGEKwAAAAAwgHAFAAAAAAYQrgAAAADAAMIVAAAAABhAuAIAAAAAAwhXAAAAAGAA4QoAAAAADCBcAQAAAIABhCsAAAAAMIBwBQAAAAAGEK4AAAAAwADCFQAAAAAYQLgCAAAAAAPyPFxNnz5dQUFBcnV1VY0aNbRhw4ab9v/oo49Uvnx5ubm5qWzZslqwYIHd8bi4OFkslkzb1atXc/MyAAAAADziHPNy8sWLF6tfv36aPn266tatq48//lgtWrTQnj17VLJkyUz9Z8yYoaioKM2aNUtPPfWUfv75Z3Xr1k0FCxbUc889Z+vn6empffv22Z3r6uqa69cDAAAA4NFlsVqt1ryaPDg4WNWrV9eMGTNsbeXLl1ebNm0UExOTqX+dOnVUt25djRs3ztbWr18/bd26VRs3bpR0feWqX79+Onfu3B3XlZycLC8vL50/f16enp53PA4AAACAB1tOskGe3RZ47do1bdu2Tc2bN7drb968uTZt2pTlOSkpKZlWoNzc3PTzzz8rNTXV1nbx4kUFBASoRIkSatWqlbZv337TWlJSUpScnGy3AQAAAEBO5Fm4OnXqlNLT0+Xr62vX7uvrq2PHjmV5TmhoqGbPnq1t27bJarVq69atmjt3rlJTU3Xq1ClJUrly5RQXF6dvvvlGn3/+uVxdXVW3bl0dOHAg21piYmLk5eVl2/z9/c1dKAAAAIBHQp6/0MJisdjtW63WTG03DBkyRC1atFDt2rXl5OSk1q1bKyIiQpLk4OAgSapdu7Y6deqkqlWrql69evriiy/0xBNPaOrUqdnWEBUVpfPnz9u2xMREMxcHAAAA4JGRZ+HKx8dHDg4OmVapTpw4kWk16wY3NzfNnTtXly9f1pEjR5SQkKDAwEAVKFBAPj4+WZ6TL18+PfXUUzdduXJxcZGnp6fdBgAAAAA5kWfhytnZWTVq1NDq1avt2levXq06derc9FwnJyeVKFFCDg4OWrRokVq1aqV8+bK+FKvVqvj4eBUtWtRY7QAAAADwT3n6KvbIyEiFh4erZs2aCgkJ0cyZM5WQkKAePXpIun673tGjR23fZbV//379/PPPCg4O1tmzZzVx4kT99ttvmj9/vm3M4cOHq3bt2ipTpoySk5M1ZcoUxcfH66OPPsqTawQAAADwaMjTcBUWFqbTp09rxIgRSkpKUqVKlbRixQoFBARIkpKSkpSQkGDrn56ergkTJmjfvn1ycnJSo0aNtGnTJgUGBtr6nDt3Tt27d9exY8fk5eWlatWqaf369apVq9a9vjwAAAAAj5A8/Z6r+xXfcwUAAABAekC+5woAAAAAHiaEKwAAAAAwgHAFAAAAAAYQrgAAAADAAMIVAAAAABhAuAIAAAAAAwhXAAAAAGAA4QoAAAAADCBcAQAAAIABhCsAAAAAMIBwBQAAAAAGEK4AAAAAwADCFQAAAAAYQLgCAAAAAAMc87qAh9WAlQtyfY4JLV7N9TkAAAAA3B5WrgAAAADAAMIVAAAAABhAuAIAAAAAAwhXAAAAAGAA4QoAAAAADCBcAQAAAIABvIr9AXZixru5On6RnrG5Oj4AAADwMGHlCgAAAAAMIFwBAAAAgAGEKwAAAAAwgHAFAAAAAAYQrgAAAADAAMIVAAAAABhAuAIAAAAAAwhXAAAAAGAA4QoAAAAADCBcAQAAAIABhCsAAAAAMIBwBQAAAAAGEK4AAAAAwADCFQAAAAAYQLgCAAAAAAMIVwAAAABgAOEKAAAAAAwgXAEAAACAAYQrAAAAADCAcAUAAAAABhCuAAAAAMAAwhUAAAAAGEC4AgAAAAADCFcAAAAAYADhCgAAAAAMIFwBAAAAgAGEKwAAAAAwwDGvCwBwdwasXJDrc0xo8WquzwEAAPCgY+UKAAAAAAwgXAEAAACAAYQrAAAAADCAcAUAAAAABhCuAAAAAMAAwhUAAAAAGEC4AgAAAAADCFcAAAAAYADhCgAAAAAMIFwBAAAAgAGEKwAAAAAwgHAFAAAAAAYQrgAAAADAAMIVAAAAABjgmNcFAAAeDANWLsj1OSa0eDXX5wAAILewcgUAAAAABrByBeCWTsx4N1fHL9IzNlfHx4ODzxoA4EHGyhUAAAAAGEC4AgAAAAADCFcAAAAAYADhCgAAAAAMIFwBAAAAgAGEKwAAAAAwgHAFAAAAAAYQrgAAAADAAMIVAAAAABhAuAIAAAAAAwhXAAAAAGAA4QoAAAAADCBcAQAAAIABjnldAO5f0z/dmOtz9Or0dK7PAQAAANwLrFwBAAAAgAGEKwAAAAAwgHAFAAAAAAYQrgAAAADAAMIVAAAAABhAuAIAAAAAAwhXAAAAAGAA4QoAAAAADCBcAQAAAIABhCsAAAAAMIBwBQAAAAAGEK4AAAAAwADCFQAAAAAYQLgCAAAAAAMIVwAAAABgAOEKAAAAAAwgXAEAAACAAYQrAAAAADCAcAUAAAAABjjmdQEAMP3Tjbk+R69OT+f6HAAA4NHGyhUAAAAAGEC4AgAAAAADCFcAAAAAYADhCgAAAAAMIFwBAAAAgAGEKwAAAAAwgHAFAAAAAAYQrgAAAADAAMIVAAAAABhAuAIAAAAAAwhXAAAAAGAA4QoAAAAADCBcAQAAAIABhCsAAAAAMIBwBQAAAAAGEK4AAAAAwADCFQAAAAAYkOfhavr06QoKCpKrq6tq1KihDRs23LT/Rx99pPLly8vNzU1ly5bVggULMvVZunSpKlSoIBcXF1WoUEFff/11bpUPAAAAAJLyOFwtXrxY/fr10+DBg7V9+3bVq1dPLVq0UEJCQpb9Z8yYoaioKEVHR2v37t0aPny43nzzTX377be2Pps3b1ZYWJjCw8O1Y8cOhYeHq0OHDtqyZcu9uiwAAAAAj6A8DVcTJ05Uly5d1LVrV5UvX16TJ0+Wv7+/ZsyYkWX/Tz75RG+88YbCwsJUqlQpvfTSS+rSpYvGjh1r6zN58mQ1a9ZMUVFRKleunKKiotSkSRNNnjw52zpSUlKUnJxstwEAAABATuRZuLp27Zq2bdum5s2b27U3b95cmzZtyvKclJQUubq62rW5ubnp559/VmpqqqTrK1f/HDM0NDTbMSUpJiZGXl5ets3f3/9OLgkAAADAIyzPwtWpU6eUnp4uX19fu3ZfX18dO3Ysy3NCQ0M1e/Zsbdu2TVarVVu3btXcuXOVmpqqU6dOSZKOHTuWozElKSoqSufPn7dtiYmJd3l1AAAAAB41jnldgMVisdu3Wq2Z2m4YMmSIjh07ptq1a8tqtcrX11cRERGKjY2Vg4PDHY0pSS4uLnJxcbmLqwAAAADwqMuzlSsfHx85ODhkWlE6ceJEppWnG9zc3DR37lxdvnxZR44cUUJCggIDA1WgQAH5+PhIkvz8/HI0JgAAAACYkGfhytnZWTVq1NDq1avt2levXq06derc9FwnJyeVKFFCDg4OWrRokVq1aqV8+a5fSkhISKYxv//++1uOCQAAAAB3I09vC4yMjFR4eLhq1qypkJAQzZw5UwkJCerRo4ek689CHT161PZdVvv379fPP/+s4OBgnT17VhMnTtRvv/2m+fPn28bs27ev6tevr7Fjx6p169Zavny5fvjhB23cuDFPrhEAAADAoyFPw1VYWJhOnz6tESNGKCkpSZUqVdKKFSsUEBAgSUpKSrL7zqv09HRNmDBB+/btk5OTkxo1aqRNmzYpMDDQ1qdOnTpatGiR3n//fQ0ZMkSPP/64Fi9erODg4Ht9eQCA+8z0T3P//2jr1enpXJ8DAHB/yvMXWvTq1Uu9evXK8lhcXJzdfvny5bV9+/Zbjtm+fXu1b9/eRHkAAAAAcFvy9EuEAQAAAOBhQbgCAAAAAAMIVwAAAABgAOEKAAAAAAwgXAEAAACAAYQrAAAAADCAcAUAAAAABhCuAAAAAMAAwhUAAAAAGEC4AgAAAAADCFcAAAAAYADhCgAAAAAMIFwBAAAAgAGEKwAAAAAwgHAFAAAAAAYQrgAAAADAAMIVAAAAABhAuAIAAAAAAwhXAAAAAGAA4QoAAAAADCBcAQAAAIABhCsAAAAAMIBwBQAAAAAGEK4AAAAAwADCFQAAAAAYQLgCAAAAAAMIVwAAAABgAOEKAAAAAAwgXAEAAACAAYQrAAAAADCAcAUAAAAABhCuAAAAAMAAwhUAAAAAGEC4AgAAAAADCFcAAAAAYADhCgAAAAAMIFwBAAAAgAGEKwAAAAAwgHAFAAAAAAY45nUBAAAAfzdg5YJcn2NCi1dzfQ4Ajx5WrgAAAADAAMIVAAAAABhAuAIAAAAAAwhXAAAAAGAA4QoAAAAADCBcAQAAAIABhCsAAAAAMIBwBQAAAAAGEK4AAAAAwADCFQAAAAAYQLgCAAAAAAMc87oAAACAe+3EjHdzdfwiPWNzdXwA9ydWrgAAAADAAMIVAAAAABhAuAIAAAAAAwhXAAAAAGAA4QoAAAAADCBcAQAAAIABhCsAAAAAMIBwBQAAAAAGEK4AAAAAwADCFQAAAAAYQLgCAAAAAAMIVwAAAABgAOEKAAAAAAwgXAEAAACAAYQrAAAAADCAcAUAAAAABhCuAAAAAMAAwhUAAAAAGEC4AgAAAAADCFcAAAAAYADhCgAAAAAMIFwBAAAAgAGEKwAAAAAwgHAFAAAAAAYQrgAAAADAAMIVAAAAABhAuAIAAAAAAwhXAAAAAGAA4QoAAAAADCBcAQAAAIABhCsAAAAAMIBwBQAAAAAGEK4AAAAAwADCFQAAAAAYQLgCAAAAAAMIVwAAAABgAOEKAAAAAAwgXAEAAACAAYQrAAAAADCAcAUAAAAABuQ4XAUGBmrEiBFKSEjIjXoAAAAA4IGU43A1YMAALV++XKVKlVKzZs20aNEipaSk5EZtAAAAAPDAyHG46t27t7Zt26Zt27apQoUK6tOnj4oWLaq33npLv/76a27UCAAAAAD3vTt+5qpq1ar68MMPdfToUQ0bNkyzZ8/WU089papVq2ru3LmyWq0m6wQAAACA+5rjnZ6Ympqqr7/+WvPmzdPq1atVu3ZtdenSRX/99ZcGDx6sH374QZ999pnJWgEAAADgvpXjcPXrr79q3rx5+vzzz+Xg4KDw8HBNmjRJ5cqVs/Vp3ry56tevb7RQAACAB8X0Tzfm+hy9Oj2d63MAyJkch6unnnpKzZo104wZM9SmTRs5OTll6lOhQgW99NJLRgoEAAAAgAdBjsPV77//roCAgJv2yZ8/v+bNm3fHRQEAAADAgybHL7Q4ceKEtmzZkql9y5Yt2rp1q5GiAAAAAOBBk+Nw9eabbyoxMTFT+9GjR/Xmm28aKQoAAAAAHjQ5Dld79uxR9erVM7VXq1ZNe/bsMVIUAAAAADxochyuXFxcdPz48UztSUlJcnS84ze7AwAAAMADLcfhqlmzZoqKitL58+dtbefOndOgQYPUrFkzo8UBAAAAwIMix0tNEyZMUP369RUQEKBq1apJkuLj4+Xr66tPPvnEeIEAAAAA8CDIcbgqXry4du7cqYULF2rHjh1yc3PT66+/rpdffjnL77wCAAAAgEfBHT0klT9/fnXv3t10LQAAAADwwLrjN1Ds2bNHCQkJunbtml37888/f9dFAQAAAMCDJsfh6vfff9cLL7ygXbt2yWKxyGq1SpIsFoskKT093WyFAAAAAPAAyPHbAvv27augoCAdP35c7u7u2r17t9avX6+aNWtq7dq1uVAiAAAAANz/crxytXnzZv3444967LHHlC9fPuXLl09PP/20YmJi1KdPH23fvj036gQAAACA+1qOV67S09Pl4eEhSfLx8dFff/0lSQoICNC+ffvMVgcAAAAAD4gcr1xVqlRJO3fuVKlSpRQcHKzY2Fg5Oztr5syZKlWqVG7UCAAAAAD3vRyHq/fff1+XLl2SJI0aNUqtWrVSvXr1VLhwYS1evNh4gQAAAADwIMhxuAoNDbX9uVSpUtqzZ4/OnDmjggUL2t4YCAAAAACPmhw9c5WWliZHR0f99ttvdu2FChUiWAEAAAB4pOUoXDk6OiogIMDod1lNnz5dQUFBcnV1VY0aNbRhw4ab9l+4cKGqVq0qd3d3FS1aVK+//rpOnz5tOx4XFyeLxZJpu3r1qrGaAQAAAOCfcvy2wPfff19RUVE6c+bMXU++ePFi9evXT4MHD9b27dtVr149tWjRQgkJCVn237hxo1599VV16dJFu3fv1pdffqlffvlFXbt2tevn6emppKQku83V1fWu6wUAAACA7OT4maspU6bo4MGDKlasmAICApQ/f36747/++uttjzVx4kR16dLFFo4mT56s7777TjNmzFBMTEym/v/9738VGBioPn36SJKCgoL0xhtvKDY21q6fxWKRn59fTi8NAAAAAO5YjsNVmzZtjEx87do1bdu2TQMHDrRrb968uTZt2pTlOXXq1NHgwYO1YsUKtWjRQidOnNCSJUvUsmVLu34XL1603b745JNPauTIkapWrVq2taSkpCglJcW2n5ycfBdXBgAAAOBRlONwNWzYMCMTnzp1Sunp6fL19bVr9/X11bFjx7I8p06dOlq4cKHCwsJ09epVpaWl6fnnn9fUqVNtfcqVK6e4uDhVrlxZycnJ+vDDD1W3bl3t2LFDZcqUyXLcmJgYDR8+3Mh1AQAAAHg05fiZK9P++ZZBq9Wa7ZsH9+zZoz59+mjo0KHatm2bVq1apcOHD6tHjx62PrVr11anTp1UtWpV1atXT1988YWeeOIJuwD2T1FRUTp//rxtS0xMNHNxAAAAAB4ZOV65ypcv301fu367bxL08fGRg4NDplWqEydOZFrNuiEmJkZ169bVO++8I0mqUqWK8ufPr3r16mnUqFEqWrRolvU+9dRTOnDgQLa1uLi4yMXF5bbqBgAAAICs5Dhcff3113b7qamp2r59u+bPn5+jW+ucnZ1Vo0YNrV69Wi+88IKtffXq1WrdunWW51y+fFmOjvYlOzg4SLq+4pUVq9Wq+Ph4Va5c+bZrAwAAAICcynG4yir4tG/fXhUrVtTixYvVpUuX2x4rMjJS4eHhqlmzpkJCQjRz5kwlJCTYbvOLiorS0aNHtWDBAknSc889p27dumnGjBkKDQ1VUlKS+vXrp1q1aqlYsWKSpOHDh6t27doqU6aMkpOTNWXKFMXHx+ujjz7K6aUCAAAAwG3LcbjKTnBwsLp165ajc8LCwnT69GmNGDFCSUlJqlSpklasWKGAgABJUlJSkt13XkVEROjChQuaNm2aBgwYIG9vbzVu3Fhjx4619Tl37py6d++uY8eOycvLS9WqVdP69etVq1YtMxcKAAAAAFkwEq6uXLmiqVOnqkSJEjk+t1evXurVq1eWx+Li4jK19e7dW7179852vEmTJmnSpEk5rgMAAAAA7kaOw1XBggXtXmhhtVp14cIFubu769NPPzVaHB5+B2esy/U5SvdskOtzAAAAADkOV5MmTbILV/ny5dNjjz2m4OBgFSxY0GhxAAAAAPCgyHG4ioiIyIUyAAAAAODBluMvEZ43b56+/PLLTO1ffvml5s+fb6QoAAAAAHjQ5DhcjRkzRj4+PpnaixQpotGjRxspCgAAAAAeNDkOV3/88YeCgoIytQcEBNi9Nh0AAAAAHiU5DldFihTRzp07M7Xv2LFDhQsXNlIUAAAAADxochyuXnrpJfXp00c//fST0tPTlZ6erh9//FF9+/bVSy+9lBs1AgAAAMB9L8dvCxw1apT++OMPNWnSRI6O10/PyMjQq6++yjNXAAAAAB5ZOQ5Xzs7OWrx4sUaNGqX4+Hi5ubmpcuXKCggIyI36AAAAAOCBkONwdUOZMmVUpkwZk7UAAAAAwAMrx89ctW/fXmPGjMnUPm7cOL344otGigIAAACAB02Ow9W6devUsmXLTO3PPPOM1q9fb6QoAAAAAHjQ5DhcXbx4Uc7OzpnanZyclJycbKQoAAAAAHjQ5DhcVapUSYsXL87UvmjRIlWoUMFIUQAAAADwoMnxCy2GDBmidu3a6dChQ2rcuLEkac2aNfrss8+0ZMkS4wUCAAAAwIMgx+Hq+eef17JlyzR69GgtWbJEbm5uqlq1qn788Ud5enrmRo0AAAAAcN+7o1ext2zZ0vZSi3PnzmnhwoXq16+fduzYofT0dKMFAgAAAMCDIMfPXN3w448/qlOnTipWrJimTZumZ599Vlu3bjVZGwAAAAA8MHK0cvXnn38qLi5Oc+fO1aVLl9ShQwelpqZq6dKlvMwCAAAAwCPttleunn32WVWoUEF79uzR1KlT9ddff2nq1Km5WRsAAAAAPDBue+Xq+++/V58+fdSzZ0+VKVMmN2sCAAAAgAfOba9cbdiwQRcuXFDNmjUVHBysadOm6eTJk7lZGwAAAAA8MG47XIWEhGjWrFlKSkrSG2+8oUWLFql48eLKyMjQ6tWrdeHChdysEwAAAADuazl+W6C7u7s6d+6sjRs3ateuXRowYIDGjBmjIkWK6Pnnn8+NGgEAAADgvnfHr2KXpLJlyyo2NlZ//vmnPv/8c1M1AQAAAMAD567C1Q0ODg5q06aNvvnmGxPDAQAAAMADx0i4AgAAAIBHHeEKAAAAAAwgXAEAAACAAYQrAAAAADCAcAUAAAAABhCuAAAAAMAAwhUAAAAAGEC4AgAAAAADCFcAAAAAYADhCgAAAAAMIFwBAAAAgAGEKwAAAAAwgHAFAAAAAAYQrgAAAADAAMIVAAAAABhAuAIAAAAAAwhXAAAAAGAA4QoAAAAADCBcAQAAAIABhCsAAAAAMIBwBQAAAAAGEK4AAAAAwADCFQAAAAAYQLgCAAAAAAMIVwAAAABgAOEKAAAAAAwgXAEAAACAAYQrAAAAADCAcAUAAAAABhCuAAAAAMAAwhUAAAAAGEC4AgAAAAADCFcAAAAAYADhCgAAAAAMIFwBAAAAgAGEKwAAAAAwgHAFAAAAAAYQrgAAAADAAMIVAAAAABhAuAIAAAAAAwhXAAAAAGAA4QoAAAAADCBcAQAAAIABhCsAAAAAMIBwBQAAAAAGEK4AAAAAwADCFQAAAAAYQLgCAAAAAAMIVwAAAABgAOEKAAAAAAwgXAEAAACAAYQrAAAAADCAcAUAAAAABhCuAAAAAMAAwhUAAAAAGEC4AgAAAAADCFcAAAAAYADhCgAAAAAMIFwBAAAAgAGEKwAAAAAwgHAFAAAAAAYQrgAAAADAAMIVAAAAABhAuAIAAAAAAwhXAAAAAGAA4QoAAAAADHDM6wIAAHiYHJyxLtfnKN2zQa7PAQDIOVauAAAAAMAAwhUAAAAAGEC4AgAAAAADCFcAAAAAYADhCgAAAAAMIFwBAAAAgAGEKwAAAAAwgHAFAAAAAAYQrgAAAADAAMIVAAAAABhAuAIAAAAAAwhXAAAAAGAA4QoAAAAADCBcAQAAAIABhCsAAAAAMIBwBQAAAAAGEK4AAAAAwADCFQAAAAAYQLgCAAAAAAMIVwAAAABgAOEKAAAAAAwgXAEAAACAAYQrAAAAADAgz8PV9OnTFRQUJFdXV9WoUUMbNmy4af+FCxeqatWqcnd3V9GiRfX666/r9OnTdn2WLl2qChUqyMXFRRUqVNDXX3+dm5cAAAAAAHkbrhYvXqx+/fpp8ODB2r59u+rVq6cWLVooISEhy/4bN27Uq6++qi5dumj37t368ssv9csvv6hr1662Pps3b1ZYWJjCw8O1Y8cOhYeHq0OHDtqyZcu9uiwAAAAAj6A8DVcTJ05Uly5d1LVrV5UvX16TJ0+Wv7+/ZsyYkWX///73vwoMDFSfPn0UFBSkp59+Wm+88Ya2bt1q6zN58mQ1a9ZMUVFRKleunKKiotSkSRNNnjz5Hl0VAAAAgEdRnoWra9euadu2bWrevLlde/PmzbVp06Ysz6lTp47+/PNPrVixQlarVcePH9eSJUvUsmVLW5/NmzdnGjM0NDTbMSUpJSVFycnJdhsAAAAA5ESehatTp04pPT1dvr6+du2+vr46duxYlufUqVNHCxcuVFhYmJydneXn5ydvb29NnTrV1ufYsWM5GlOSYmJi5OXlZdv8/f3v4soAAAAAPIry/IUWFovFbt9qtWZqu2HPnj3q06ePhg4dqm3btmnVqlU6fPiwevToccdjSlJUVJTOnz9v2xITE+/wagAAAAA8qhzzamIfHx85ODhkWlE6ceJEppWnG2JiYlS3bl298847kqQqVaoof/78qlevnkaNGqWiRYvKz88vR2NKkouLi1xcXO7yigAAAAA8yvJs5crZ2Vk1atTQ6tWr7dpXr16tOnXqZHnO5cuXlS+ffckODg6Srq9OSVJISEimMb///vtsxwQAAAAAE/Js5UqSIiMjFR4erpo1ayokJEQzZ85UQkKC7Ta/qKgoHT16VAsWLJAkPffcc+rWrZtmzJih0NBQJSUlqV+/fqpVq5aKFSsmSerbt6/q16+vsWPHqnXr1lq+fLl++OEHbdy4Mc+uEwAAAMDDL0/DVVhYmE6fPq0RI0YoKSlJlSpV0ooVKxQQECBJSkpKsvvOq4iICF24cEHTpk3TgAED5O3trcaNG2vs2LG2PnXq1NGiRYv0/vvva8iQIXr88ce1ePFiBQcH3/PrAwAAAPDoyNNwJUm9evVSr169sjwWFxeXqa13797q3bv3Tcds37692rdvb6I8AAAAALgtef62QAAAAAB4GBCuAAAAAMAAwhUAAAAAGEC4AgAAAAADCFcAAAAAYADhCgAAAAAMIFwBAAAAgAGEKwAAAAAwgHAFAAAAAAYQrgAAAADAAMe8LgDIbZ9s6Z7rc4QHz8z1OQAAAHB/Y+UKAAAAAAwgXAEAAACAAYQrAAAAADCAcAUAAAAABhCuAAAAAMAAwhUAAAAAGEC4AgAAAAADCFcAAAAAYADhCgAAAAAMIFwBAAAAgAGEKwAAAAAwgHAFAAAAAAYQrgAAAADAAMIVAAAAABhAuAIAAAAAAwhXAAAAAGAA4QoAAAAADCBcAQAAAIABhCsAAAAAMIBwBQAAAAAGOOZ1AQAAIGc+2dI91+cID56Z63MAwMOGlSsAAAAAMIBwBQAAAAAGEK4AAAAAwADCFQAAAAAYQLgCAAAAAAMIVwAAAABgAOEKAAAAAAwgXAEAAACAAYQrAAAAADCAcAUAAAAABhCuAAAAAMAAwhUAAAAAGEC4AgAAAAADCFcAAAAAYADhCgAAAAAMIFwBAAAAgAGOeV0AANwLB2esy/U5SvdskOtzAACA+xcrVwAAAABgAOEKAAAAAAwgXAEAAACAAYQrAAAAADCAcAUAAAAABhCuAAAAAMAAwhUAAAAAGEC4AgAAAAADCFcAAAAAYADhCgAAAAAMIFwBAAAAgAGOeV0AADwsPtnSPdfnCA+emetzAACAO8PKFQAAAAAYQLgCAAAAAAMIVwAAAABgAOEKAAAAAAwgXAEAAACAAYQrAAAAADCAcAUAAAAABhCuAAAAAMAAwhUAAAAAGEC4AgAAAAADCFcAAAAAYADhCgAAAAAMIFwBAAAAgAGEKwAAAAAwgHAFAAAAAAYQrgAAAADAAMIVAAAAABhAuAIAAAAAAwhXAAAAAGAA4QoAAAAADCBcAQAAAIABhCsAAAAAMIBwBQAAAAAGEK4AAAAAwADCFQAAAAAYQLgCAAAAAAMIVwAAAABgAOEKAAAAAAwgXAEAAACAAYQrAAAAADCAcAUAAAAABhCuAAAAAMAAwhUAAAAAGOCY1wUAAAAg5w7OWJfrc5Tu2SDX5wAeJqxcAQAAAIABhCsAAAAAMIBwBQAAAAAGEK4AAAAAwADCFQAAAAAYQLgCAAAAAAMIVwAAAABgAOEKAAAAAAwgXAEAAACAAYQrAAAAADCAcAUAAAAABhCuAAAAAMAAwhUAAAAAGEC4AgAAAAADCFcAAAAAYADhCgAAAAAMIFwBAAAAgAGEKwAAAAAwgHAFAAAAAAYQrgAAAADAAMIVAAAAABhAuAIAAAAAAwhXAAAAAGBAnoer6dOnKygoSK6urqpRo4Y2bNiQbd+IiAhZLJZMW8WKFW194uLisuxz9erVe3E5AAAAAB5Rjnk5+eLFi9WvXz9Nnz5ddevW1ccff6wWLVpoz549KlmyZKb+H374ocaMGWPbT0tLU9WqVfXiiy/a9fP09NS+ffvs2lxdXXPnIgAAAB5Sn2zpnutzhAfPzPU5gHslT8PVxIkT1aVLF3Xt2lWSNHnyZH333XeaMWOGYmJiMvX38vKSl5eXbX/ZsmU6e/asXn/9dbt+FotFfn5+t11HSkqKUlJSbPvJyck5vRQAAAAAj7g8uy3w2rVr2rZtm5o3b27X3rx5c23atOm2xpgzZ46aNm2qgIAAu/aLFy8qICBAJUqUUKtWrbR9+/abjhMTE2MLbl5eXvL398/ZxQAAAAB45OVZuDp16pTS09Pl6+tr1+7r66tjx47d8vykpCStXLnStup1Q7ly5RQXF6dvvvlGn3/+uVxdXVW3bl0dOHAg27GioqJ0/vx525aYmHhnFwUAAADgkZWntwVK12/h+zur1ZqpLStxcXHy9vZWmzZt7Npr166t2rVr2/br1q2r6tWra+rUqZoyZUqWY7m4uMjFxSXnxQMAAADA/5dnK1c+Pj5ycHDItEp14sSJTKtZ/2S1WjV37lyFh4fL2dn5pn3z5cunp5566qYrVwAAAABwt/IsXDk7O6tGjRpavXq1Xfvq1atVp06dm567bt06HTx4UF26dLnlPFarVfHx8SpatOhd1QsAAAAAN5OntwVGRkYqPDxcNWvWVEhIiGbOnKmEhAT16NFD0vVnoY4ePaoFCxbYnTdnzhwFBwerUqVKmcYcPny4ateurTJlyig5OVlTpkxRfHy8Pvroo3tyTQAAAAAeTXkarsLCwnT69GmNGDFCSUlJqlSpklasWGF7+19SUpISEhLszjl//ryWLl2qDz/8MMsxz507p+7du+vYsWPy8vJStWrVtH79etWqVSvXrwcAAADAoyvPX2jRq1cv9erVK8tjcXFxmdq8vLx0+fLlbMebNGmSJk2aZKo8AAAAALgtefbMFQAAAAA8TAhXAAAAAGAA4QoAAAAADCBcAQAAAIABef5CCwAAADwa8slJjnKXZLG1Xb16Ne8KAv4/Z2dn5ct39+tOhCsAAADkOh9LdRVyKqd8Fvu/fh4+fDiPKgL+T758+RQUFCRnZ+e7GodwBQAAgFzlY6muIi5V5eNTSM6uDvr7ylXB/MXzrjBAUkZGhv766y8lJSWpZMmSslgstz4pG4QrAAAA5Jp8clIhp3Ly8SkkDy+XTMddXV3zoCrA3mOPPaa//vpLaWlpcnJyuuNxeKEFAAAAco2j3JXP4vj/V6yA+9ON2wHT09PvahzCFQAAAHKR5R//BO4/d3Mr4N8RrgAAAADAAMIVAAAAABjACy0AAACQJ0ZvWC9p/T2Za0KLV+/43E2bNqlevXpq1qyZVq1aZXfsyJEjCgoK0vbt2/Xkk09mOjcuLk79+vXTuXPnbmuutWvXqlGjRpnaBw8erFGjRt1J+ZlYLBZ9/fXXatOmjZHx8H8IVwAAAMBNzJ07V71799bs2bOVkJCgkiVL5vqc+/btk6enp23fw8Mj1+fMqWvXrt3190I9bLgtEAAAAMjGpUuX9MUXX6hnz55q1aqV4uLi7sm8RYoUkZ+fn227Ea6OHj2qsLAwFSxYUIULF1br1q115MgR23m//PKLmjVrJh8fH3l5ealBgwb69ddfbccDAwMlSS+88IIsFottPyIiItNKVr9+/dSwYUPbfsOGDfXWW28pMjJSPj4+atasmSRpz549evbZZ+Xh4SFfX1+Fh4fr1KlTtvOWLFmiypUry83NTYULF1bTpk116dIlcz+s+wjhCgAAAMjG4sWLVbZsWZUtW1adOnXSvHnzZLVa86SWy5cvq1GjRvLw8ND69eu1ceNGeXh46JlnntG1a9ckSRcuXNBrr72mDRs26L///a/KlCmjZ599VhcuXJB0PXxJ0rx585SUlGTbv13z58+Xo6Oj/vOf/+jjjz9WUlKSGjRooCeffFJbt27VqlWrdPz4cXXo0EGSlJSUpJdfflmdO3fW3r17tXbtWrVt2zbPfoa5jdsCAQAAgGzMmTNHnTp1kiQ988wzunjxotasWaOmTZve1vnpyWckq1WpJ/68rf5pZ09KkkoUL27XfnDbf/Xtqu9ksWZoxuho26vD582bJ29vb61du1bNmzdX48aN7c77+OOPVbBgQa1bt06tWrXSY489Jkny9vaWn5/fbdX0d6VLl1ZsbKxtf+jQoapevbpGjx5ta5s7d678/f21f/9+Xbx4UWlpaWrbtq0CAgIkSZUrV87xvA8KwhUAAACQhX379unnn3/WV199JUlydHRUWFiY5s6de9vh6k79+M1SFfDIb9sv6O2lX3fu0qHDR1SoVLn/62ix6OrVqzp06JAk6cSJExo6dKh+/PFHHT9+XOnp6bp8+bISEhKM1FWzZk27/W3btumnn37K8pmwQ4cOqXnz5mrSpIkqV66s0NBQNW/eXO3bt1fBggWN1HO/IVwBAAAAWZgzZ47S0tJU/G+rSFarVU5OTjp79myuBoSgkv7y9vKya8vIyFD1KpU1f8YUW5tT4aKSZFuRioiI0MmTJzV58mQFBATIxcVFISEhttsGs5MvX75Mt+qlpqZm6pc/f367/YyMDD333HMaO3Zspr5FixaVg4ODVq9erU2bNun777/X1KlTNXjwYG3ZskVBQUE3relBRLgCAAAA/iEtLU0LFizQhAkT1Lx5c7tj7dq108KFC/XWW2/d05qqVa6sL5d/qyI+PvIsUECS5FSkhF2fDRs2aPr06Xr22WclSYmJiXYvl5AkJycnpaen27U99thj+u233+za4uPj5eTkdNOaqlevrqVLlyowMFCOjllHC4vForp166pu3boaOnSoAgIC9PXXXysyMvLWF/2A4YUWAAAAwD/8+9//1tmzZ9WlSxdVqlTJbmvfvr3mzJlj13/fvn2Kj4+3226sFqWnpyv+t9122559+3Nc08vtXlDhQoXU7tUu2vjfLTr8R4LWrVunvn376s8/rz/TVbp0aX3yySfau3evtmzZoo4dO8rNzc1unMDAQK1Zs0bHjh3T2bNnJUmNGzfW1q1btWDBAh04cEDDhg3LFLay8uabb+rMmTN6+eWX9fPPP+v333/X999/r86dOys9PV1btmzR6NGjtXXrViUkJOirr77SyZMnVb58+Rxf/4OAlSsAAADkiUH16quwR2Bel5GlOXPmqGnTpvL6x6150vWVq9GjR+vXX39VoUKFJEkvvfRSpn6HDx+WJF28dEm1mjxjdyzAv4QObN2co5rc3d304/IlGjQyRh06d9eFi5dUvHhxNWnSxPadWHPnzlX37t1VrVo1lSxZUqNHj9bbb79tN86ECRMUGRmpWbNmqXjx4jpy5IhCQ0M1ZMgQvfvuu7p69ao6d+6sV199Vbt27bppTcWKFdN//vMfvffeewoNDVVKSooCAgL0zDPPKF++fPL09NT69es1efJkJScnKyAgQBMmTFCLFi1ydO0PCsIVAAAA8A/ffvtttseqV69u93zSzV4r/upLHfTqSx1ue94GdUN07Xhitsf9ihTR3KmTbPv/vC2wWrVqmV6v3r59e7v95557Ts8991ymsYcPH67hw4dnO/fatWuzbC9TpoztpR//VL58ea1atSrbMR823BYIAAAAAAYQrgAAAADAAMIVAAAAABhAuAIAAAAAAwhXAAAAAGAA4QoAAAAADCBcAQAAAIABhCsAAAAAMIBwBQAAAAAGEK4AAACAXHYkIVHOvv6K/2232XGPHJHFYlF8fLzRce9WYGCgJk+efFdjrF27VhaLRefOnTNS073gmNcFAAAA4NGU/sl0nbhHcxXpGXtH5yUmJio6OlorV67UqVOnVLRoUbVp00ZDhw5V4cKFDVd5c1369Ne588laOn+Orc3f319JSUny8fG5p7Xcyi+//KL8+fPndRn3HCtXAAAAQBZ+//131axZU/v379fnn3+ugwcP6l//+pfWrFmjkJAQnTlzJq9LlIODg/z8/OToeH+tmTz22GNyd3fP6zLuOcIVAAAAkIU333xTzs7O+v7779WgQQOVLFlSLVq00A8//KCjR49q8ODBtr6BgYEaPXq0OnfurAIFCqhkyZKaOXNmluNarVaVD35aE6f/y679t73/Kxe/kjp05Eimc0aMm6hPFi/Rt6u+l7Ovv5x9/bXuP5sz3RZ441a67777TtWqVZObm5saN26sEydOaOXKlSpfvrw8PT318ssv6/Lly3Y1xcbGqlSpUnJzc1PVqlW1ZMkS2/EaNWpowoQJtv02bdrI0dFRycnJkqRjx47JYrFo3759tp/H328LtFgsmj17tl544QW5u7urTJky+uabb+yuccWKFXriiSfk5uamRo0a6UgWP4elS5eqYsWKcnFxUWBgoF1NU6dOVeXKlW37y5Ytk8Vi0UcffWRrCw0NVVRUVKZxTSFcAQAAAP9w5swZfffdd+rVq5fc3Nzsjvn5+aljx45avHixrFarrX3ChAmqWbOmtm/frl69eqlnz5763wMHM41tsVj02sthmr/oS7v2+Z8v1tO1a+nxwMBM50T2ekPtn2+l0MYNlbBrmxJ2bVPIUzWyrT86OlrTpk3Tpk2blJiYqA4dOmjy5Mn67LPP9D//8z9avXq1pk6dauv//vvva968eZoxY4Z2796t/v37q1OnTlq3bp0kqWHDhlq7dq2k60Fsw4YNKliwoDZu3ChJ+umnn+Tn56eyZctmW9Pw4cPVoUMH7dy5U88++6w6duxoW/1LTExU27Zt9eyzzyo+Pl5du3bVwIED7c7ftm2bOnTooJdeekm7du1SdHS0hgwZori4OFuNu3fv1qlTpyRJ69atk4+Pj+0a0tLStGnTJjVo0CDbGu8W4QoAAAD4hwMHDlxfYSpfPsvj5cuX19mzZ3Xy5Elb27PPPqtevXqpdOnSeu+99+Tj46P1mzZnef5rL3fQ/oOH9Muv2yVJqamp+mzJ13rt5bAs+3vkzy83N1c5OzvLr0gR+RUpImdn52zrHzVqlOrWratq1aqpS5cuWrdunWbMmKFq1aqpXr16at++vX766SdJ0qVLlzRx4kTNnTtXoaGhKlWqlCIiItSpUyd9/PHHkq4Hlw0bNigjI0M7d+6Ug4ODwsPDbYFr7dq1twwtERERevnll1W6dGmNHj1aly5d0s8//yxJmjFjhkqVKqVJkyapbNmy6tixoyIiIuzOnzhxopo0aaIhQ4boiSeeUEREhN566y2NGzdOklSpUiUVLlzYFqbWrl2rAQMG2PZ/+eUXXb16VU8//fRN67wbhCsAAAAgh26sWFksFltblSpVbH+2WCzy8/PTiVOnszy/qK+vWjRtrLjPv5Ak/c/qH3Q1JUXtn2tlpL6/1+Lr6yt3d3eVKlXKru3EieuvE9mzZ4+uXr2qZs2aycPDw7YtWLBAhw4dkiTVr19fFy5c0Pbt27Vu3To1aNBAjRo1sgsytwpXf68pf/78KlCggK2GvXv3qnbt2nY/z5CQELvz9+7dq7p169q11a1bVwcOHFB6erosFovq16+vtWvX6ty5c9q9e7d69Oih9PR07d27V2vXrlX16tXl4eFx2z/HnCJcAQAAAP9QunRpWSwW7dmzJ8vj//u//6uCBQvavaXPycnJro/FYlFGRka2c3Tu+LK+WPaNrly5ovmff6EXWz8nd3e3bPvnxN9rsVgsN63txj//53/+R/Hx8bZtz549tueuvLy89OSTT2rt2rVat26dGjZsqHr16ik+Pl4HDhzQ/v371bBhw9uu6Z81/P32yuxYrVa78JXVeTduX9ywYYOqVq0qb29v1a9fX+vWrdPatWtvWePdIlwBAAAA/1C4cGE1a9ZM06dP15UrV+yOHTt2TAsXLlRYWFimv+znRIumjZXf3U0fz/9E3/24VhHZ3BJ4g7OTs9LTsw9rd6pChQpycXFRQkKCSpcubbf5+/vb+jVs2FA//fST1q9fr4YNG8rb21sVKlTQqFGjVKRIkWxvobzdGv773//atf1zv0KFCrZnvG7YtGmTnnjiCTk4ONhq3L17t5YsWWILUg0aNNAPP/yQ689bSYQrAAAAIEvTpk1TSkqKQkNDtX79eiUmJmrVqlVq1qyZihcvrg8++OCuxndwcFB42It6/4OxejwoULVv8oIKSQrwL6Hf9u7VvoOHdOr0GaWmpt7V/DcUKFBAb7/9tvr376/58+fr0KFD2r59uz766CPNnz/f1q9hw4ZatWqVLBaLKlSoYGtbuHDhXYeWHj166NChQ4qMjNS+ffv02Wef2V5UccOAAQO0Zs0ajRw5Uvv379f8+fM1bdo0vf3227Y+N567WrhwoS1cNWzYUMuWLdOVK1dy9XkriS8RBgAAQB5xCO+lwh6BeV1GtsqUKaOtW7cqOjpaYWFhOn36tPz8/NSmTRsNGzZMhQoVuus5Xn/lJY39cNotV60kqUunV7R+02aFNG+pi5cuafVXX6h0tafuugZJGjlypIoUKaKYmBj9/vvv8vb2VvXq1TVo0CBbn/r160u6vhJ0Y8WuQYMGmjx58l2Hq5IlS2rp0qXq37+/pk+frlq1atlebX9D9erV9cUXX2jo0KEaOXKkihYtqhEjRti9+MJisahBgwZatmyZ6tWrJ+n6s15eXl4qVaqUPD0976rOWyFcAQAAANkICAjQvHnzbtkvq+9kio+PV+qJPyVJgSX9de14YqY+x06ckKOjozq92O6WczzmU1grvvjMrs2pSAm7544aNmyY6TmkiIiITG/ei46OVnR0tG3fYrGoT58+6tOnT7bze3l5KS0tza6tTZs2WT4v9c+fR1Z9zp07Z7ffqlUrtWpl/0KP119/3W6/Xbt2atfu5j+rv38/l3T92k6fzvrFIqYRrgAAAIB7LCUlRYl//aXoMePV/vlW8i3yWF6XBAN45goAAAC4xxZ/vVyV6jTU+QsXFDN00K1PwAOBlSsAAADgHnv1pQ569aUOeV0GDCNcAQAA4JGUeP5Urs/hl+sz4H7CbYEAAAAAYADhCgAAAAAMIFwBAAAAgAGEKwAAAAAwgHAFAAAAAAYQrgAAAADAAF7FDgAAgDyxeNmfkv68J3P16vR0js+J7PmWlny+OFP7+l+3KLBUqbuuacGiLzRgyHCdPLD7rse6UydOnNCQIUO0cuVKHT9+XAULFlTVqlUVHR2tkJCQ2xojOjpay5YtU3x8/E37ffXVVxo9erQOHjyo1NRUlSlTRgMGDFB4eLiBK7k/EK4AAACAbDRs2ljjP5pi11bYxyePqsleamqqnJyccnxeu3btlJqaqvnz56tUqVI6fvy41qxZozNnzhivsVChQho8eLDKlSsnZ2dn/fvf/9brr7+uIkWKKDQ01Ph8eYHbAgEAAIBsODu7qIivr93m4OAgSVq98js926CJyviWUN2qNTVpzDilpaXZzp01bYaqNWgq78AnVKpaLfV+b5AuXrokSVr3n83q2neAzicny9nXX86+/hoxbuL1OX39tXzFKrs6HitTUQsWfSFJOpKQKGdff325/Fs1bNhQrq6u+vTTTyVJ8+bNU/ny5eXq6qpy5cpp+vTp2V7buXPntHHjRo0dO1aNGjVSQECAatWqpaioKLVs2dLW7/z58+revbuKFCkiT09PNW7cWDt27JAkxcXFafjw4dqxY4csFossFovi4uKynK9hw4Z64YUXVL58eT3++OPq27evqlSpoo0bN+bkX8l9jZUrAAAAIIfWrflR/d7oqegxo1WrTm39cfiIovoOkCT1H/iOJMmSz6JJH4xQgH8JHUlIVO+BgxU14gNNHTtaIU/V0ISR0RoeO0G/bVorSfLInz9HNQweGaMJkydr3rx5cnFx0axZszRs2DBNmzZN1apV0/bt29WtWzflz59fr732WqbzPTw85OHhoWXLlql27dpycXHJ1Mdqtaply5YqVKiQVqxYIS8vL3388cdq0qSJ9u/fr7CwMP32229atWqVfvjhB0mSl5fXLWu3Wq368ccftW/fPo0dOzZH130/Y+UKAAAAyMaa775XueIBtq3Ha50lSVPHT1LPfn304isvKSAwUPUbNdSAwQO1MG6+7dyuvXqo4dN1FBRQUo3q1VX0e29ryTf/liQ5OzvLy7OALBaL/IoUkV+RIjkOV727d1Hbtm0VFBSkYsWKaeTIkZowYYKtrW3bturfv78+/vjjLM93dHRUXFyc5s+fL29vb9WtW1eDBg3Szp07bX1++ukn7dq1S19++aVq1qypMmXKaPz48fL29taSJUvk5uYmDw8POTo6ys/PT35+fnJzc8u25vPnz8vDw0POzs5q2bKlpk6dqmbNmuXouu9nrFwBAAAA2Qip97RGT4y17bu5u0uSdu3YqR3b4zVtwiTbsfT0DKVcvaorly/Lzd1dm9Zv1KzxE7V3/34lX7iotPQ0Xb2aokuXLit/fve7rq3Gk1Vsfz558qQSExPVpUsXdevWzdaelpZ205Wkdu3aqWXLltqwYYM2b96sVatWKTY2VrNnz1ZERIS2bdumixcvqnDhwnbnXblyRYcOHcpxzQUKFFB8fLwuXryoNWvWKDIyUqVKlVLDhg1zPNb9iHAFAAAAZMPd3T3LNwNmZGQoMupdtXiuZaZjLq6u+jMhUa91eFlvvNpR0e+9rYIFvbVpy8/q3v8dpaal3nROi8Uiq6x2bampmc9xd/+/gJaRkSFJmjVrloKDg+363XhGLDuurq5q1qyZmjVrpqFDh6pr164aNmyYIiIilJGRoaJFi2rt2rWZzvP29r7puFnJly+fSpcuLUl68skntXfvXsXExBCuAAAAgEdVpaqV9fuBg9m+kn3n9nilp6UpdvhQ5ct3/UmcJcu/tevj5OSk9PT0TOc+Vriwjh0/Yds/8PthXb5y5ab1+Pr6qnjx4vr999/VsWPHnF6OnQoVKmjZsmWSpOrVq+vYsWNydHRUYGBglv2dnZ2zvI7bYbValZKScoeV3n8IVwAAAEAO9Xv3bb0e1lFFixdXyzbPK1++fNq7e7f27dmrd94fpICgQKWlpemj2fPUsnlTbfplq2Yt+NRujMCS/rp46ZJ+XL9RVSpWkLubm9zd3dTw6TqaPne+gmtUV0ZGhgaNjLmt16xHR0erT58+8vT0VIsWLZSSkqKtW7fq7NmzioyMzNT/9OnTevHFF9W5c2dVqVJFBQoU0NatWxUbG6vWrVtLkpo2baqQkBC1adNGY8eOVdmyZfXXX39pxYoVatOmjWrWrKnAwEAdPnxY8fHxKlGihAoUKJDlyzFiYmJUs2ZNPf7447p27ZpWrFihBQsWaMaMGXf4b+H+Q7gCAABAnghrU0KFPQLzuow70qBJY81bvFCTY8frX1OmycnJUY+XKaOXXu0kSapYpbKGfjBS46dM1fujx6he7WCNHDxQnd/qZxsj5Kma6v5aJ3V8o5dOnzmr99/ur6HvRCp2+BB16ztAjVu3V1E/X00cNVy/7tx1y5q6du0qd3d3jRs3Tu+++67y58+vypUrq1+/fln29/DwUHBwsCZNmqRDhw4pNTVV/v7+6tatmwYNGiTp+i2KK1as0ODBg9W5c2edPHlSfn5+ql+/vnx9fSVdf27rq6++UqNGjXTu3DnNmzdPERERmea7dOmSevXqpT///FNubm4qV66cPv30U4WFheXsh38fs1itVuutuz1akpOT5eXlpfPnz8vT0/OOxhiwcoHhqjJ778hvuTr+kgLP5+r4ktT8wp0tIefE5uoLc32O8OCZuT5Hdvis3R4+a3ePz9rt4bN29/is3Z4H5bPmLG+VcnleJfyLytkl87M/eRmuEs+fyvU5/FKu5ur4TkVK5Or4j4qrV6/q8OHDCgoKkqurq92xnGQDXsUOAAAAAAYQrgAAAADAAMIVAAAAABhAuAIAAAAAAwhXAAAAAGAA4QoAAAAADCBcAQAAAIABhCsAAAAAMIBwBQAAAAAGEK4AAAAAwADHvC4AAAAAj6azn/yhs/rjnsxVumeDHJ8T2fMtLfl8cab29b9uUWCpUndd04JFX2jAkOE6eWD3XY91p06cOKEhQ4Zo5cqVOn78uAoWLKiqVasqOjpaISEhtzVGdHS0li1bpvj4+Jv2mzVrlhYsWKDffvtNklSjRg2NHj1atWrVutvLuG8QrgAAAIBsNGzaWOM/mmLXVtjHJ4+qyV5qaqqcnJxyfF67du2Umpqq+fPnq1SpUjp+/LjWrFmjM2fOGK9x7dq1evnll1WnTh25uroqNjZWzZs31+7du1W8eHHj8+UFbgsEAAAAsuHs7KIivr52m4ODgyRp9crv9GyDJirjW0J1q9bUpDHjlJaWZjt31rQZqtagqbwDn1CparXU+71BunjpkiRp3X82q2vfATqfnCxnX385+/prxLiJ1+f09dfyFavs6nisTEUtWPSFJOlIQqKcff315fJv1bBhQ7m6uurTTz+VJM2bN0/ly5eXq6urypUrp+nTp2d7befOndPGjRs1duxYNWrUSAEBAapVq5aioqLUsmVLW7/z58+re/fuKlKkiDw9PdW4cWPt2LFDkhQXF6fhw4drx44dslgsslgsiouLy3K+hQsXqlevXnryySdVrlw5zZo1SxkZGVqzZk1O/pXc11i5AgAAAHJo3Zof1e+NnooeM1q16tTWH4ePKKrvAElS/4HvSJIs+Sya9MEIBfiX0JGERPUeOFhRIz7Q1LGjFfJUDU0YGa3hsRP026a1kiSP/PlzVMPgkTGaMHmy5s2bJxcXF82aNUvDhg3TtGnTVK1aNW3fvl3dunVT/vz59dprr2U638PDQx4eHlq2bJlq164tFxeXTH2sVqtatmypQoUKacWKFfLy8tLHH3+sJk2aaP/+/QoLC9Nvv/2mVatW6YcffpAkeXl53Vb9ly9fVmpqqgoVKpSj676fsXIFAAAAZGPNd9+rXPEA29bjtc6SpKnjJ6lnvz568ZWXFBAYqPqNGmrA4IFaGDffdm7XXj3U8Ok6CgooqUb16ir6vbe15Jt/S5KcnZ3l5VlAFotFfkWKyK9IkRyHq97du6ht27YKCgpSsWLFNHLkSE2YMMHW1rZtW/Xv318ff/xxluc7OjoqLi5O8+fPl7e3t+rWratBgwZp586dtj4//fSTdu3apS+//FI1a9ZUmTJlNH78eHl7e2vJkiVyc3OTh4eHHB0d5efnJz8/P7m5ud1W/QMHDlTx4sXVtGnTHF33/YyVKwAAACAbIfWe1uiJsbZ9N3d3SdKuHTu1Y3u8pk2YZDuWnp6hlKtXdeXyZbm5u2vT+o2aNX6i9u7fr+QLF5WWnqarV1N06dJl5c/vfte11Xiyiu3PJ0+eVGJiorp06aJu3brZ2tPS0m66ktSuXTu1bNlSGzZs0ObNm7Vq1SrFxsZq9uzZioiI0LZt23Tx4kUVLlzY7rwrV67o0KFDd1x7bGysPv/8c61du1aurq53PM79hnAFAAAAZMPd3T3LNwNmZGQoMupdtXiuZaZjLq6u+jMhUa91eFlvvNpR0e+9rYIFvbVpy8/q3v8dpaal3nROi8Uiq6x2bampmc9xd/+/gJaRkSHp+hv5goOD7frdeEYsO66urmrWrJmaNWumoUOHqmvXrho2bJgiIiKUkZGhokWLau3atZnO8/b2vum42Rk/frxGjx6tH374QVWqVLn1CQ8QwhUAAACQQ5WqVtbvBw5m+0r2ndvjlZ6WptjhQ5Uv3/UncZYs/9auj5OTk9LT0zOd+1jhwjp2/IRt/8Dvh3X5ypWb1uPr66vixYvr999/V8eOHXN6OXYqVKigZcuWSZKqV6+uY8eOydHRUYGBgVn2d3Z2zvI6sjJu3DiNGjVK3333nWrWrHlXdd6PCFcAAABADvV79229HtZRRYsXV8s2zytfvnzau3u39u3Zq3feH6SAoEClpaXpo9nz1LJ5U236ZatmLfjUbozAkv66eOmSfly/UVUqVpC7m5vc3d3U8Ok6mj53voJrVFdGRoYGjYy5rdesR0dHq0+fPvL09FSLFi2UkpKirVu36uzZs4qMjMzU//Tp03rxxRfVuXNnValSRQUKFNDWrVsVGxur1q1bS5KaNm2qkJAQtWnTRmPHjlXZsmX1119/acWKFWrTpo1q1qypwMBAHT58WPHx8SpRooQKFCiQ5csxYmNjNWTIEH322WcKDAzUsWPHJP3fizUeBoQrAAAA5ImC4QEq7BGY12XckQZNGmve4oWaHDte/5oyTU5Ojnq8TBm99GonSVLFKpU19IORGj9lqt4fPUb1agdr5OCB6vxWP9sYIU/VVPfXOqnjG710+sxZvf92fw19J1Kxw4eoW98Baty6vYr6+WriqOH6deeuW9bUtWtXubu7a9y4cXr33XeVP39+Va5cWf369cuyv4eHh4KDgzVp0iQdOnRIqamp8vf3V7du3TRo0CBJ129RXLFihQYPHqzOnTvr5MmT8vPzU/369eXr6yvp+nNbX331lRo1aqRz585p3rx5ioiIyDTf9OnTde3aNbVv396ufdiwYYqOjr71D/0BQLgCAAAAsjBxxrSbHm/QpLEaNGmc7fGub/bQ+10j7No6vdjObn9abIymxcbYtRXz89P/LF5o13bywG7bnwNL+uva8cQs53zllVf0yiuv3LTuG1xcXBQTE6OYmJib9itQoICmTJmiKVOmZHncxcVFS5YsueV8R44cua26HmS8ih0AAAAADCBcAQAAAIABhCsAAAAAMIBwBQAAAAAGEK4AAAAAwADCFQAAAAAYQLgCAAAAAAMIVwAAAABgAOEKAAAAAAwgXAEAAACAAY55XQAAAAAeTSt2j75nc4UHz8zxOZE939KSzxdnal//6xYFlip11zUtWPSFBgwZrpMHdt/1WHfqxIkTGjJkiFauXKnjx4+rYMGCqlq1qqKjoxUSEnJbY0RHR2vZsmWKj4+/ab/du3dr6NCh2rZtm/744w9NmjRJ/fr1u/uLuI8QrgAAAIBsNGzaWOM/mmLXVtjHJ4+qyV5qaqqcnJxyfF67du2Umpqq+fPnq1SpUjp+/LjWrFmjM2fOGK/x8uXLKlWqlF588UX179/f+Pj3A24LBAAAALLh7OyiIr6+dpuDg4MkafXK7/RsgyYq41tCdavW1KQx45SWlmY7d9a0GarWoKm8A59QqWq11Pu9Qbp46ZIkad1/Nqtr3wE6n5wsZ19/Ofv6a8S4idfn9PXX8hWr7Op4rExFLVj0hSTpSEKinH399eXyb9WwYUO5urrq008/lSTNmzdP5cuXl6urq8qVK6fp06dne23nzp3Txo0bNXbsWDVq1EgBAQGqVauWoqKi1LJlS1u/8+fPq3v37ipSpIg8PT3VuHFj7dixQ5IUFxen4cOHa8eOHbJYLLJYLIqLi8tyvqeeekrjxo3TSy+9JBcXl5z8a3hgsHIFAAAA5NC6NT+q3xs9FT1mtGrVqa0/Dh9RVN8BkqT+A9+RJFnyWTTpgxEK8C+hIwmJ6j1wsKJGfKCpY0cr5KkamjAyWsNjJ+i3TWslSR758+eohsEjYzRh8mTNmzdPLi4umjVrloYNG6Zp06apWrVq2r59u7p166b8+fPrtddey3S+h4eHPDw8tGzZMtWuXTvLwGO1WtWyZUsVKlRIK1askJeXlz7++GM1adJE+/fvV1hYmH777TetWrVKP/zwgyTJy8srR9fxMGHlCgAAAMjGmu++V7niAbatx2udJUlTx09Sz3599OIrLykgMFD1GzXUgMEDtTBuvu3crr16qOHTdRQUUFKN6tVV9Htva8k3/5YkOTs7y8uzgCwWi/yKFJFfkSI5Dle9u3dR27ZtFRQUpGLFimnkyJGaMGGCra1t27bq37+/Pv744yzPd3R0VFxcnObPny9vb2/VrVtXgwYN0s6dO219fvrpJ+3atUtffvmlatasqTJlymj8+PHy9vbWkiVL5ObmJg8PDzk6OsrPz09+fn5yc3PL4U/54cHKFQAAAJCNkHpPa/TEWNu+m7u7JGnXjp3asT1e0yZMsh1LT89QytWrunL5stzc3bVp/UbNGj9Re/fvV/KFi0pLT9PVqym6dOmy8ud3v+vaajxZxfbnkydPKjExUV26dFG3bt1s7WlpaTddSWrXrp1atmypDRs2aPPmzVq1apViY2M1e/ZsRUREaNu2bbp48aIKFy5sd96VK1d06NChu76Ghw3hCgAAAMiGu7t7lm8GzMjIUGTUu2rxXMtMx1xcXfVnQqJe6/Cy3ni1o6Lfe1sFC3pr05af1b3/O0pNS73pnBaLRVZZ7dpSUzOf4+7+fwEtIyNDkjRr1iwFBwfb9bvxjFh2XF1d1axZMzVr1kxDhw5V165dNWzYMEVERCgjI0NFixbV2rVrM53n7e1903EfRYQrAAAAIIcqVa2s3w8czPaV7Du3xys9LU2xw4cqX77rT+IsWf6tXR8nJyelp6dnOvexwoV17PgJ2/6B3w/r8pUrN63H19dXxYsX1++//66OHTvm9HLsVKhQQcuWLZMkVa9eXceOHZOjo6MCAwOz7O/s7JzldTyKCFcAAABADvV79229HtZRRYsXV8s2zytfvnzau3u39u3Zq3feH6SAoEClpaXpo9nz1LJ5U236ZatmLfjUbozAkv66eOmSfly/UVUqVpC7m5vc3d3U8Ok6mj53voJrVFdGRoYGjYy5rdesR0dHq0+fPvL09FSLFi2UkpKirVu36uzZs4qMjMzU//Tp03rxxRfVuXNnValSRQUKFNDWrVsVGxur1q1bS5KaNm2qkJAQtWnTRmPHjlXZsmX1119/acWKFWrTpo1q1qypwMBAHT58WPHx8SpRooQKFCiQ5csxrl27pj179tj+fPToUcXHx8vDw0OlS5e+k38N9x3CFQAAAPLEsxUHqbBHYF6XcUcaNGmseYsXanLseP1ryjQ5OTnq8TJl9NKrnSRJFatU1tAPRmr8lKl6f/QY1asdrJGDB6rzW/1sY4Q8VVPdX+ukjm/00ukzZ/X+2/019J1IxQ4fom59B6hx6/Yq6ueriaOG69edu25ZU9euXeXu7q5x48bp3XffVf78+VW5cuVsv6jXw8NDwcHBmjRpkg4dOqTU1FT5+/urW7duGjRokKTrtyiuWLFCgwcPVufOnXXy5En5+fmpfv368vX1lXT9ua2vvvpKjRo10rlz5zRv3jxFRERkmu+vv/5StWrVbPvjx4/X+PHj1aBBgyxvO3wQEa4AAACALEycMe2mxxs0aawGTRpne7zrmz30ftcIu7ZOL7az258WG6NpsTF2bcX8/PQ/ixfatZ08sNv258CS/rp2PDHLOV955RW98sorN637BhcXF8XExCgmJuam/QoUKKApU6ZoypQpWR53cXHRkiVLbjlfYGCgrFbrLfs9yHgVOwAAAAAYQLgCAAAAAAMIVwAAAABgAOEKAAAAAAwgXAEAACAXWf/xT+D+Y+pFG4QrAAAA5Jo0XVaGNU3XrvIls7h/Xbt2TZLk4OBwV+PwKnYAAADkmgyl6kzq/8rxlIukQnJ2dZBksR2/6ng1z2pLu5aa63NcTU3L1fHTr+bdz+9hkZGRoZMnT8rd3V2OjncXjwhXAAAAyFWnrL9KKVLaiXLKZ7H/6+c5l2t5VJV09srFXJ/jUlruBjiH5Cu5Ov6jIl++fCpZsqQsFsutO98E4QoAAAC57pT1V525tkuOctffV65alxuRZzV9sX5Zrs/R9eiBXB2/8Mvv5Or4jwpnZ2fly3f3T0wRrgAAAHBPZChV13Ters3V1TWPqpGS03N/1czp6oVcHT8vf37ILM9faDF9+nQFBQXJ1dVVNWrU0IYNG7LtGxERIYvFkmmrWLGiXb+lS5eqQoUKcnFxUYUKFfT111/n9mUAAAAAeMTlabhavHix+vXrp8GDB2v79u2qV6+eWrRooYSEhCz7f/jhh0pKSrJtiYmJKlSokF588UVbn82bNyssLEzh4eHasWOHwsPD1aFDB23ZsuVeXRYAAACAR1CehquJEyeqS5cu6tq1q8qXL6/JkyfL399fM2bMyLK/l5eX/Pz8bNvWrVt19uxZvf7667Y+kydPVrNmzRQVFaVy5copKipKTZo00eTJk+/RVQEAAAB4FOXZM1fXrl3Ttm3bNHDgQLv25s2ba9OmTbc1xpw5c9S0aVMFBATY2jZv3qz+/fvb9QsNDb1puEpJSVFKSopt//z56/cCJycn31YdWY55Offf3HLhSsqtO92FK46XcnV8SbpwJfe/8+LKpdy/n/puPit3i8/a7eGzdvf4rN0ePmt3j8/a7eGzdvcehs+aax7+/B4VNz6jt/VFw9Y8cvToUask63/+8x+79g8++MD6xBNP3PL8v/76y+rg4GBdvHixXbuTk5N14cKFdm0LFy60Ojs7ZzvWsGHDrLr+teFsbGxsbGxsbGxsbGyZtsTExFtmlDx/W+A/3yVvtVpv6/3ycXFx8vb2Vps2be56zKioKEVGRtr2MzIydObMGRUuXPiu33X/KElOTpa/v78SExPl6emZ1+XgIcZnDfcKnzXcK3zWcK/wWcs5q9WqCxcuqFixYrfsm2fhysfHRw4ODjp27Jhd+4kTJ+Tr63vTc61Wq+bOnavw8HA5OzvbHfPz88vxmC4uLnJxcbFr8/b2vo2rQFY8PT35HyvuCT5ruFf4rOFe4bOGe4XPWs54eXndVr88e6GFs7OzatSoodWrV9u1r169WnXq1LnpuevWrdPBgwfVpUuXTMdCQkIyjfn999/fckwAAAAAuBt5eltgZGSkwsPDVbNmTYWEhGjmzJlKSEhQjx49JF2/Xe/o0aNasGCB3Xlz5sxRcHCwKlWqlGnMvn37qn79+ho7dqxat26t5cuX64cfftDGjRvvyTUBAAAAeDTlabgKCwvT6dOnNWLECCUlJalSpUpasWKF7e1/SUlJmb7z6vz581q6dKk+/PDDLMesU6eOFi1apPfff19DhgzR448/rsWLFys4ODjXr+dR5+LiomHDhmW6xRIwjc8a7hU+a7hX+KzhXuGzlrssVuvtvFMQAAAAAHAzefolwgAAAADwsCBcAQAAAIABhCsAAAAAMIBwBQAAAAAGEK6QpYiICLVp08aubcmSJXJ1dVVsbKyio6NlsVhsr82/IT4+XhaLRUeOHJEkHTlyRBaLRUWKFNGFCxfs+j755JOKjo7OxavAgyoiIkIWi0Vjxoyxa1+2bJksFoskae3atbJYLKpUqZLS09Pt+nl7eysuLu5elYsH3I3Pm8VikaOjo0qWLKmePXvq7Nmztj6BgYG2Pje2EiVK5GHVeND8/XPm5OQkX19fNWvWTHPnzlVGRobtv2k32/jvGm5HTn6H3tjc3NxUsWJFzZw5My9KfqgQrnBbZs+erY4dO2ratGl69913JUmurq6aM2eO9u/ff8vzL1y4oPHjx+d2mXiIuLq6auzYsXZ/wc3KoUOHMn0XHpBTzzzzjJKSknTkyBHNnj1b3377rXr16mXX58bXhtzYtm/fnkfV4kH198/ZypUr1ahRI/Xt21etWrVSnTp17D5fHTp0sPW/sYWFheX1JeABcbu/Q/ft26ekpCTt2bNHb7zxhnr27Kk1a9bcoyofToQr3FJsbKzeeustffbZZ+ratautvWzZsmrUqJHef//9W47Ru3dvTZw4USdOnMjNUvEQadq0qfz8/BQTE3PTfr1799awYcN09erVe1QZHkYuLi7y8/NTiRIl1Lx5c4WFhen777+361OgQAH5+fnZtsceeyyPqsWD6sbnrHjx4qpevboGDRqk5cuXa+XKlVqwYIHd58vNzc3W/+9twO243d+hRYoUkZ+fn4KCgtSnTx8FBgbq119/vUdVPpwIV7ipgQMHauTIkfr3v/+tdu3aZTo+ZswYLV26VL/88stNx3n55ZdVunRpjRgxIrdKxUPGwcFBo0eP1tSpU/Xnn39m269fv35KS0vTtGnT7mF1eJj9/vvvWrVqlZycnPK6FDwCGjdurKpVq+qrr77K61LwELnd36E3WK1WrVq1SomJiQoODr4HFT68CFfI1sqVKzV27FgtX75cTZs2zbJP9erV1aFDBw0cOPCmY92493fmzJk6dOhQbpSLh9ALL7ygJ598UsOGDcu2j7u7u4YNG6aYmBidP3/+HlaHh8m///1veXh4yM3NTY8//rj27Nmj9957z67Pe++9Jw8PD9s2ZcqUPKoWD5ty5crZnlUGTLmd36ElSpSQh4eHnJ2d1bJlSw0bNkz169e/h1U+fAhXyFaVKlUUGBiooUOHZnoZxd+NGjVKGzZsyHQLzT+Fhobq6aef1pAhQ0yXiofY2LFjNX/+fO3ZsyfbPl26dJGPj4/Gjh17DyvDw6RRo0aKj4/Xli1b1Lt3b4WGhqp37952fd555x3Fx8fbtldffTWPqsXDxmq12l40AJh0q9+hGzZssP03bfbs2Ro9erRmzJhxj6t8uBCukK3ixYtr3bp1SkpK0jPPPJNtwHr88cfVrVs3DRw4UFar9aZjjhkzRosXL+ZBcNy2+vXrKzQ0VIMGDcq2j6Ojo0aNGqUPP/xQf/311z2sDg+L/Pnzq3Tp0qpSpYqmTJmilJQUDR8+3K6Pj4+PSpcubdu8vb3zplg8dPbu3augoKC8LgMPoVv9Dg0KClLp0qVVsWJFvf766woPD9cHH3xwj6t8uBCucFMlS5bUunXrdOLECTVv3lzJyclZ9hs6dKj279+vRYsW3XS8WrVqqW3btre8jRD4uzFjxujbb7/Vpk2bsu3z4osvqmLFipn+QgzciWHDhmn8+PGEdeS6H3/8Ubt27cryuWbAhNv5HXqDg4ODrly5cg+qeng55nUBuP+VKFFCa9euVaNGjdS8eXN99913mfr4+voqMjJS48aNu+V4H3zwgSpWrChHRz5+uD2VK1dWx44dNXXq1Jv2GzNmjEJDQ+9RVXiYNWzYUBUrVtTo0aN5WQqMSUlJ0bFjx5Senq7jx49r1apViomJUatWrbjNFLnmZr9DT5w4oatXryolJUU///yzPvnkE7Vv3z4Pqnx4sHKF23LjFsFz586pWbNmOnfuXKY+77zzjjw8PG451hNPPKHOnTvz6mzkyMiRI29522njxo3VuHFjpaWl3aOq8DCLjIzUrFmzlJiYmNel4CGxatUqFS1aVIGBgXrmmWf0008/acqUKVq+fLkcHBzyujw8xLL7HVq2bFkVLVpUpUuX1nvvvac33njjlv9HJm7OYr3V31YAAAAAALfEyhUAAAAAGEC4AgAAAAADCFcAAAAAYADhCgAAAAAMIFwBAAAAgAGEKwAAAAAwgHAFAAAAAAYQrgAAAADAAMIVAAA5sHbtWlksFp07d+62zwkMDNTkyZNzrSYAwP2BcAUAeKhERETIYrGoR48emY716tVLFotFERER974wAMBDj3AFAHjo+Pv7a9GiRbpy5Yqt7erVq/r8889VsmTJPKwMAPAwI1wBAB461atXV8mSJfXVV1/Z2r766iv5+/urWrVqtraUlBT16dNHRYoUkaurq55++mn98ssvdmOtWLFCTzzxhNzc3NSoUSMdOXIk03ybNm1S/fr15ebmJn9/f/Xp00eXLl3KtesDANyfCFcAgIfS66+/rnnz5tn2586dq86dO9v1effdd7V06VLNnz9fv/76q0qXLq3Q0FCdOXNGkpSYmKi2bdvq2WefVXx8vLp27aqBAwfajbFr1y6Fhoaqbdu22rlzpxYvXqyNGzfqrbfeyv2LBADcVwhXAICHUnh4uDZu3KgjR47ojz/+0H/+8x916tTJdvzSpUuaMWOGxo0bpxYtWqhChQqaNWuW3NzcNGfOHEnSjBkzVKpUKU2aNElly5ZVx44dMz2vNW7cOL3yyivq16+fypQpozp16mjKlClasGCBrl69ei8vGQCQxxzzugAAAHKDj4+PWrZsqfnz58tqtaply5by8fGxHT906JBSU1NVt25dW5uTk5Nq1aqlvXv3SpL27t2r2rVry2Kx2PqEhITYzbNt2zYdPHhQCxcutLVZrVZlZGTo8OHDKl++fG5dIgDgPkO4AgA8tDp37my7Pe+jjz6yO2a1WiXJLjjdaL/RdqPPzWRkZOiNN95Qnz59Mh3j5RkA8GjhtkAAwEPrmWee0bVr13Tt2jWFhobaHStdurScnZ21ceNGW1tqaqq2bt1qW22qUKGC/vvf/9qd98/96tWra/fu3SpdunSmzdnZOZeuDABwPyJcAQAeWg4ODtq7d6/27t0rBwcHu2P58+dXz5499c4772jVqlXas2ePunXrpsuXL6tLly6SpB49eujQoUOKjIzUvn379NlnnykuLs5unPfee0+bN2/Wm2++qfj4eB04cEDffPONevfufa8uEwBwnyBcAQAeap6envL09Mzy2JgxY9SuXTuFh4erevXqOnjwoL777jsVLFhQ0vXb+pYuXapvv/1WVatW1b/+9S+NHj3abowqVapo3bp1OnDggOrVq6dq1appyJAhKlq0aK5fGwDg/mKx3s4N5QAAAACAm2LlCgAAAAAMIFwBAAAAgAGEKwAAAAAwgHAFAAAAAAYQrgAAAADAAMIVAAAAABhAuAIAAAAAAwhXAAAAAGAA4QoAAAAADCBcAQAAAIABhCsAAAAAMOD/ART4NE3QjfWRAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score_df = score_df.sort_values(by=\"accuracy\", ascending=False)  # Ensure sorting is applied\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.barplot(x=\"model\", y=\"accuracy\", hue=\"feature_set\", data=score_df, palette=\"Set2\")  # Fixed typo\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0.7, 1)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_set_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
