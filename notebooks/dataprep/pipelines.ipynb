{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../../data/raw/df_resample_100ms.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>label</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>trial</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:38:38.700</th>\n",
       "      <td>0.948777</td>\n",
       "      <td>-9.636166</td>\n",
       "      <td>0.002699</td>\n",
       "      <td>0.003818</td>\n",
       "      <td>0.016875</td>\n",
       "      <td>0.006643</td>\n",
       "      <td>BSC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:38:38.800</th>\n",
       "      <td>0.948993</td>\n",
       "      <td>-9.759188</td>\n",
       "      <td>0.087482</td>\n",
       "      <td>0.020693</td>\n",
       "      <td>0.027565</td>\n",
       "      <td>0.015669</td>\n",
       "      <td>BSC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:38:38.900</th>\n",
       "      <td>1.071514</td>\n",
       "      <td>-9.787465</td>\n",
       "      <td>-0.093610</td>\n",
       "      <td>0.168721</td>\n",
       "      <td>0.075747</td>\n",
       "      <td>0.037797</td>\n",
       "      <td>BSC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:38:39.000</th>\n",
       "      <td>1.135679</td>\n",
       "      <td>-9.754036</td>\n",
       "      <td>0.065878</td>\n",
       "      <td>0.339488</td>\n",
       "      <td>0.078970</td>\n",
       "      <td>0.040134</td>\n",
       "      <td>BSC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:38:39.100</th>\n",
       "      <td>1.126174</td>\n",
       "      <td>-9.443248</td>\n",
       "      <td>0.075006</td>\n",
       "      <td>0.594494</td>\n",
       "      <td>-0.012065</td>\n",
       "      <td>0.103557</td>\n",
       "      <td>BSC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 04:49:55.200</th>\n",
       "      <td>2.128992</td>\n",
       "      <td>14.084110</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>-1.022787</td>\n",
       "      <td>0.162796</td>\n",
       "      <td>0.609964</td>\n",
       "      <td>WAL</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 04:49:55.300</th>\n",
       "      <td>-1.563028</td>\n",
       "      <td>11.139874</td>\n",
       "      <td>1.061856</td>\n",
       "      <td>-2.417346</td>\n",
       "      <td>-0.699792</td>\n",
       "      <td>1.861551</td>\n",
       "      <td>WAL</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 04:49:55.400</th>\n",
       "      <td>2.767679</td>\n",
       "      <td>8.869539</td>\n",
       "      <td>0.154884</td>\n",
       "      <td>-0.998184</td>\n",
       "      <td>0.612194</td>\n",
       "      <td>1.557859</td>\n",
       "      <td>WAL</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 04:49:55.500</th>\n",
       "      <td>0.149554</td>\n",
       "      <td>5.565219</td>\n",
       "      <td>2.023148</td>\n",
       "      <td>0.629237</td>\n",
       "      <td>0.462074</td>\n",
       "      <td>-0.136162</td>\n",
       "      <td>WAL</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 04:49:55.600</th>\n",
       "      <td>5.108846</td>\n",
       "      <td>9.221981</td>\n",
       "      <td>4.497037</td>\n",
       "      <td>0.958338</td>\n",
       "      <td>-0.160963</td>\n",
       "      <td>-0.892430</td>\n",
       "      <td>WAL</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>846950 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            acc_x      acc_y     acc_z    gyro_x    gyro_y  \\\n",
       "timestamp                                                                    \n",
       "1970-01-01 00:38:38.700  0.948777  -9.636166  0.002699  0.003818  0.016875   \n",
       "1970-01-01 00:38:38.800  0.948993  -9.759188  0.087482  0.020693  0.027565   \n",
       "1970-01-01 00:38:38.900  1.071514  -9.787465 -0.093610  0.168721  0.075747   \n",
       "1970-01-01 00:38:39.000  1.135679  -9.754036  0.065878  0.339488  0.078970   \n",
       "1970-01-01 00:38:39.100  1.126174  -9.443248  0.075006  0.594494 -0.012065   \n",
       "...                           ...        ...       ...       ...       ...   \n",
       "1970-01-01 04:49:55.200  2.128992  14.084110  0.907692 -1.022787  0.162796   \n",
       "1970-01-01 04:49:55.300 -1.563028  11.139874  1.061856 -2.417346 -0.699792   \n",
       "1970-01-01 04:49:55.400  2.767679   8.869539  0.154884 -0.998184  0.612194   \n",
       "1970-01-01 04:49:55.500  0.149554   5.565219  2.023148  0.629237  0.462074   \n",
       "1970-01-01 04:49:55.600  5.108846   9.221981  4.497037  0.958338 -0.160963   \n",
       "\n",
       "                           gyro_z label  subject_id  trial   age  height  \\\n",
       "timestamp                                                                  \n",
       "1970-01-01 00:38:38.700  0.006643   BSC         1.0    1.0  32.0   180.0   \n",
       "1970-01-01 00:38:38.800  0.015669   BSC         1.0    1.0  32.0   180.0   \n",
       "1970-01-01 00:38:38.900  0.037797   BSC         1.0    1.0  32.0   180.0   \n",
       "1970-01-01 00:38:39.000  0.040134   BSC         1.0    1.0  32.0   180.0   \n",
       "1970-01-01 00:38:39.100  0.103557   BSC         1.0    1.0  32.0   180.0   \n",
       "...                           ...   ...         ...    ...   ...     ...   \n",
       "1970-01-01 04:49:55.200  0.609964   WAL        67.0    1.0  23.0   180.0   \n",
       "1970-01-01 04:49:55.300  1.861551   WAL        67.0    1.0  23.0   180.0   \n",
       "1970-01-01 04:49:55.400  1.557859   WAL        67.0    1.0  23.0   180.0   \n",
       "1970-01-01 04:49:55.500 -0.136162   WAL        67.0    1.0  23.0   180.0   \n",
       "1970-01-01 04:49:55.600 -0.892430   WAL        67.0    1.0  23.0   180.0   \n",
       "\n",
       "                         weight gender  \n",
       "timestamp                               \n",
       "1970-01-01 00:38:38.700    85.0      M  \n",
       "1970-01-01 00:38:38.800    85.0      M  \n",
       "1970-01-01 00:38:38.900    85.0      M  \n",
       "1970-01-01 00:38:39.000    85.0      M  \n",
       "1970-01-01 00:38:39.100    85.0      M  \n",
       "...                         ...    ...  \n",
       "1970-01-01 04:49:55.200    67.0      M  \n",
       "1970-01-01 04:49:55.300    67.0      M  \n",
       "1970-01-01 04:49:55.400    67.0      M  \n",
       "1970-01-01 04:49:55.500    67.0      M  \n",
       "1970-01-01 04:49:55.600    67.0      M  \n",
       "\n",
       "[846950 rows x 13 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew, kurtosis, entropy\n",
    "from scipy.signal import welch\n",
    "import numpy as np\n",
    "from scipy.fft import rfft, rfftfreq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_entropy(signal, num_blocks=10):\n",
    "    \"\"\"\n",
    "    Example placeholder function for energy entropy.\n",
    "    Adjust or replace as needed.\n",
    "    \"\"\"\n",
    "    # compute energy in each block, then compute Shannon entropy\n",
    "    block_size = len(signal) // num_blocks\n",
    "    energies = []\n",
    "    for i in range(num_blocks):\n",
    "        start = i * block_size\n",
    "        end = start + block_size\n",
    "        block = signal[start:end]\n",
    "        energies.append(np.sum(block**2))\n",
    "\n",
    "    energies = np.array(energies)\n",
    "    energies_norm = energies / (np.sum(energies) + 1e-10)\n",
    "    entropy_val = -np.sum(energies_norm * np.log2(energies_norm + 1e-10))\n",
    "    return entropy_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features that will be generated by the function defined below are:\n",
    "1. Stat features of both sensors data: mean, std, min, max, skew, kurtosis, min-max diff for each axis\n",
    "2. The magnitude of each axis from both sensors\n",
    "3. Statistical features for those magnitude computed\n",
    "4. Incorporate 10 block entropy of energy for accelerometer magnitude (strongest feature in MobiFall paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def extract_features_from_windows(df, \n",
    "                                  window_duration_s=2.5, \n",
    "                                  overlap=0.5, \n",
    "                                  sampling_rate_ms=100):\n",
    "    \"\"\"\n",
    "    Slide window through each trial of each subject.\n",
    "    Extract statistical features per window: mean, std, min, max, skew, kurtosis,\n",
    "    slope (SL), and tilt angle (T_Ai) stats.\n",
    "    \"\"\"\n",
    "    window_size = int(window_duration_s * 1000 / sampling_rate_ms)\n",
    "    step_size   = int(window_size * (1 - overlap))\n",
    "    \n",
    "    features = []\n",
    "    labels   = []\n",
    "    \n",
    "    for subject in df['subject_id'].unique():\n",
    "        subject_data = df[df['subject_id'] == subject]\n",
    "        \n",
    "        for trial in subject_data['trial'].unique():\n",
    "            trial_data = subject_data[subject_data['trial'] == trial]\n",
    "            trial_data = trial_data.sort_index()  # sort by timestamp\n",
    "\n",
    "            # 6D signals: [acc_x, acc_y, acc_z, gyro_x, gyro_y, gyro_z]\n",
    "            signal_data = trial_data[['acc_x', 'acc_y', 'acc_z', \n",
    "                                      'gyro_x', 'gyro_y', 'gyro_z']].values\n",
    "            class_labels = trial_data['label'].values\n",
    "\n",
    "            for start in range(0, len(signal_data) - window_size + 1, step_size):\n",
    "                window = signal_data[start:start + window_size]\n",
    "                window_labels = class_labels[start:start + window_size]\n",
    "                label = window_labels[-1]  # Take the last label in the window\n",
    "\n",
    "                # ---------------------------------------------------------\n",
    "                # Basic stats\n",
    "                # ---------------------------------------------------------\n",
    "                mean_feat = window.mean(axis=0)\n",
    "                std_feat  = window.std(axis=0)\n",
    "                min_feat  = window.min(axis=0)\n",
    "                max_feat  = window.max(axis=0)\n",
    "                skew_feat = skew(window, axis=0)\n",
    "                kurt_feat = kurtosis(window, axis=0)\n",
    "                minmax_diff = max_feat - min_feat\n",
    "\n",
    "                # ---------------------------------------------------------\n",
    "                # NEW: Slope (SL) of the three accelerometer axes\n",
    "                # ---------------------------------------------------------\n",
    "                # window[:, 0:3] -> acc_x, acc_y, acc_z in the window\n",
    "                acc_x = window[:, 0]\n",
    "                acc_y = window[:, 1]\n",
    "                acc_z = window[:, 2]\n",
    "\n",
    "                # Slope = sqrt( (max_x - min_x)^2 + (max_y - min_y)^2 + (max_z - min_z)^2 )\n",
    "                acc_slope = np.sqrt(\n",
    "                    (acc_x.max() - acc_x.min())**2 +\n",
    "                    (acc_y.max() - acc_y.min())**2 +\n",
    "                    (acc_z.max() - acc_z.min())**2\n",
    "                )\n",
    "\n",
    "                # ---------------------------------------------------------\n",
    "                # NEW: Tilt angle (T_Ai) between gravitational vector and y-axis\n",
    "                # ---------------------------------------------------------\n",
    "                # T_Ai = arcsin( y / sqrt(x^2 + y^2 + z^2) ) for each sample\n",
    "                # We'll compute stats of this tilt angle across the window.\n",
    "                \n",
    "                magnitude = np.sqrt(acc_x**2 + acc_y**2 + acc_z**2)\n",
    "                tilt_angles = np.arcsin(acc_y / magnitude)\n",
    "\n",
    "                tilt_mean = np.mean(tilt_angles)\n",
    "                tilt_std  = np.std(tilt_angles)\n",
    "                tilt_skew = skew(tilt_angles)\n",
    "                tilt_kurt = kurtosis(tilt_angles)\n",
    "\n",
    "                # ---------------------------------------------------------\n",
    "                # Magnitude-based features for ACC and GYRO\n",
    "                # ---------------------------------------------------------\n",
    "                # Accelerometer magnitude\n",
    "                acc_mag = np.sqrt(np.sum(window[:, :3] ** 2, axis=1))\n",
    "                acc_mag_mean = np.mean(acc_mag)\n",
    "                acc_mag_std  = np.std(acc_mag)\n",
    "                acc_mag_min  = np.min(acc_mag)\n",
    "                acc_mag_max  = np.max(acc_mag)\n",
    "                acc_mag_diff = acc_mag_max - acc_mag_min\n",
    "                acc_mag_energy_entropy = energy_entropy(acc_mag, num_blocks=10)\n",
    "\n",
    "                # Gyroscope magnitude\n",
    "                gyro_mag = np.sqrt(np.sum(window[:, 3:] ** 2, axis=1))\n",
    "                gyro_mag_mean = np.mean(gyro_mag)\n",
    "                gyro_mag_std  = np.std(gyro_mag)\n",
    "                gyro_mag_min  = np.min(gyro_mag)\n",
    "                gyro_mag_max  = np.max(gyro_mag)\n",
    "                gyro_mag_diff = gyro_mag_max - gyro_mag_min\n",
    "\n",
    "                # ---------------------------------------------------------\n",
    "                # Concatenate all features\n",
    "                # ---------------------------------------------------------\n",
    "                feat = np.concatenate([\n",
    "                    mean_feat,\n",
    "                    std_feat,\n",
    "                    min_feat,\n",
    "                    max_feat,\n",
    "                    skew_feat,\n",
    "                    kurt_feat,\n",
    "                    minmax_diff,\n",
    "                    # slope\n",
    "                    [acc_slope],\n",
    "                    # tilt stats\n",
    "                    [tilt_mean, tilt_std, tilt_skew, tilt_kurt],\n",
    "                    # Raw magnitudes\n",
    "                    acc_mag,\n",
    "                    gyro_mag,\n",
    "                    # Summary magnitude features\n",
    "                    [acc_mag_mean, acc_mag_std, acc_mag_min, acc_mag_max, acc_mag_diff, acc_mag_energy_entropy],\n",
    "                    [gyro_mag_mean, gyro_mag_std, gyro_mag_min, gyro_mag_max, gyro_mag_diff]\n",
    "                ])\n",
    "\n",
    "                features.append(feat)\n",
    "                labels.append(label)\n",
    "                \n",
    "    return features, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nfeatures, labels = extract_features_from_windows(df)\\n\\n# Base sensor names\\nsensors = [\\'acc_x\\', \\'acc_y\\', \\'acc_z\\', \\'gyro_x\\', \\'gyro_y\\', \\'gyro_z\\']\\n\\n# Feature types per sensor\\nstats = [\\'mean\\', \\'std\\', \\'min\\', \\'max\\', \\'skew\\', \\'kurt\\', \\'minmax_diff\\']\\nstat_columns = [f\"{stat}_{sensor}\" for stat in stats for sensor in sensors]\\n\\n# Magnitude column sizes\\nwindow_duration_s = 2.5\\nsampling_rate_ms = 100\\nwindow_size = int(window_duration_s * 1000 / sampling_rate_ms)\\n\\nacc_mag_cols = [f\\'acc_mag_t{i}\\' for i in range(window_size)]\\ngyro_mag_cols = [f\\'gyro_mag_t{i}\\' for i in range(window_size)]\\n\\n# Magnitude stats\\nacc_mag_stats = [\\'acc_mag_mean\\', \\'acc_mag_std\\', \\'acc_mag_min\\', \\'acc_mag_max\\', \\'acc_mag_diff\\', \\'acc_mag_energy_entropy\\']\\ngyro_mag_stats = [\\'gyro_mag_mean\\', \\'gyro_mag_std\\', \\'gyro_mag_min\\', \\'gyro_mag_max\\', \\'gyro_mag_diff\\']\\n\\n# Combine all column names\\ncolumn_names = stat_columns + acc_mag_cols + gyro_mag_cols + acc_mag_stats + gyro_mag_stats\\n\\n# Create the DataFrame\\nfeatures_df = pd.DataFrame(features, columns=column_names)\\nfeatures_df[\\'label\\'] = labels\\n\\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "\n",
    "features, labels = extract_features_from_windows(df)\n",
    "\n",
    "# Base sensor names\n",
    "sensors = ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z']\n",
    "\n",
    "# Feature types per sensor\n",
    "stats = ['mean', 'std', 'min', 'max', 'skew', 'kurt', 'minmax_diff']\n",
    "stat_columns = [f\"{stat}_{sensor}\" for stat in stats for sensor in sensors]\n",
    "\n",
    "# Magnitude column sizes\n",
    "window_duration_s = 2.5\n",
    "sampling_rate_ms = 100\n",
    "window_size = int(window_duration_s * 1000 / sampling_rate_ms)\n",
    "\n",
    "acc_mag_cols = [f'acc_mag_t{i}' for i in range(window_size)]\n",
    "gyro_mag_cols = [f'gyro_mag_t{i}' for i in range(window_size)]\n",
    "\n",
    "# Magnitude stats\n",
    "acc_mag_stats = ['acc_mag_mean', 'acc_mag_std', 'acc_mag_min', 'acc_mag_max', 'acc_mag_diff', 'acc_mag_energy_entropy']\n",
    "gyro_mag_stats = ['gyro_mag_mean', 'gyro_mag_std', 'gyro_mag_min', 'gyro_mag_max', 'gyro_mag_diff']\n",
    "\n",
    "# Combine all column names\n",
    "column_names = stat_columns + acc_mag_cols + gyro_mag_cols + acc_mag_stats + gyro_mag_stats\n",
    "\n",
    "# Create the DataFrame\n",
    "features_df = pd.DataFrame(features, columns=column_names)\n",
    "features_df['label'] = labels\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_acc_x</th>\n",
       "      <th>mean_acc_y</th>\n",
       "      <th>mean_acc_z</th>\n",
       "      <th>mean_gyro_x</th>\n",
       "      <th>mean_gyro_y</th>\n",
       "      <th>mean_gyro_z</th>\n",
       "      <th>std_acc_x</th>\n",
       "      <th>std_acc_y</th>\n",
       "      <th>std_acc_z</th>\n",
       "      <th>std_gyro_x</th>\n",
       "      <th>...</th>\n",
       "      <th>acc_mag_min</th>\n",
       "      <th>acc_mag_max</th>\n",
       "      <th>acc_mag_diff</th>\n",
       "      <th>acc_mag_energy_entropy</th>\n",
       "      <th>gyro_mag_mean</th>\n",
       "      <th>gyro_mag_std</th>\n",
       "      <th>gyro_mag_min</th>\n",
       "      <th>gyro_mag_max</th>\n",
       "      <th>gyro_mag_diff</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.253800</td>\n",
       "      <td>-9.735710</td>\n",
       "      <td>-0.759319</td>\n",
       "      <td>-0.052844</td>\n",
       "      <td>0.018417</td>\n",
       "      <td>0.029541</td>\n",
       "      <td>0.245499</td>\n",
       "      <td>0.014139</td>\n",
       "      <td>0.217480</td>\n",
       "      <td>0.028723</td>\n",
       "      <td>...</td>\n",
       "      <td>9.735512</td>\n",
       "      <td>9.809990</td>\n",
       "      <td>0.074478</td>\n",
       "      <td>3.293505</td>\n",
       "      <td>0.090548</td>\n",
       "      <td>0.039731</td>\n",
       "      <td>0.028844</td>\n",
       "      <td>0.229268</td>\n",
       "      <td>0.200424</td>\n",
       "      <td>STD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.249150</td>\n",
       "      <td>-9.739145</td>\n",
       "      <td>-0.733451</td>\n",
       "      <td>-0.032854</td>\n",
       "      <td>0.029329</td>\n",
       "      <td>0.011645</td>\n",
       "      <td>0.237170</td>\n",
       "      <td>0.014339</td>\n",
       "      <td>0.232159</td>\n",
       "      <td>0.031158</td>\n",
       "      <td>...</td>\n",
       "      <td>9.738685</td>\n",
       "      <td>9.809990</td>\n",
       "      <td>0.071305</td>\n",
       "      <td>3.292415</td>\n",
       "      <td>0.072513</td>\n",
       "      <td>0.046496</td>\n",
       "      <td>0.019905</td>\n",
       "      <td>0.229268</td>\n",
       "      <td>0.209363</td>\n",
       "      <td>STD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.386838</td>\n",
       "      <td>-9.739573</td>\n",
       "      <td>-0.578832</td>\n",
       "      <td>-0.036421</td>\n",
       "      <td>0.003834</td>\n",
       "      <td>0.016446</td>\n",
       "      <td>0.146762</td>\n",
       "      <td>0.013975</td>\n",
       "      <td>0.088793</td>\n",
       "      <td>0.026637</td>\n",
       "      <td>...</td>\n",
       "      <td>9.730387</td>\n",
       "      <td>9.785563</td>\n",
       "      <td>0.055175</td>\n",
       "      <td>3.292894</td>\n",
       "      <td>0.056273</td>\n",
       "      <td>0.017656</td>\n",
       "      <td>0.019905</td>\n",
       "      <td>0.092863</td>\n",
       "      <td>0.072958</td>\n",
       "      <td>STD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.326125</td>\n",
       "      <td>-9.741381</td>\n",
       "      <td>-0.672142</td>\n",
       "      <td>-0.049490</td>\n",
       "      <td>0.001070</td>\n",
       "      <td>0.023786</td>\n",
       "      <td>0.055841</td>\n",
       "      <td>0.011643</td>\n",
       "      <td>0.079863</td>\n",
       "      <td>0.007339</td>\n",
       "      <td>...</td>\n",
       "      <td>9.730387</td>\n",
       "      <td>9.790438</td>\n",
       "      <td>0.060051</td>\n",
       "      <td>3.293122</td>\n",
       "      <td>0.059128</td>\n",
       "      <td>0.011383</td>\n",
       "      <td>0.044413</td>\n",
       "      <td>0.092863</td>\n",
       "      <td>0.048451</td>\n",
       "      <td>STD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.283808</td>\n",
       "      <td>-9.745207</td>\n",
       "      <td>-0.738642</td>\n",
       "      <td>-0.042550</td>\n",
       "      <td>0.012788</td>\n",
       "      <td>0.018867</td>\n",
       "      <td>0.027931</td>\n",
       "      <td>0.008566</td>\n",
       "      <td>0.040782</td>\n",
       "      <td>0.005152</td>\n",
       "      <td>...</td>\n",
       "      <td>9.762408</td>\n",
       "      <td>9.792928</td>\n",
       "      <td>0.030519</td>\n",
       "      <td>3.292951</td>\n",
       "      <td>0.049011</td>\n",
       "      <td>0.005093</td>\n",
       "      <td>0.039530</td>\n",
       "      <td>0.058386</td>\n",
       "      <td>0.018856</td>\n",
       "      <td>STD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69978</th>\n",
       "      <td>5.822824</td>\n",
       "      <td>-1.556491</td>\n",
       "      <td>7.235764</td>\n",
       "      <td>-0.066575</td>\n",
       "      <td>0.083216</td>\n",
       "      <td>-0.058658</td>\n",
       "      <td>1.872333</td>\n",
       "      <td>0.572352</td>\n",
       "      <td>1.382859</td>\n",
       "      <td>0.357383</td>\n",
       "      <td>...</td>\n",
       "      <td>3.617510</td>\n",
       "      <td>12.013304</td>\n",
       "      <td>8.395794</td>\n",
       "      <td>3.276123</td>\n",
       "      <td>0.490682</td>\n",
       "      <td>0.574643</td>\n",
       "      <td>0.027853</td>\n",
       "      <td>2.293158</td>\n",
       "      <td>2.265304</td>\n",
       "      <td>SIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69979</th>\n",
       "      <td>6.218721</td>\n",
       "      <td>-2.150890</td>\n",
       "      <td>6.742830</td>\n",
       "      <td>0.040020</td>\n",
       "      <td>0.044249</td>\n",
       "      <td>0.119265</td>\n",
       "      <td>1.445265</td>\n",
       "      <td>0.697573</td>\n",
       "      <td>1.440475</td>\n",
       "      <td>0.306958</td>\n",
       "      <td>...</td>\n",
       "      <td>8.646267</td>\n",
       "      <td>10.517353</td>\n",
       "      <td>1.871086</td>\n",
       "      <td>3.295499</td>\n",
       "      <td>0.425943</td>\n",
       "      <td>0.440300</td>\n",
       "      <td>0.027853</td>\n",
       "      <td>1.416272</td>\n",
       "      <td>1.388418</td>\n",
       "      <td>CSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69980</th>\n",
       "      <td>6.294121</td>\n",
       "      <td>-0.479762</td>\n",
       "      <td>5.933423</td>\n",
       "      <td>0.127804</td>\n",
       "      <td>0.004355</td>\n",
       "      <td>-0.142396</td>\n",
       "      <td>1.834981</td>\n",
       "      <td>4.135841</td>\n",
       "      <td>1.116061</td>\n",
       "      <td>0.857453</td>\n",
       "      <td>...</td>\n",
       "      <td>5.389208</td>\n",
       "      <td>12.161697</td>\n",
       "      <td>6.772488</td>\n",
       "      <td>3.251270</td>\n",
       "      <td>1.127563</td>\n",
       "      <td>0.727587</td>\n",
       "      <td>0.040854</td>\n",
       "      <td>2.398200</td>\n",
       "      <td>2.357346</td>\n",
       "      <td>CSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69981</th>\n",
       "      <td>4.271851</td>\n",
       "      <td>5.092304</td>\n",
       "      <td>3.382345</td>\n",
       "      <td>0.320573</td>\n",
       "      <td>-0.384789</td>\n",
       "      <td>-0.601700</td>\n",
       "      <td>2.281468</td>\n",
       "      <td>5.606993</td>\n",
       "      <td>3.181307</td>\n",
       "      <td>1.035809</td>\n",
       "      <td>...</td>\n",
       "      <td>5.289488</td>\n",
       "      <td>13.113264</td>\n",
       "      <td>7.823775</td>\n",
       "      <td>3.253118</td>\n",
       "      <td>1.482418</td>\n",
       "      <td>1.146300</td>\n",
       "      <td>0.133865</td>\n",
       "      <td>4.501683</td>\n",
       "      <td>4.367818</td>\n",
       "      <td>STD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69982</th>\n",
       "      <td>2.575851</td>\n",
       "      <td>8.923356</td>\n",
       "      <td>0.138188</td>\n",
       "      <td>0.196273</td>\n",
       "      <td>-0.318099</td>\n",
       "      <td>-0.303589</td>\n",
       "      <td>1.281563</td>\n",
       "      <td>2.904465</td>\n",
       "      <td>1.742787</td>\n",
       "      <td>0.719484</td>\n",
       "      <td>...</td>\n",
       "      <td>5.289488</td>\n",
       "      <td>13.113264</td>\n",
       "      <td>7.823775</td>\n",
       "      <td>3.221675</td>\n",
       "      <td>0.891186</td>\n",
       "      <td>1.176328</td>\n",
       "      <td>0.052377</td>\n",
       "      <td>4.501683</td>\n",
       "      <td>4.449305</td>\n",
       "      <td>STD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69983 rows √ó 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_acc_x  mean_acc_y  mean_acc_z  mean_gyro_x  mean_gyro_y  \\\n",
       "0        0.253800   -9.735710   -0.759319    -0.052844     0.018417   \n",
       "1        0.249150   -9.739145   -0.733451    -0.032854     0.029329   \n",
       "2        0.386838   -9.739573   -0.578832    -0.036421     0.003834   \n",
       "3        0.326125   -9.741381   -0.672142    -0.049490     0.001070   \n",
       "4        0.283808   -9.745207   -0.738642    -0.042550     0.012788   \n",
       "...           ...         ...         ...          ...          ...   \n",
       "69978    5.822824   -1.556491    7.235764    -0.066575     0.083216   \n",
       "69979    6.218721   -2.150890    6.742830     0.040020     0.044249   \n",
       "69980    6.294121   -0.479762    5.933423     0.127804     0.004355   \n",
       "69981    4.271851    5.092304    3.382345     0.320573    -0.384789   \n",
       "69982    2.575851    8.923356    0.138188     0.196273    -0.318099   \n",
       "\n",
       "       mean_gyro_z  std_acc_x  std_acc_y  std_acc_z  std_gyro_x  ...  \\\n",
       "0         0.029541   0.245499   0.014139   0.217480    0.028723  ...   \n",
       "1         0.011645   0.237170   0.014339   0.232159    0.031158  ...   \n",
       "2         0.016446   0.146762   0.013975   0.088793    0.026637  ...   \n",
       "3         0.023786   0.055841   0.011643   0.079863    0.007339  ...   \n",
       "4         0.018867   0.027931   0.008566   0.040782    0.005152  ...   \n",
       "...            ...        ...        ...        ...         ...  ...   \n",
       "69978    -0.058658   1.872333   0.572352   1.382859    0.357383  ...   \n",
       "69979     0.119265   1.445265   0.697573   1.440475    0.306958  ...   \n",
       "69980    -0.142396   1.834981   4.135841   1.116061    0.857453  ...   \n",
       "69981    -0.601700   2.281468   5.606993   3.181307    1.035809  ...   \n",
       "69982    -0.303589   1.281563   2.904465   1.742787    0.719484  ...   \n",
       "\n",
       "       acc_mag_min  acc_mag_max  acc_mag_diff  acc_mag_energy_entropy  \\\n",
       "0         9.735512     9.809990      0.074478                3.293505   \n",
       "1         9.738685     9.809990      0.071305                3.292415   \n",
       "2         9.730387     9.785563      0.055175                3.292894   \n",
       "3         9.730387     9.790438      0.060051                3.293122   \n",
       "4         9.762408     9.792928      0.030519                3.292951   \n",
       "...            ...          ...           ...                     ...   \n",
       "69978     3.617510    12.013304      8.395794                3.276123   \n",
       "69979     8.646267    10.517353      1.871086                3.295499   \n",
       "69980     5.389208    12.161697      6.772488                3.251270   \n",
       "69981     5.289488    13.113264      7.823775                3.253118   \n",
       "69982     5.289488    13.113264      7.823775                3.221675   \n",
       "\n",
       "       gyro_mag_mean  gyro_mag_std  gyro_mag_min  gyro_mag_max  gyro_mag_diff  \\\n",
       "0           0.090548      0.039731      0.028844      0.229268       0.200424   \n",
       "1           0.072513      0.046496      0.019905      0.229268       0.209363   \n",
       "2           0.056273      0.017656      0.019905      0.092863       0.072958   \n",
       "3           0.059128      0.011383      0.044413      0.092863       0.048451   \n",
       "4           0.049011      0.005093      0.039530      0.058386       0.018856   \n",
       "...              ...           ...           ...           ...            ...   \n",
       "69978       0.490682      0.574643      0.027853      2.293158       2.265304   \n",
       "69979       0.425943      0.440300      0.027853      1.416272       1.388418   \n",
       "69980       1.127563      0.727587      0.040854      2.398200       2.357346   \n",
       "69981       1.482418      1.146300      0.133865      4.501683       4.367818   \n",
       "69982       0.891186      1.176328      0.052377      4.501683       4.449305   \n",
       "\n",
       "       label  \n",
       "0        STD  \n",
       "1        STD  \n",
       "2        STD  \n",
       "3        STD  \n",
       "4        STD  \n",
       "...      ...  \n",
       "69978    SIT  \n",
       "69979    CSO  \n",
       "69980    CSO  \n",
       "69981    STD  \n",
       "69982    STD  \n",
       "\n",
       "[69983 rows x 104 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Feature Extraction + Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ Extracts features once\n",
    "‚úÖ Encodes labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def preprocess_dataset(df, sampling_rate_ms, window_duration_s=2.5, overlap=0.5, test_size=0.2, random_state=42):\n",
    "    # Extract features and labels from windows\n",
    "    X, y = extract_features_from_windows(\n",
    "        df,\n",
    "        window_duration_s=window_duration_s,\n",
    "        overlap=overlap,\n",
    "        sampling_rate_ms=sampling_rate_ms\n",
    "    )\n",
    "\n",
    "    # Label encode target\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    print(f\"\\n‚úÖ Feature extraction done | Total windows: {len(y)} | Labels: {label_encoder.classes_}\")\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y_encoded)\n",
    "\n",
    "    print(f\"\\nüîÅ Data Split | Training: {len(y_train)} | Testing: {len(y_test)}\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, label_encoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, model_type=\"random_forest\", **kwargs):\n",
    "    if model_type == \"random_forest\":\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42, **kwargs)\n",
    "    elif model_type == \"knn\":\n",
    "        model = KNeighborsClassifier(**kwargs)\n",
    "    elif model_type == \"svm\":\n",
    "        model = SVC(probability=True, random_state=42, **kwargs)\n",
    "    elif model_type == \"mlp\":\n",
    "        model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42, **kwargs)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluation Function with Decode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, model_name=None, show_confusion_matrix=True, label_encoder=None):\n",
    "    \"\"\"\n",
    "    Evaluate a multi-class classification model and print standard metrics including accuracy.\n",
    "    \"\"\"\n",
    "    if model_name:\n",
    "        print(f\"\\nüìà Evaluation Results for Model: {model_name}\")\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Decode labels if label_encoder is provided\n",
    "    if label_encoder:\n",
    "        y_test_decoded = label_encoder.inverse_transform(y_test)\n",
    "        y_pred_decoded = label_encoder.inverse_transform(y_pred)\n",
    "    else:\n",
    "        y_test_decoded = y_test\n",
    "        y_pred_decoded = y_pred\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test_decoded, y_pred_decoded)\n",
    "    print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_decoded, y_pred_decoded, digits=4))\n",
    "\n",
    "    # Confusion matrix\n",
    "    if show_confusion_matrix:\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        print(confusion_matrix(y_test_decoded, y_pred_decoded))\n",
    "\n",
    "    # ROC AUC score\n",
    "    try:\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "        roc_auc = roc_auc_score(y_test, y_proba, multi_class='ovr', average='macro')\n",
    "        print(f\"\\nROC AUC (OvR, macro): {roc_auc:.4f}\")\n",
    "    except AttributeError:\n",
    "        print(\"\\nROC AUC not available (predict_proba missing for this model).\")\n",
    "    except ValueError:\n",
    "        print(\"\\nROC AUC could not be computed (check if y_test is binary or properly encoded).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Feature extraction done | Total windows: 69983 | Labels: ['BSC' 'CHU' 'CSI' 'CSO' 'FKL' 'FOL' 'JOG' 'JUM' 'LYI' 'SCH' 'SDL' 'SIT'\n",
      " 'STD' 'STN' 'STU' 'WAL']\n",
      "\n",
      "üîÅ Data Split | Training: 55986 | Testing: 13997\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, label_encoder = preprocess_dataset(df, sampling_rate_ms =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÅ Training & Evaluating Model: random_forest\n",
      "\n",
      "üìà Evaluation Results for Model: random_forest\n",
      "\n",
      "Accuracy: 0.9228\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BSC     0.8676    0.6277    0.7284        94\n",
      "         CHU     0.8800    0.5238    0.6567        42\n",
      "         CSI     0.7103    0.6255    0.6652       243\n",
      "         CSO     0.8340    0.7833    0.8078       263\n",
      "         FKL     0.6818    0.4286    0.5263        70\n",
      "         FOL     0.8293    0.5312    0.6476        64\n",
      "         JOG     0.9547    0.9447    0.9497       959\n",
      "         JUM     0.9492    0.9624    0.9558       932\n",
      "         LYI     0.8832    0.8884    0.8858       851\n",
      "         SCH     0.8354    0.5593    0.6701       118\n",
      "         SDL     0.6769    0.5366    0.5986        82\n",
      "         SIT     0.8780    0.8762    0.8771      1002\n",
      "         STD     0.9472    0.9779    0.9623      4124\n",
      "         STN     0.8721    0.7530    0.8082       498\n",
      "         STU     0.8991    0.7577    0.8224       553\n",
      "         WAL     0.9374    0.9849    0.9605      4102\n",
      "\n",
      "    accuracy                         0.9228     13997\n",
      "   macro avg     0.8523    0.7351    0.7827     13997\n",
      "weighted avg     0.9202    0.9228    0.9200     13997\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  59    0    1    2    0    0    1    1    6    2    8    0   14    0\n",
      "     0    0]\n",
      " [   0   22    0   10    0    0    0    0    1    0    0    7    1    0\n",
      "     1    0]\n",
      " [   0    0  152    9    0    0    3    7    2    1    2    7   30    4\n",
      "     9   17]\n",
      " [   0    0    7  206    0    0    0    0    2    0    1   15   19    0\n",
      "     1   12]\n",
      " [   1    0    0    0   30    3    2    3    4    1    4    0    8    9\n",
      "     0    5]\n",
      " [   0    0    3    0    7   34    0    1    4    0    2    0   11    2\n",
      "     0    0]\n",
      " [   0    0    2    1    0    0  906   10    0    0    0    0    5    8\n",
      "     6   21]\n",
      " [   0    0    0    1    0    0   12  897    0    0    0    0    8    7\n",
      "     1    6]\n",
      " [   0    0    2    0    1    1    0    0  756    0    0   84    4    0\n",
      "     0    3]\n",
      " [   0    0    3    2    0    0    3    8    1   66    1    5   18    0\n",
      "     1   10]\n",
      " [   6    0    8    0    5    2    0    0    5    0   44    1   10    1\n",
      "     0    0]\n",
      " [   0    0   11    9    0    0    0    0   69    8    0  878   27    0\n",
      "     0    0]\n",
      " [   1    3    4    6    0    1    5   11    6    1    1    3 4033   11\n",
      "     7   31]\n",
      " [   0    0    4    0    1    0    5    4    0    0    2    0   23  375\n",
      "     5   79]\n",
      " [   1    0    6    0    0    0    7    1    0    0    0    0   28    5\n",
      "   419   86]\n",
      " [   0    0   11    1    0    0    5    2    0    0    0    0   19    8\n",
      "    16 4040]]\n",
      "\n",
      "ROC AUC (OvR, macro): 0.9900\n",
      "\n",
      "üîÅ Training & Evaluating Model: knn\n",
      "\n",
      "üìà Evaluation Results for Model: knn\n",
      "\n",
      "Accuracy: 0.8902\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BSC     0.6000    0.6383    0.6186        94\n",
      "         CHU     0.6571    0.5476    0.5974        42\n",
      "         CSI     0.5691    0.5761    0.5726       243\n",
      "         CSO     0.7421    0.7110    0.7262       263\n",
      "         FKL     0.5085    0.4286    0.4651        70\n",
      "         FOL     0.5946    0.3438    0.4356        64\n",
      "         JOG     0.9291    0.9426    0.9358       959\n",
      "         JUM     0.9607    0.9442    0.9524       932\n",
      "         LYI     0.8085    0.7192    0.7612       851\n",
      "         SCH     0.5763    0.5763    0.5763       118\n",
      "         SDL     0.5833    0.3415    0.4308        82\n",
      "         SIT     0.7623    0.8323    0.7958      1002\n",
      "         STD     0.9334    0.9488    0.9411      4124\n",
      "         STN     0.8610    0.6968    0.7703       498\n",
      "         STU     0.8668    0.7414    0.7992       553\n",
      "         WAL     0.9320    0.9756    0.9533      4102\n",
      "\n",
      "    accuracy                         0.8902     13997\n",
      "   macro avg     0.7428    0.6853    0.7082     13997\n",
      "weighted avg     0.8878    0.8902    0.8876     13997\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  60    0    4    3    0    1    1    1    5    3    1    0   14    1\n",
      "     0    0]\n",
      " [   0   23    0    2    0    0    0    0    4    0    0   11    2    0\n",
      "     0    0]\n",
      " [   3    0  140   15    1    0    1    0    1   11    2    8   39    3\n",
      "    10    9]\n",
      " [   1    1   13  187    0    1    0    0    9    2    1   19   21    0\n",
      "     1    7]\n",
      " [   4    0    8    0   30    4    2    1    5    2    3    0    6    2\n",
      "     0    3]\n",
      " [   3    0    2    0   12   22    1    0    7    3    5    0    7    2\n",
      "     0    0]\n",
      " [   0    0    3    0    0    1  904    5    0    3    1    1   14   11\n",
      "     4   12]\n",
      " [   0    0    1    0    1    0   17  880    0    0    1    0   10   12\n",
      "     1    9]\n",
      " [   5    1   10    9    2    3    0    0  612    0    2  201    1    0\n",
      "     0    5]\n",
      " [   1    1    6    2    2    0    2    0    1   68    0    5   19    0\n",
      "     0   11]\n",
      " [  11    0    9    2    8    1    0    0    9    1   28    1    9    2\n",
      "     0    1]\n",
      " [   2    2   13   17    0    0    1    0   96    9    1  834   25    2\n",
      "     0    0]\n",
      " [   6    6   12   12    1    1   31   22    6    8    2   11 3913   13\n",
      "    17   63]\n",
      " [   1    1    5    0    2    2    6    7    0    5    1    1   30  347\n",
      "    10   80]\n",
      " [   2    0    5    1    0    1    5    0    1    2    0    0   30    4\n",
      "   410   92]\n",
      " [   1    0   15    2    0    0    2    0    1    1    0    2   52    4\n",
      "    20 4002]]\n",
      "\n",
      "ROC AUC (OvR, macro): 0.9268\n",
      "\n",
      "üîÅ Training & Evaluating Model: mlp\n",
      "\n",
      "üìà Evaluation Results for Model: mlp\n",
      "\n",
      "Accuracy: 0.9058\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BSC     0.7089    0.5957    0.6474        94\n",
      "         CHU     0.7576    0.5952    0.6667        42\n",
      "         CSI     0.5992    0.6461    0.6218       243\n",
      "         CSO     0.8739    0.7376    0.8000       263\n",
      "         FKL     0.4684    0.5286    0.4966        70\n",
      "         FOL     0.5526    0.3281    0.4118        64\n",
      "         JOG     0.9646    0.9385    0.9514       959\n",
      "         JUM     0.9655    0.9603    0.9629       932\n",
      "         LYI     0.7661    0.8543    0.8078       851\n",
      "         SCH     0.6392    0.5254    0.5767       118\n",
      "         SDL     0.6087    0.5122    0.5563        82\n",
      "         SIT     0.8341    0.7525    0.7912      1002\n",
      "         STD     0.9493    0.9709    0.9600      4124\n",
      "         STN     0.7481    0.8112    0.7784       498\n",
      "         STU     0.8137    0.7740    0.7933       553\n",
      "         WAL     0.9641    0.9686    0.9663      4102\n",
      "\n",
      "    accuracy                         0.9058     13997\n",
      "   macro avg     0.7634    0.7187    0.7368     13997\n",
      "weighted avg     0.9053    0.9058    0.9048     13997\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  56    0    1    0    0    0    3    0    7    4   12    0    9    0\n",
      "     1    1]\n",
      " [   1   25    1    5    0    0    0    0    0    0    0    4    4    0\n",
      "     0    2]\n",
      " [   4    0  157    3    1    0    3    1    2    5    4    7   19   14\n",
      "     9   14]\n",
      " [   2    4    9  194    1    0    1    0    5    2    1    9   22    2\n",
      "     4    7]\n",
      " [   1    0    1    0   37    8    1    4    3    1    1    0    1    4\n",
      "     5    3]\n",
      " [   0    1    2    1   13   21    1    1    8    2    4    0    5    4\n",
      "     1    0]\n",
      " [   2    0    7    0    1    1  900    7    0    0    0    1    7   12\n",
      "     5   16]\n",
      " [   0    0    2    0    3    0    2  895    0    0    1    1    8   14\n",
      "     2    4]\n",
      " [   3    0    0    0    0    2    0    0  727    0    4  109    5    0\n",
      "     0    1]\n",
      " [   1    0   17    0    1    0    1    3    2   62    0    6   13    1\n",
      "     3    8]\n",
      " [   1    0    7    1    6    4    1    0    8    1   42    1    7    1\n",
      "     1    1]\n",
      " [   1    0   18    9    1    0    0    1  175    8    0  754   34    1\n",
      "     0    0]\n",
      " [   5    3   16    5    7    0    4    6   10    4    0   12 4004   24\n",
      "    10   14]\n",
      " [   0    0    3    0    6    1    3    8    1    2    0    0   28  404\n",
      "    16   26]\n",
      " [   1    0    9    0    2    1    8    1    0    6    0    0   22   24\n",
      "   428   51]\n",
      " [   1    0   12    4    0    0    5    0    1    0    0    0   30   35\n",
      "    41 3973]]\n",
      "\n",
      "ROC AUC (OvR, macro): 0.9826\n"
     ]
    }
   ],
   "source": [
    "for model_type in [\"random_forest\", \"knn\", \"mlp\"]:\n",
    "    print(f\"\\nüîÅ Training & Evaluating Model: {model_type}\")\n",
    "\n",
    "    model = train_model(X_train, y_train, model_type=model_type)\n",
    "\n",
    "    evaluate_model(\n",
    "        model,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        model_name=model_type,\n",
    "        label_encoder=label_encoder\n",
    "     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
